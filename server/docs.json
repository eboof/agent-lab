[
  {
    "filename": "PocketBlog250304.pdf",
    "title": "I Built Pocket Flow, an LLM Framework in just 10",
    "date": "2025-03-04",
    "content": "\n\nI Built Pocket Flow, an LLM Framework in just 10\nLines — Here is Why\nMAR 04, 2025\n134Sh\nHave you ever stared at a complex AI framework and wondered, “Does it really need to\nthis complicated?” After a year of struggling with bloated frameworks, I decided to stri\naway anything unnecessary. The result is Pocket Flow, a minimalist LLM framework in\n100 lines of code.\nFor the past year, I’ve been building AI applications using popular frameworks lik\nLangChain. The experience has been consistently frustrating:\nBloated Abstraction: As Octomind’s engineering team explains: “LangChain w\nhelpful at first when our simple requirements aligned with its usage presumptions. Bu\nhigh-level abstractions soon made our code more difficult to understand and frustrat\nmaintain.” These frameworks hide simple functionality behind unnecessary\ncomplexity.\nZACHARY HUANG\n30\nCurrent LLM Frameworks Are Bloated\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just1/14\n\nImplementation Nightmares: Beyond the abstractions, these frameworks bur\ndevelopers with dependency bloat, version conflicts, and constantly changing\ninterfaces. Developers often complain: “It’s unstable, the interface constantly cha\nthe documentation is regularly out of date.” Another developer jokes: “In the time \ntook to read this sentence langchain deprecated 4 classes without updating\ndocumentation.”\nThis led me to wonder: Do we really need so many wrappers? What if we stripped everyth\naway? What is truly minimal and viable?\nAfter a year of building LLM applications from scratch, I had a revelation: beneath\nthe complexity, LLM systems are fundamentally just simple directed graphs. By\nstripping away the unnecessary layers, I created Pocket Flow — a framework with\nbloat, zero dependencies, and zero vendor lock-in, all in just 100 lines of code.\nEnter Pocket Flow: 100 Lines For the\nCore Abstraction\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just2/14\n\nComparison of AI system frameworks for abstraction, application-specific wrappers,\nvendor-specific wrappers, lines of code, and size.\nThink of Pocket Flow like a well-organized kitchen:\nNodes are like cooking stations (chopping, cooking, plating):\nFlow is the recipe dictating which station to visit next:\nShared store is the countertop where ingredients are visible to all stations. It \noften an in-mem dict:\nThe Simple Building Blocks\nclass BaseNode:\n  def __init__(self): \n    self.params,self.successors={},{}\n  def add_successor(self,node,action=\"default\"): \nself.successors[action]=node;return node\n  def prep(self,shared): pass\n  def exec(self,prep_res): pass\n  def post(self,shared,prep_res,exec_res): pass\n  def run(self,shared): p=self.prep(shared);e=self.exec(p);return \nself.post(shared,p,e)\nclass Flow(BaseNode):\n  def __init__(self,start): super().__init__();self.start=start\n  def get_next_node(self,curr,action):\n      return nxt=curr.successors.get(action or \"default\")\n  def orch(self,shared,params=None):\n      curr,p=copy.copy(self.start),(params or {**self.params})\n      while curr: \ncurr.set_params(p);c=curr.run(shared);curr=copy.copy(self.get_next_\node(curr,c))\n  def run(self,shared): \npr=self.prep(shared);self.orch(shared);return \nself.post(shared,pr,None)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just3/14\n\nIn our kitchen (agent system):\n1. Each station (Node) performs three simple operations:\nPrep: Retrieve what you need from the shared store (gather ingredients)\nExec: Perform your specialized task (cook the ingredients)\nPost: Return results to the shared store and determine next steps (serve the di\nand decide what to make next)\n2. The recipe (Flow) directs execution based on conditions (Orch):\n“If vegetables are chopped, proceed to cooking station”\n“If meal is cooked, move to plating station”\nWe also support batch processing, asynchronous execution, and parallel processin\nboth nodes and flows. And that’s it! That’s all you need to build LLM applications.\nunnecessary abstractions, no complex architecture — just simple building blocks t\ncan be composed to create powerful systems.\nPocket Flow Core Graph Abstraction\nload_data_node = LoadDataNode()\nsummarize_node = SummarizeNode()\nload_data_node >> summarize_node\nflow = Flow(start=load_data)\nshared = {\"file_name\": \"data.txt\"}\nflow.run(shared)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just4/14\n\nUnlike other frameworks, Pocket Flow deliberately avoids bundling vendor-specifi\nAPIs. Here’s why:\nNo Dependency Issues: Current LLM frameworks come with hundreds of MB\ndependencies. Pocket Flow has zero dependencies, keeping your project lean a\nnimble.\nNo Vendor Lock-in: You’re free to use any model you want, including local m\nlike OpenLLaMA, without changing your core architecture.\nCustomized Full Control: Want prompt caching, batching, and streaming? Bu\nexactly what you need without fighting against pre-baked abstractions.\nWhat if you need an API wrapper? Just ask models like ChatGPT to write one on-\nfly. It’s usually just 10 lines of code. This approach is far more flexible than rigid b\nin wrappers or abstractions that quickly become outdated.\nWith this minimal but powerful building blocks, you can build sophisticated agents, RA\nsystems, and LLM workflows with complete transparency and control over every compon\nLet’s see an example!\nWhat About Wrappers Like OpenAI?\ndef call_llm(prompt):\n   from openai import OpenAI\n   client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n   r = client.chat.completions.create(\n      model=\"gpt-4o\", messages=[{\"role\": \"user\", \"content\": prompt}]\n   )\n   return r.choices[0].message.content\n# Example usage\ncall_llm(\"Hello World!\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just5/14\n\nLet’s build a simple web search agent using the building blocks from Pocket Flow.\nSuch a simple web search AI agent that can search the web and answer questions \nsimilar to tools like Perplexity AI.\nHere’s the agent’s behavior modeled as a simple flow graph:\nLetʼs build a Web Search Agent with\nPocket Flow\nThe Flow Design\n# Create instances of each node\ndecide = DecideAction()\nsearch = SearchWeb()\nanswer = AnswerQuestion()\n# Connect the nodes\n# If DecideAction returns \"search\", go to SearchWeb\ndecide - \"search\" >> search\n# If DecideAction returns \"answer\", go to AnswerQuestion\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just6/14\n\nWhat Happens at Each Node?\n1. DecideAction — “Should we search the web, or do we already know enough?”\nPrep: Pulls in the original question and any previous search context from shar\nmemory\nExec: Asks the LLM whether to perform a web search or answer directly\nPost: Saves a search query if needed, and returns either \"search\" or \"answe\nas the next action\n2. SearchWeb — “Let’s go fetch some fresh information.”\nPrep: Retrieves the query generated in the last step\nExec: Calls a web search API (Google, Bing, etc.), fetches results, and distills t\ninto readable chunks\nPost: Adds the search results back into context, then loops back to DecideAct\nfor re-evaluation\n3. AnswerQuestion — “We’ve got enough info — let’s answer the question.”\nPrep: Collects the question and all search context\nExec: Prompts the LLM to generate a well-researched, helpful answer\nPost: Stores the final response and signals \"done\" to finish the flow\nThe graph is dynamic, transparent, and easy to extend. You can plug in different\nLLMs, swap out the search engine, or insert new decision points — without ever\ndecide - \"answer\" >> answer\n# After SearchWeb completes and returns \"decide\", go back to \nDecideAction\nsearch - \"decide\" >> decide\n# Create and return the flow, starting with the DecideAction node\nreturn Flow(start=decide) \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just7/14\n\nbreaking the core logic.\nImagine you asked our agent: “Who won the 2023 Super Bowl?” Here’s what would\nhappen step-by-step for each node:\n1. DecideAction Node:\nLOOKS AT (Prep): Your question and what we know so far (nothing yet)\nTHINKS (Exec): “I don’t know who won the 2023 Super Bowl, I need to search\nDECIDES (Post): Search for “2023 Super Bowl winner”\nPASSES TO (Orch): SearchWeb station\n2. SearchWeb Node:\nLOOKS AT (Prep): The search query “2023 Super Bowl winner”\nDOES (Exec): Searches the internet (imagine it finds “The Kansas City Chiefs\nwon”)\nSAVES (Post): The search results to our shared countertop\nPASSES TO (Orch): Back to DecideAction station\n3. DecideAction Node(second time):\nLOOKS AT (Prep): Your question and what we know now (search results)\nTHINKS (Exec): “Great, now I know the Chiefs won the 2023 Super Bowl”\nDECIDES (Post): We have enough info to answer\nPASSES TO (Orch): AnswerQuestion station\n4. AnswerQuestion Node:\nLOOKS AT (Prep): Your question and all our research\nDOES (Exec): Creates a friendly answer using all the information\nSAVES (Post): The final answer\nLetʼs Walk Through an Example\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just8/14\n\nFINISHES (Orch): The task is complete!\nAnd that’s it! Simple, elegant, and powered by search. The entire agent\nimplementation requires just a few hundred lines of code, built on our 100-line\nframework. You can see the complete code and run it yourself using this cookbook\nThis is the essence of Pocket Flow: composable nodes and simple graphs creating smar\nreactive AI agents. No hidden magic. No framework gymnastics. Just clear logic and com\ncontrol.\nPocket Flow isn’t limited to search agents. Build everything you love — Multi-Age\nWorkflows, RAG systems, Map-Reduce operations, Streaming, Supervisors, Chat\nMemory, Model Context Protocol, and more — all with the same elegant simplicit\nEach implementation follows the same pattern: a few hundred lines of code built o\nfirst principles, with our minimal 100-line framework as the foundation.\nNo unnecessary abstraction. No bloat. Instead of trying to understand a gigantic\nframework with hundreds of thousands of files, Pocket Flow gives you the\nfundamentals so you can build your own understanding from the ground up. Find\ncomplete tutorials for all these implementations in the Pocket Flow GitHub repos\nand explore our basic tutorials to get started.\nWhat else can we build?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just9/14\n\nDesign Patterns based on Pocket Flow\nThe true power of Pocket Flow extends beyond its minimalist design. Its most\nrevolutionary aspect is enabling Agentic Coding — a new way of programming wh\nAI assistants help you build and modify AI applications.\nAgentic coding is simply the practice of working alongside AI to build software. T\nof it like building a house — you’re the architect with the vision and expertise, wh\nthe AI is your construction crew handling the detailed work:\nYou focus on high-level design and strategic decisions (the human strength)\nThe AI assistant handles implementation details and technical execution (the\nstrength)\nYou review and refine the results, guiding the process\nThis 10x productivity multiplier means you spend less time coding repetitive patte\nand more time on creative problem-solving.\nFuture Vision of Pocket Flow: Agentic\nCoding\nWhat is Agentic Coding?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just10/14\n\nAgentic Coding in Action\nHow do we teach AI to build powerful LLM applications? Previous frameworks to\nthe wrong approach — they create hard coded wrappers for specific applications l\nsummarization, tagging, and web scraping that end up bewildering both human\ndevelopers and AI assistants alike.\nOur solution is elegantly simple: Documentation as the second codebase! Instead\nhard coded wrappers, vibe code them in documentation. Pocket Flow provides jus\nlines of core building blocks, paired with clear documentation that teaches how to\ncombine these blocks into powerful applications. We simply provide examples and\nAI agents implement solutions on the fly. This documentation-as-code approach\nallows AI assistants to:\n1. Master the fundamentals: Learn a small set of building blocks instead of\ndrowning in framework complexity\nTeaching AI to Build LLM Applications\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just11/14\n\n2. Build customized solutions: Generate implementations perfectly tailored to\nspecific application needs\n3. Focus on architecture: Think about system design rather than fighting framew\nlimitations\nWe pass these “instruction manuals” directly to AI assistants as rule files (e.g.,\n.cursorrules for cursor AI), giving them the knowledge to build sophisticated syste\nfrom simple components.\nFor deeper exploration of this approach, visit: Agentic Coding: The Most Fun Way\nBuild LLM Apps or check out my YouTube channel for more tutorials.\nThe future vision is even more exciting: as Pocket Flow patterns spread through the devel\necosystem, they’ll eventually be absorbed into future LLMs’ training data. At that point,\nwon’t even need explicit documentation — AI assistants will intrinsically understand th\nprinciples, making LLM application development truly frictionless.\nPocket Flow strips away the complexity, offering just what you need: 100 lines of c\nthat model LLM applications as simple directed graphs. No bloat, no magic, just\ntransparent logic and complete control.\nIf you’re tired of framework gymnastics and want to build your understanding from\nthe ground up, Pocket Flow’s minimalist approach lets you create powerful agents\ntoday while preparing for the agentic coding revolution of tomorrow.\nJoin our Discord community to connect with other developers building with Pocke\nFlow!\nConclusion: Simplicity Is the Ultimate\nSophistication\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just12/14\n\nTry Pocket Flow today and experience how 100 lines can replace hundreds of thousand\nGitHub Repository | Documentation | TypeScript Version\nSubscribe to Pocket Flow\nBy Zachary Huang · Launched 6 months ago\nPocket Flow: 100-line LLM framework for Agentic Coding\nBy subscribing, I agree to Substack'sTerms of Use, and\nacknowledge itsInformation Collection NoticeandPrivacy Policy.\n30 Likes∙4 Restacks\nDiscussion about this post\nPledge your support\nNext\nWrite a comment...\nJul 16\nLiked by Zachary Huang\nLeandro\nI am having fun with this already! Gemini CLI helped me make this flow that reads an m3u fil\ndownloads its URLs in parallel. It took a while to get Gemini to follow the conventions, but I t\ngot close enough by the end of the session.\nhttps://github.com/argenkiwi/pocketflow-m3u-downloader\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just13/14\n\n11 more comments...\nLIKE (2)REPLY\nJul 18\nLiked by Zachary Huang\nLarry Maloney\nThank you for building this. I have avoided that problem. Now that Pocket Flow exists, I will s\nwith it.\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:59 PMI Built Pocket Flow, an LLM Framework in just 100 Lines — Here is Why\nhttps://pocketflow.substack.com/p/i-built-an-llm-framework-in-just14/14"
  },
  {
    "filename": "PocketBlog250314.pdf",
    "title": "Use AI to Generate Cold Outreach Openers",
    "date": "2025-03-14",
    "content": "\n\nUse AI to Generate Cold Outreach Openers\nStep-by-Step Tutorial using Pocket Flow, a 100-line LLM framework!\nMAR 14, 2025\nSh\nZACHARY HUANG\n4\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach1/15\n\nCold outreach is a numbers game—but that doesn't mean it has to feel like spam.\nWhat if you could personally research each prospect, find their recent achievemen\ninterests, and background, and craft a thoughtful opening message that shows you\ndone your homework?\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThat's exactly what we're building today: a tool that uses AI to automate what wou\nnormally take hours of manual research and writing. In this tutorial, I'll show you \nto use AI to generate cold outreach openers that are:\nActually personalized (not just \"Hey {first_name}!\")\nBased on real research (not made-up facts)\nAttention-grabbing (by referencing things your prospect actually cares about)\nThe best part? You can adapt this approach for your own needs—whether you're\nlooking for a job, raising funds for your startup, or reaching out to potential client\nThe result is available at: https://github.com/The-Pocket/Tutorial-Cold-Email-\nPersonalization\nYou can try it online: https://pocket-opener-851564657364.us-east1.run.app\nLet's dive in.\nHere's the high-level workflow of what we're building:\n1. Input: You provide basic information about your prospect (name, relevant\nkeywords)\n2. Research: The AI searches the web for information about your prospect\nHow It Works: The System Behind Personalize\nAI Openers\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach2/15\n\n3. Analysis: The AI analyzes the search results for personalization opportunities\n4. Generation: The AI crafts a personalized opening message based on its resear\n5. Output: You get a ready-to-use opening message\nThe entire process takes about 30-60 seconds per prospect—compared to the 15+\nminutes it might take to do this research manually.\nThis system is built using Pocket Flow, a 100-line minimalist framework for buildi\nLLM applications. What makes Pocket Flow special isn't just its compact size, but\nhow it reveals the inner workings of AI application development in a clear, educat\nway.\nTo follow along with this tutorial, you'll need:\n1. API keys for AI and search services\n2. Basic Python knowledge\n3. Git to clone the repository\nNote: The implementation uses Google Search API and Claude for AI, but you \neasily replace them with your preferred services such as OpenAI GPT or SerpA\ndepending on your needs.\nIf you just want to try it out first, you can use the live demo.\nStart by cloning the repository with all the code you need:\nGetting Started: Setting Up Your Environment\nStep 1: Clone the Repository\ngit clone https://github.com/The-Pocket/Tutorial-Cold-Email-\nPersonalization.git\ncd Tutorial-Cold-Email-Personalization\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach3/15\n\nCreate a .env file in the project root directory with your API keys:\nThe tool is designed to work with different AI and search providers. Here's a simp\nimplementation of call_llm using OpenAI:\nStep 2: Set Up Your API Keys\nOPENAI_API_KEY=your_openai_api_key_here\n# utils/call_llm.py example\nimport os\nfrom openai import OpenAI\ndef call_llm(prompt):\n    \"\"\"Simple implementation using OpenAI.\"\"\"\n    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response.choices[0].message.content\n# Test the function\nif __name__ == \"__main__\":\n    print(call_llm(\"Write a one-sentence greeting.\"))\n# utils/call_llm.py example\nimport os\nfrom openai import OpenAI\ndef call_llm(prompt):\n    \"\"\"Simple implementation using OpenAI.\"\"\"\n    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response.choices[0].message.content\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach4/15\n\nYou can easily modify this to use other AI services or add features like caching.\nThe search_web utility function is implemented in a similar way—a simple func\nthat takes a query and returns search results. Just like with the LLM implementati\nyou can swap in your preferred search provider (Google Search, SerpAPI, etc.) base\non your needs.\nMake sure your API keys work by testing the utility functions:\nIf both scripts run without errors, you're ready to go!\nInstall the required Python packages:\nNow that you have everything set up, let's generate your first personalized opener.\ntool offers multiple interfaces to fit different workflows:\nCommand line interface for quick individual messages\nWeb UI for a user-friendly interactive experience\nBatch processing for handling multiple prospects at scale\n# Test the function\nif __name__ == \"__main__\":\n    print(call_llm(\"Write a one-sentence greeting.\"))\npython utils/call_llm.py  # Test your AI implementation\npython utils/search_web.py  # Test your search implementation\nStep 3: Install Dependencies\npip install -r requirements.txt\nUsing the Tool: Your First Personalized Opener\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach5/15\n\nChoose the method that works best for your specific needs:\nThe simplest way to generate a single opener is through the command line:\nThis will prompt you for:\nFirst name\nLast name\nKeywords related to the person (like company names or topics they're known \nFor a more user-friendly experience, run the web interface:\nThis will open a browser window where you can:\n1. Enter the target person's information\n2. Define personalization factors to look for\n3. Set your preferred message style\n4. Generate and review the opening message\nFor efficiently handling multiple prospects at once, the tool provides a powerful b\nprocessing mode:\nMethod 1: Using the Command Line Interface\npython main.py\nMethod 2: Using the Web Interface\nstreamlit run app.py\nMethod 3: Batch Processing from CSV\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach6/15\n\nYour input CSV should have three columns:\nfirst_name: Prospect's first name\nlast_name: Prospect's last name\nkeywords: Space-separated keywords (e.g., \"Tesla SpaceX entrepreneur\")\nThis is particularly useful when you need to reach out to dozens or hundreds of\nprospects. The system will:\n1. Process each row in your CSV file\n2. Perform web searches for each prospect\n3. Generate personalized openers for each one\n4. Write the results back to your output CSV file\nThe output CSV will contain all your original data plus an additional column with\ngenerated opening message for each prospect. You can then import this directly in\nyour email marketing tool or CRM system.\nExample batch processing workflow:\n1. Prepare a CSV with your prospect list\n2. Run the batch processing command\n3. Let it run (processing time: ~1 minute per prospect)\n4. Review and refine the generated openers in the output CSV\n5. Import into your outreach tool and start your campaign\nFor the best results, we recommend this approach:\npython main_batch.py --input my_targets.csv --output my_results.csv\nRecommended Workflow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach7/15\n\n1. Start with single mode or the Streamlit UI to fine-tune your personalization\nfactors and message style. This gives you immediate feedback on what works w\n2. Experiment with different settings for a few test prospects until you find the\nperfect combination of personalization factors and style preferences.\n3. Once satisfied with the results, scale up using the batch processing mode to\nhandle your entire prospect list.\nThis workflow ensures you don't waste time and API calls processing a large batch\nwith suboptimal settings, and helps you refine your approach before scaling.\nThis system is built using Pocket Flow, a 100-line minimalist framework for buildi\nLLM applications. What makes Pocket Flow special isn't just its compact size, but\nhow it reveals the inner workings of AI application development in a clear, educat\nway.\nUnlike complex frameworks that hide implementation details, Pocket Flow's\nminimalist design makes it perfect for learning how LLM applications actually wo\nunder the hood. With just 100 lines of core code, it's impressively expressive, allow\nyou to build sophisticated AI workflows while still understanding every componen\nDespite its small size, it provides many of the same capabilities you'd find in large\nlibraries like LangChain, LangGraph, or CrewAI:\nAgents & Tools: Build autonomous AI agents that can use tools and make\ndecisions\nRAG (Retrieval Augmented Generation): Enhance LLM responses with extern\nknowledge\nTask Decomposition: Break complex tasks into manageable subtasks\nParallel Processing: Handle multiple tasks efficiently with batch processing\nMulti-Agent Systems: Coordinate multiple AI agents working together\nUnderstanding the Magic: How the AI\nPersonalization Works\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach8/15\n\nThe difference? You can read and understand Pocket Flow's entire codebase in\nminutes, making it perfect for learning and customization.\nPocket Flow's approach to complex AI workflows is elegant and transparent:\nGraph-based Processing: Each task is a node in a graph, making the flow easy\nunderstand and modify\nShared State: Nodes communicate through a shared store, eliminating comple\ndata passing\nBatch Processing: Built-in support for parallel processing of multiple items\nFlexibility: Easy to swap components or add new features without breaking\nexisting code\nLet's look at how we've structured our cold outreach system using Pocket Flow:\nThe system follows a straightforward flow pattern with these core components:\n1. SearchPersonNode: Searches the web for information about the prospect\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach9/15\n\n2. ContentRetrievalNode (Batch): Retrieves and processes content from search\nresults in parallel\n3. AnalyzeResultsBatchNode (Batch): Analyzes content for personalization\nopportunities using LLM\n4. DraftOpeningNode: Creates the final personalized opener\nWhat makes this architecture powerful is its:\nModularity: Each component can be improved independently\nParallel Processing: Batch nodes handle multiple items simultaneously\nFlexibility: You can swap in different search providers or LLMs\nScalability: Works for single prospects or batch processing\nNow, let's break down the implementation details for each phase:\nThe system first searches the web for information about your prospect using their\nname and the keywords you provided:\n1. Web Search Phase\n# From flow.py\nclass SearchPersonNode(Node):\n    def prep(self, shared):\n        first_name = shared[\"input\"][\"first_name\"]\n        last_name = shared[\"input\"][\"last_name\"]\n        keywords = shared[\"input\"][\"keywords\"]\n        \n        query = f\"{first_name} {last_name} {keywords}\"\n        return query\n    \n    def exec(self, query):\n        search_results = search_web(query)\n        return search_results\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach10/15\n\nBy default, the implementation uses Google Search API, but you can easily swap t\nout for another search provider like SerpAPI in the search_web utility function. \nflexibility allows you to use whichever search provider works best for your needs o\nbudget.\nNext, it retrieves and processes the content from the top search results:\nThe system then analyzes the content looking for specific personalization factors y\ndefined:\n2. Content Retrieval Phase\nclass ContentRetrievalNode(BatchNode):\n    def prep(self, shared):\n        search_results = shared[\"search_results\"]\n        urls = [result[\"link\"] for result in search_results if \"link\" \nresult]\n        return urls\n    \n    def exec(self, url):\n        content = get_html_content(url)\n        return {\"url\": url, \"content\": content}\n3. Analysis Phase\nclass AnalyzeResultsBatchNode(BatchNode):\n    def exec(self, url_content_pair):\n        # Prepare prompt for LLM analysis\n        prompt = f\"\"\"Analyze the following webpage content about \n{self.first_name} {self.last_name}.\n        Look for the following personalization factors:\n        \n{self._format_personalization_factors(self.personalization_factors)}\"\"\n        \n        # LLM analyzes the content for personalization opportunities\n        analysis_results = call_llm(prompt)\n        return analysis_results\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach11/15\n\nFinally, the system crafts a personalized opener based on the discovered informati\nThe system uses the call_llm utility function which can be configured to use\ndifferent AI models like Claude or GPT models from OpenAI. This allows you to\nexperiment with different LLMs to find the one that creates the most effective ope\nfor your specific use case.\nThe real power of this system is in the personalization factors you define. Here are\nsome effective examples:\nRecent company news: \"I saw [Company] just announced [News]. I'd love to\ndiscuss how my experience in [Skill] could help with this initiative.\"\n4. Generation Phase\nclass DraftOpeningNode(Node):\n    def exec(self, prep_data):\n        first_name, last_name, style, personalization = prep_data\n        \n        prompt = f\"\"\"Draft a personalized opening message for a cold \noutreach email to {first_name} {last_name}.\n        \n        Style preferences: {style}\n        \n        Personalization details:\n        {self._format_personalization_details(personalization)}\n        \n        Only write the opening message. Be specific, authentic, and \nconcise.\"\"\"\n        \n        opening_message = call_llm(prompt)\n        return opening_message\nCustomizing for Your Needs\nFor Job Seekers:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach12/15\n\nShared alma mater: \"As a fellow [University] alum, I was excited to see your w\non [Project].\"\nMutual connection: \"I noticed we're both connected to [Name]. I've worked w\nthem on [Project] and they spoke highly of your team.\"\nPain points: \"I noticed from your recent interview that [Company] is facing\nchallenges with [Problem]. We've helped similar companies solve this by...\"\nGrowth initiatives: \"Congratulations on your expansion into [Market]. Our\nsolution has helped similar companies accelerate growth in this area by...\"\nCompetitor mentions: \"I saw you mentioned working with [Competitor] in th\npast. Many of our clients who switched from them found our approach to [Fea\nmore effective because...\"\nInvestment thesis alignment: \"Your recent investment in [Company] caught m\nattention. Our startup is also focused on [Similar Space], but with a unique\napproach to...\"\nIndustry challenges: \"I read your thoughts on [Industry Challenge] in\n[Publication]. We're building a solution that addresses this exact issue by...\"\nShared vision: \"Your talk at [Conference] about [Topic] resonated with me. We\nbuilding technology that aligns with your vision of [Vision]...\"\nHere are some tips for getting the best results from the system:\n1. Be specific with keywords: Instead of just \"CEO\", try \"CEO FinTech\nYCombinator\"\n2. Test different personalization factors: Some work better than others dependi\non the person\nFor Sales Professionals:\nFor Founders:\nTips for Better Results\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach13/15\n\n3. Refine your style preferences: The more specific your style guidance, the bett\nthe results\n4. Review and edit: AI-generated openers are a starting point, not the final prod\n5. A/B test: Try different approaches and track which ones get better responses\nWhile we've focused on cold outreach openers, the same approach can be used for\nPersonalizing follow-ups after meetings\nCrafting tailored proposals based on prospect research\nCreating customized content that resonates with specific audience segments\nBuilding detailed prospect profiles for your sales team\nThe possibilities are endless when you combine AI with thoughtful personalizatio\nstrategies.\nThe key is striking the right balance: using AI to scale your outreach without losin\nthe human touch that makes connections meaningful.\nWant to explore the full code? Check out the GitHub repository.\nHave questions or want to share your results? Leave a comment below!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n4 Likes\nConclusion: Beyond Cold Outreach\nPreviousNext\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach14/15\n\nDiscussion about this post\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:58 PMUse AI to Generate Cold Outreach Openers - by Zachary Huang\nhttps://pocketflow.substack.com/p/use-ai-to-generate-cold-outreach15/15"
  },
  {
    "filename": "PocketBlog250315.pdf",
    "title": "Building Cursor with Cursor: A Step-by-Step",
    "date": "2025-03-15",
    "content": "\n\nBuilding Cursor with Cursor: A Step-by-Step\nGuide to Creating Your Own AI Coding Agent\nMAR 15, 2025\nSh\nHave you ever wished you could customize your AI coding assistant to work exact\nthe way you want? What if you could build your own version of Cursor—an AI-\npowered code editor—using Cursor itself? That's exactly what we're doing in this\ntutorial: creating a customizable, open-source AI coding agent that operates right\nwithin Cursor.\nIn this step-by-step guide, we'll dive deep into the code to show you how to build a\npowerful AI assistant that can:\nZACHARY HUANG\n6\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step1/18\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nNavigate and understand codebases\nImplement code changes based on natural language instructions\nMake intelligent decisions about which files to inspect or modify\nLearn from its own history of operations\nThe result is available at: https://github.com/The-Pocket/Tutorial-Cursor\nAlso, check out the YouTube Video:\nLet's dive in!\nBefore we write a single line of code, let's understand the architecture of our Curs\nAgent. The system is built on a flow-based architecture using Pocket Flow, a\n1. Understanding the Architecture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step2/18\n\nminimalist 100-line LLM framework that enables agentic development.\nHere's a high-level overview of our architecture:\nThis architecture separates concerns into distinct nodes:\nDecision making (what operation to perform next)\nFile operations (reading, writing, and searching)\nCode analysis (understanding and planning changes)\nCode modification (safely applying changes)\nLet's get our environment ready:\nOur agent is built on the Pocket Flow framework, which provides three core\nabstractions:\n2. Setting Up Your Environment\n# Clone the repository\ngit clone https://github.com/The-Pocket/Tutorial-Cursor\ncd Tutorial-Cursor\n# Install dependencies\npip install -r requirements.txt\n3. The Core: Building with Pocket Flow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step3/18\n\n1. Nodes: Individual units of computation that perform specific tasks\n2. Flows: Directed graphs of nodes that define the program's execution path\n3. Shared Store: A dictionary that all nodes can access to share data\nLet's look at the core imports and setup:\nThis imports the core classes from Pocket Flow and our custom utility functions th\nhandle file operations and LLM calls.\nAt the heart of our agent is the MainDecisionAgent, which determines what ac\nto take based on the user's request and the current state of the system.\nHere's how it's implemented:\n# flow.py\nfrom pocketflow import Node, Flow, BatchNode\nimport os\nimport yaml\nimport logging\nfrom datetime import datetime\nfrom typing import List, Dict, Any, Tuple\n# Import utility functions\nfrom utils.call_llm import call_llm\nfrom utils.read_file import read_file\nfrom utils.delete_file import delete_file\nfrom utils.replace_file import replace_file\nfrom utils.search_ops import grep_search\nfrom utils.dir_ops import list_dir\n4. Implementing Decision Making\nclass MainDecisionAgent(Node):\n    def prep(self, shared: Dict[str, Any]) -> Tuple[str, List[Dict[str\nAny]]]:\n        # Get user query and history\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step4/18\n\n        user_query = shared.get(\"user_query\", \"\")\n        history = shared.get(\"history\", [])\n        \n        return user_query, history\n    \n    def exec(self, inputs: Tuple[str, List[Dict[str, Any]]]) -> \nDict[str, Any]:\n        user_query, history = inputs\n        \n        # Format history for context\n        history_str = format_history_summary(history)\n        \n        # Create prompt for the LLM\n        prompt = f\"\"\"You are a coding assistant that helps modify and \nnavigate code. Given the following request, \ndecide which tool to use from the available options.\nUser request: {user_query}\nHere are the actions you performed:\n{history_str}\nAvailable tools:\n1. read_file: Read content from a file\n   - Parameters: target_file (path)\n2. edit_file: Make changes to a file\n   - Parameters: target_file (path), instructions, code_edit\n[... more tool descriptions ...]\nRespond with a YAML object containing:\n```yaml\ntool: one of: read_file, edit_file, delete_file, grep_search, list_dir\nfinish\nreason: |\n  detailed explanation of why you chose this tool and what you intend \ndo\nparams:\n  # parameters specific to the chosen tool\n```\"\"\"\n        \n        # Call LLM to decide action\n        response = call_llm(prompt)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step5/18\n\nThis node:\n1. Gathers the user's query and the history of previous actions\n2. Formats a prompt for the LLM with all available tools\n3. Calls the LLM to decide what action to take\n4. Parses the response and validates it\n5. Adds the decision to the history\n6. Returns the name of the selected tool, which determines the next node to exec\nLet's look at how our agent reads files, which is a fundamental operation:\n        \n        # Parse YAML response\n        yaml_content = extract_yaml_from_response(response)\n        decision = yaml.safe_load(yaml_content)\n        \n        # Validate the required fields\n        assert \"tool\" in decision, \"Tool name is missing\"\n        assert \"reason\" in decision, \"Reason is missing\"\n        \n        return decision\n    \n    def post(self, shared: Dict[str, Any], prep_res: Any, exec_res: \nDict[str, Any]) -> str:\n        # Add the decision to history\n        shared.setdefault(\"history\", []).append({\n            \"tool\": exec_res[\"tool\"],\n            \"reason\": exec_res[\"reason\"],\n            \"params\": exec_res.get(\"params\", {}),\n            \"timestamp\": datetime.now().isoformat()\n        })\n        \n        # Return the name of the tool to determine which node to execu\nnext\n        return exec_res[\"tool\"]\n5. File Operations: Reading and Writing Code\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step6/18\n\nThe read_file utility function itself is implemented like this:\nclass ReadFileAction(Node):\n    def prep(self, shared: Dict[str, Any]) -> str:\n        # Get parameters from the last history entry\n        history = shared.get(\"history\", [])\n        last_action = history[-1]\n        file_path = last_action[\"params\"].get(\"target_file\")\n        \n        # Ensure path is relative to working directory\n        working_dir = shared.get(\"working_dir\", \"\")\n        full_path = os.path.join(working_dir, file_path) if working_di\nelse file_path\n        \n        return full_path\n    \n    def exec(self, file_path: str) -> Tuple[str, bool]:\n        # Call read_file utility which returns a tuple of (content, \nsuccess)\n        return read_file(file_path)\n    \n    def post(self, shared: Dict[str, Any], prep_res: str, exec_res: \nTuple[str, bool]) -> str:\n        # Unpack the tuple returned by read_file()\n        content, success = exec_res\n        \n        # Update the result in the last history entry\n        history = shared.get(\"history\", [])\n        if history:\n            history[-1][\"result\"] = {\n                \"success\": success,\n                \"content\": content\n            }\n        \n        return \"decision\"  # Go back to the decision node\ndef read_file(target_file: str) -> Tuple[str, bool]:\n    \"\"\"\n    Read content from a file with support for line ranges.\n    Prepends 1-based line numbers to each line in the output.\n    \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step7/18\n\nThis provides a clean, line-numbered view of the file content that makes it easier f\nthe LLM to reference specific lines in its analysis.\nWhen the agent needs to modify code, it first analyzes the code and plans the chan\nusing AnalyzeAndPlanNode:\n    Returns:\n        Tuple of (file content with line numbers, success status)\n    \"\"\"\n    try:\n        if not os.path.exists(target_file):\n            return f\"Error: File {target_file} does not exist\", False\n        \n        with open(target_file, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n            # Add line numbers to each line\n            numbered_lines = [f\"{i+1}: {line}\" for i, line in \nenumerate(lines)]\n            return ''.join(numbered_lines), True\n            \n    except Exception as e:\n        return f\"Error reading file: {str(e)}\", False\n6. Code Analysis and Planning\nclass AnalyzeAndPlanNode(Node):\n    def prep(self, shared: Dict[str, Any]) -> Dict[str, Any]:\n        # Get history\n        history = shared.get(\"history\", [])\n        last_action = history[-1]\n        \n        # Get file content and edit instructions\n        file_content = last_action.get(\"file_content\")\n        instructions = last_action[\"params\"].get(\"instructions\")\n        code_edit = last_action[\"params\"].get(\"code_edit\")\n        \n        return {\n            \"file_content\": file_content,\n            \"instructions\": instructions,\n            \"code_edit\": code_edit\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step8/18\n\n        }\n    \n    def exec(self, params: Dict[str, Any]) -> List[Dict[str, Any]]:\n        file_content = params[\"file_content\"]\n        instructions = params[\"instructions\"]\n        code_edit = params[\"code_edit\"]\n        \n        # Generate a prompt for the LLM to analyze the edit\n        prompt = f\"\"\"\nAs a code editing assistant, I need to convert the following code edit\ninstruction \nand code edit pattern into specific edit operations (start_line, \nend_line, replacement).\nFILE CONTENT:\n{file_content}\nEDIT INSTRUCTIONS: \n{instructions}\nCODE EDIT PATTERN (markers like \"// ... existing code ...\" indicate \nunchanged code):\n{code_edit}\nAnalyze the file content and the edit pattern to determine exactly whe\nchanges should be made. \nReturn a YAML object with your reasoning and an array of edit \noperations:\n```yaml\nreasoning: |\n  Explain your thinking process about how you're interpreting the edit\npattern.\noperations:\n  - start_line: 10\n    end_line: 15\n    replacement: |\n      # New code here\n```\"\"\"\n        \n        # Call LLM to analyze the edit\n        response = call_llm(prompt)\n        \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step9/18\n\nThis node:\n1. Extracts the file content, instructions, and code edit pattern from the history\n2. Creates a prompt for the LLM to analyze the edit\n3. Calls the LLM to determine the exact line numbers and replacement text\n4. Parses the response to extract the edit operations\n5. Stores the reasoning in shared memory\n6. Returns the operations as a list of dictionaries\nOnce the agent has planned the changes, it applies them using ApplyChangesNo\n        # Parse the response and extract edit operations\n        yaml_content = extract_yaml_from_response(response)\n        result = yaml.safe_load(yaml_content)\n        \n        # Store reasoning in shared memory\n        shared[\"edit_reasoning\"] = result.get(\"reasoning\", \"\")\n        \n        # Return the operations\n        return result.get(\"operations\", [])\n7. Applying Code Changes\nclass ApplyChangesNode(BatchNode):\n    def prep(self, shared: Dict[str, Any]) -> List[Dict[str, Any]]:\n        # Get edit operations\n        edit_operations = shared.get(\"edit_operations\", [])\n        \n        # Sort edit operations in descending order by start_line\n        # This ensures that line numbers remain valid as we edit from \nbottom to top\n        sorted_ops = sorted(edit_operations, key=lambda op: \nop[\"start_line\"], reverse=True)\n        \n        # Get target file from history\n        history = shared.get(\"history\", [])\n        last_action = history[-1]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step10/18\n\nThis node is a BatchNode, which allows it to process multiple operations in a sin\nrun. It:\n        target_file = last_action[\"params\"].get(\"target_file\")\n        \n        # Ensure path is relative to working directory\n        working_dir = shared.get(\"working_dir\", \"\")\n        full_path = os.path.join(working_dir, target_file) if \nworking_dir else target_file\n        \n        # Attach file path to each operation\n        for op in sorted_ops:\n            op[\"target_file\"] = full_path\n        \n        return sorted_ops\n    \n    def exec(self, op: Dict[str, Any]) -> Tuple[bool, str]:\n        # Call replace_file utility to replace content\n        return replace_file(\n            target_file=op[\"target_file\"],\n            start_line=op[\"start_line\"],\n            end_line=op[\"end_line\"],\n            content=op[\"replacement\"]\n        )\n    \n    def post(self, shared: Dict[str, Any], prep_res: List[Dict[str, \nAny]], exec_res_list: List[Tuple[bool, str]]) -> str:\n        # Check if all operations were successful\n        all_successful = all(success for success, _ in exec_res_list)\n        \n        # Update edit result in history\n        history = shared.get(\"history\", [])\n        if history:\n            history[-1][\"result\"] = {\n                \"success\": all_successful,\n                \"operations\": len(exec_res_list),\n                \"details\": [{\"success\": s, \"message\": m} for s, m in \nexec_res_list],\n                \"reasoning\": shared.get(\"edit_reasoning\", \"\")\n            }\n        \n        return \"decision\"  # Go back to the decision node\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step11/18\n\n1. Gets the edit operations from shared memory\n2. Sorts them in descending order by start line to ensure edits remain valid\n3. Attaches the target file path to each operation\n4. Executes each operation using the replace_file utility\n5. Updates the history with the results\n6. Returns to the decision node\nThe replace_file utility works by combining remove_file and insert_fil\nNow that we've implemented all the key components, let's put it all together in ou\nmain.py:\ndef replace_file(target_file: str, start_line: int, end_line: int, \ncontent: str) -> Tuple[str, bool]:\n    try:\n        # First, remove the specified lines\n        remove_result, remove_success = remove_file(target_file, \nstart_line, end_line)\n        \n        if not remove_success:\n            return f\"Error during remove step: {remove_result}\", False\n        \n        # Then, insert the new content at the start line\n        insert_result, insert_success = insert_file(target_file, \ncontent, start_line)\n        \n        if not insert_success:\n            return f\"Error during insert step: {insert_result}\", False\n        \n        return f\"Successfully replaced lines {start_line} to \n{end_line}\", True\n        \n    except Exception as e:\n        return f\"Error replacing content: {str(e)}\", False\n8. Running Your Agent\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step12/18\n\nAnd finally, let's create the flow in flow.py:\nimport os\nimport argparse\nimport logging\nfrom flow import coding_agent_flow\ndef main():\n    # Parse command-line arguments\n    parser = argparse.ArgumentParser(description='Coding Agent - AI-\npowered coding assistant')\n    parser.add_argument('--query', '-q', type=str, help='User query to\nprocess', required=False)\n    parser.add_argument('--working-dir', '-d', type=str, \ndefault=os.path.join(os.getcwd(), \"project\"), \n                        help='Working directory for file operations')\n    args = parser.parse_args()\n    \n    # If no query provided via command line, ask for it\n    user_query = args.query\n    if not user_query:\n        user_query = input(\"What would you like me to help you with? \"\n    \n    # Initialize shared memory\n    shared = {\n        \"user_query\": user_query,\n        \"working_dir\": args.working_dir,\n        \"history\": [],\n        \"response\": None\n    }\n    \n    # Run the flow\n    coding_agent_flow.run(shared)\nif __name__ == \"__main__\":\n    main()\n# Define the nodes\nmain_decision = MainDecisionAgent()\nread_file_action = ReadFileAction()\ngrep_search_action = GrepSearchAction()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step13/18\n\nNow you can run your agent with:\nOne of the most powerful aspects of this architecture is how easy it is to customiz\nLet's explore a few ways you can extend this agent:\nlist_dir_action = ListDirAction()\ndelete_file_action = DeleteFileAction()\nedit_file_node = EditFileNode()\nanalyze_plan_node = AnalyzeAndPlanNode()\napply_changes_node = ApplyChangesNode()\nformat_response_node = FormatResponseNode()\n# Connect the nodes\nmain_decision - \"read_file\" >> read_file_action\nmain_decision - \"grep_search\" >> grep_search_action\nmain_decision - \"list_dir\" >> list_dir_action\nmain_decision - \"delete_file\" >> delete_file_action\nmain_decision - \"edit_file\" >> edit_file_node\nmain_decision - \"finish\" >> format_response_node\n# Connect action nodes back to main decision\nread_file_action - \"decision\" >> main_decision\ngrep_search_action - \"decision\" >> main_decision\nlist_dir_action - \"decision\" >> main_decision\ndelete_file_action - \"decision\" >> main_decision\n# Connect edit flow\nedit_file_node - \"analyze\" >> analyze_plan_node\nanalyze_plan_node - \"apply\" >> apply_changes_node\napply_changes_node - \"decision\" >> main_decision\n# Create the flow\ncoding_agent_flow = Flow(start=main_decision)\npython main.py --query \"List all Python files\" --working-dir ./project\n9. Advanced: Customizing Your Agent\n1. Adding New Tools\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step14/18\n\nTo add a new tool, simply:\n1. Create a new action node class\n2. Add it to the MainDecisionAgent's prompt\n3. Connect it to the flow\nFor example, to add a \"run_tests\" tool:\nclass RunTestsAction(Node):\n    def prep(self, shared):\n        # Get test directory from parameters\n        history = shared.get(\"history\", [])\n        last_action = history[-1]\n        test_dir = last_action[\"params\"].get(\"test_dir\")\n        return test_dir\n    \n    def exec(self, test_dir):\n        # Run tests and capture output\n        import subprocess\n        result = subprocess.run(\n            [\"pytest\", test_dir], \n            capture_output=True, \n            text=True\n        )\n        return result.stdout, result.returncode == 0\n    \n    def post(self, shared, prep_res, exec_res):\n        # Update history with test results\n        output, success = exec_res\n        history = shared.get(\"history\", [])\n        if history:\n            history[-1][\"result\"] = {\n                \"success\": success,\n                \"output\": output\n            }\n        return \"decision\"\n# Then add to your flow:\nrun_tests_action = RunTestsAction()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step15/18\n\nYou can enhance the code analysis capabilities by modifying the prompts in\nAnalyzeAndPlanNode:\nTo give your agent more context, you could add a vector database to store and retr\nrelevant information:\nmain_decision - \"run_tests\" >> run_tests_action\nrun_tests_action - \"decision\" >> main_decision\n2. Improving Code Analysis\n# Add language-specific hints\nlanguage_hints = {\n    \".py\": \"This is Python code. Look for function and class \ndefinitions.\",\n    \".js\": \"This is JavaScript code. Look for function declarations an\nexports.\",\n    # Add more languages as needed\n}\n# Update the prompt with language-specific hints\nfile_ext = os.path.splitext(target_file)[1]\nlanguage_hint = language_hints.get(file_ext, \"\")\nprompt += f\"\\n\\nLANGUAGE HINT: {language_hint}\"\n3. Adding Memory and Context\nclass VectorDBNode(Node):\n    def prep(self, shared):\n        # Get text to store\n        history = shared.get(\"history\", [])\n        context = \"\"\n        for action in history:\n            if action[\"tool\"] == \"read_file\" and action.get(\"result\", \n{}).get(\"success\", False):\n                content = action[\"result\"][\"content\"]\n                context += f\"File: {action['params']\n['target_file']}\\n{content}\\n\\n\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step16/18\n\nCongratulations! You've built a customizable AI coding agent that can help you\nnavigate and modify code based on natural language instructions. This agent\ndemonstrates the power of agentic development, where AI systems help build bett\nAI systems.\nThe possibilities for extending this agent are endless:\nAdd support for more programming languages\nImplement code refactoring capabilities\nCreate specialized tools for specific frameworks\nAdd security checks before making changes\nImplement static analysis to catch potential bugs\nAs LLM capabilities continue to improve, agents like this will become even more\npowerful tools in a developer's arsenal.\nWant to learn more? Subscribe to our YouTube channel for a step-by-step video\ntutorial on building and extending this agent.\n        return context\n    \n    def exec(self, context):\n        # Store in vector DB\n        embeddings = OpenAIEmbeddings()\n        vectordb = Chroma.from_texts(\n            texts=[context], \n            embedding=embeddings,\n            persist_directory=\"./db\"\n        )\n        return vectordb\n    \n    def post(self, shared, prep_res, exec_res):\n        shared[\"vectordb\"] = exec_res\n        return \"decision\"\n10. Conclusion and Next Steps\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step17/18\n\nHappy coding!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n6 Likes\nDiscussion about this post\nPreviousNext\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMBuilding Cursor with Cursor: A Step-by-Step Guide to Creating Your Own AI Coding Agent\nhttps://pocketflow.substack.com/p/building-cursor-with-cursor-a-step18/18"
  },
  {
    "filename": "PocketBlog250318.pdf",
    "title": "LLM Agents are simply Graph — Tutorial For",
    "date": "2025-03-18",
    "content": "\n\nLLM Agents are simply Graph — Tutorial For\nDummies\nMAR 18, 2025\n72Sh\nEver wondered how AI agents actually work behind the scenes? This guide breaks down\nhow agent systems are built as simple graphs - explained in the most beginner-friendly \npossible!\nNote: This is a super-friendly, step-by-step version of the official PocketFlow Agent\ndocumentation. We've expanded all the concepts with examples and simplified\nexplanations to make them easier to understand.\nHave you been hearing about \"LLM agents\" everywhere but feel lost in all the\ntechnical jargon? You're not alone! While companies are racing to build increasing\nZACHARY HUANG\n100\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial1/20\n\ncomplex AI agents like GitHub Copilot, PerplexityAI, and AutoGPT, most\nexplanations make them sound like rocket science.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nGood news: they're not. In this beginner-friendly guide, you'll learn:\nThe surprisingly simple concept behind all AI agents\nHow agents actually make decisions (in plain English!)\nHow to build your own simple agent with just a few lines of code\nWhy most frameworks overcomplicate what's actually happening\nCheck out my YouTube Video on this topic:\nIn this tutorial, we'll use PocketFlow - a tiny 100-line framework that strips away \nthe complexity to show you how agents really work under the hood. Unlike other\nLLM Agents = Graphs!? My Tutorial Sparks Hacker News Debate!LLM Agents = Graphs!? My Tutorial Sparks Hacker News Debate!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial2/20\n\nframeworks that hide the important details, PocketFlow lets you see the entire sys\nat once.\nMost agent frameworks hide what's really happening behind complex abstractions\nthat look impressive but confuse beginners. PocketFlow takes a different approach\nit's just 100 lines of code that lets you see exactly how agents work!\nBenefits for beginners:\nCrystal clear: No mysterious black boxes or complex abstractions\nSee everything: The entire framework fits in one readable file\nLearn fundamentals: Perfect for understanding how agents really operate\nNo baggage: No massive dependencies or vendor lock-in\nInstead of trying to understand a gigantic framework with thousands of files,\nPocketFlow gives you the fundamentals so you can build your own understanding \nthe ground up.\nImagine our agent system like a kitchen:\nNodes are like different cooking stations (chopping station, cooking station,\nplating station)\nFlow is like the recipe that tells you which station to go to next\nShared store is like the big countertop where everyone can see and use the\ningredients\nIn our kitchen (agent system):\n1. Each station (Node) has three simple jobs:\nPrep: Grab what you need from the countertop (like getting ingredients)\nWhy Learn Agents with PocketFlow?\nThe Simple Building Blocks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial3/20\n\nExec: Do your special job (like cooking the ingredients)\nPost: Put your results back on the countertop and tell everyone where to g\nnext (like serving the dish and deciding what to make next)\n2. The recipe (Flow) just tells you which station to visit based on decisions:\n\"If the vegetables are chopped, go to the cooking station\"\n\"If the meal is cooked, go to the plating station\"\nLet's see how this works with our research helper!\nAn LLM (Large Language Model) agent is basically a smart assistant (like ChatGP\nbut with the ability to take actions) that can:\n1. Think about what to do next\n2. Choose from a menu of actions\n3. Actually do something in the real world\n4. See what happened\n5. Think again...\nThink of it like having a personal assistant managing your tasks:\n1. They review your inbox and calendar to understand the situation\n2. They decide what needs attention first (reply to urgent email? schedule a\nmeeting?)\n3. They take action (draft a response, book a conference room)\n4. They observe the result (did someone reply? was the room available?)\n5. They plan the next task based on what happened\nHere's the mind-blowing truth about agents that frameworks overcomplicate:\nWhat's an LLM Agent (In Human Terms)?\nThe Big Secret: Agents Are Just Simple Graphs!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial4/20\n\nThat's it! Every agent is just a graph with:\n1. A decision node that branches to different actions\n2. Action nodes that do specific tasks\n3. A finish node that ends the process\n4. Edges that connect everything together\n5. Loops that bring execution back to the decision node\nNo complex math, no mysterious algorithms - just nodes and arrows! Everything e\nis just details. If you dig deeper, you’ll uncover these hidden graphs in overcomplic\nframeworks:\nOpenAI Agents: run.py#L119 for a workflow in graph.\nPydantic Agents: _agent_graph.py#L779 organizes steps in a graph.\nLangchain: agent_iterator.py#L174 demonstrates the loop structure.\nLangGraph: agent.py#L56 for a graph-based approach.\nLet’s see how the graph actually works with a simple example.\nLet's Build a Super Simple Research Agent\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial5/20\n\nImagine we want to build an AI assistant that can search the web and answer\nquestions - similar to tools like Perplexity AI, but much simpler. We want our agen\nbe able to:\n1. Read a question from a user\n2. Decide if it needs to search for information\n3. Look things up on the web if needed\n4. Provide an answer once it has enough information\nLet's break down our agent into individual \"stations\" that each handle one specifi\njob. Think of these stations like workers on an assembly line - each with their own\nspecific task.\nHere's a simple diagram of our research agent:\nIn this diagram:\n1. DecideAction is our \"thinking station\" where the agent decides what to do ne\n2. SearchWeb is our \"research station\" where the agent looks up information\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial6/20\n\n3. AnswerQuestion is our \"response station\" where the agent creates the final\nanswer\nImagine you asked our agent: \"Who won the 2023 Super Bowl?\"\nHere's what would happen step-by-step:\n1. DecideAction station:\nLOOKS AT: Your question and what we know so far (nothing yet)\nTHINKS: \"I don't know who won the 2023 Super Bowl, I need to search\"\nDECIDES: Search for \"2023 Super Bowl winner\"\nPASSES TO: SearchWeb station\n2. SearchWeb station:\nLOOKS AT: The search query \"2023 Super Bowl winner\"\nDOES: Searches the internet (imagine it finds \"The Kansas City Chiefs wo\nSAVES: The search results to our shared countertop\nPASSES TO: Back to DecideAction station\n3. DecideAction station (second time):\nLOOKS AT: Your question and what we know now (search results)\nTHINKS: \"Great, now I know the Chiefs won the 2023 Super Bowl\"\nDECIDES: We have enough info to answer\nPASSES TO: AnswerQuestion station\n4. AnswerQuestion station:\nLOOKS AT: Your question and all our research\nDOES: Creates a friendly answer using all the information\nSAVES: The final answer\nFINISHES: The task is complete!\nBefore We Code: Let's Walk Through an Example\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial7/20\n\nThis is exactly what our code will do - just expressed in programming language.\nLet's build each of these stations one by one and then connect them together!\nThe DecideAction node is like the \"brain\" of our agent. Its job is simple:\n1. Look at the question and any information we've gathered so far\n2. Decide whether we need to search for more information or if we can answer n\nLet's build it step by step:\nFirst, we created a prep method that gathers information. Think of prep like a ch\ngathering ingredients before cooking. All it does is look at what we already know (\n\"context\") and what question we're trying to answer.\nNow, let's build the \"thinking\" part:\nStep 1: Building Our First Node: DecideAction 樂\nclass DecideAction(Node):\n    def prep(self, shared):\n        # Think of \"shared\" as a big notebook that everyone can read a\nwrite in\n        # It's where we store everything our agent knows\n        # Look for any previous research we've done (if we haven't \nsearched yet, just note that)\n        context = shared.get(\"context\", \"No previous search\")\n        # Get the question we're trying to answer\n        question = shared[\"question\"]\n        # Return both pieces of information for the next step\n        return question, context\n    def exec(self, inputs):\n        # This is where the magic happens - the LLM \"thinks\" about wha\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial8/20\n\nto do\n        question, context = inputs\n        # We ask the LLM to decide what to do next with this prompt:\n        prompt = f\"\"\"\n### CONTEXT\nYou are a research assistant that can search the web.\nQuestion: {question}\nPrevious Research: {context}\n### ACTION SPACE\n[1] search\n  Description: Look up more information on the web\n  Parameters:\n    - query (str): What to search for\n[2] answer\n  Description: Answer the question with current knowledge\n  Parameters:\n    - answer (str): Final answer to the question\n## NEXT ACTION\nDecide the next action based on the context and available actions.\nReturn your response in this format:\n```yaml\nthinking: |\n    <your step-by-step reasoning process>\naction: search OR answer\nreason: <why you chose this action>\nsearch_query: <specific search query if action is search>\n```\"\"\"\n        # Call the LLM to make a decision\n        response = call_llm(prompt)\n        # Pull out just the organized information part from the LLM's \nanswer\n        # (This is like finding just the recipe part of a cooking vide\n        yaml_str = response.split(\"```yaml\")[1].split(\"```\")[0].strip(\n        decision = yaml.safe_load(yaml_str)  # Convert the text into a\nformat our program can use\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial9/20\n\nThe exec method is where the actual \"thinking\" happens. Think of it like the che\ncooking the ingredients. Here, we:\n1. Create a prompt that explains the current situation to the LLM\n2. Ask the LLM to decide whether to search or answer\n3. Parse the response to get a clear decision\nFinally, let's save the decision and tell the flow what to do next:\nThe post method is where we save results and decide what happens next. Think o\nlike the chef serving the food and deciding what dish to prepare next. We save the\nsearch query if needed, and then return either \"search\" or \"answer\" to tell our flow\nwhich node to visit next.\nThe SearchWeb node is our \"researcher.\" Its only job is to:\n1. Take a search query\n2. Look it up (in this simple example, we'll fake the results)\n3. Save what it finds\n4. Tell the agent to decide what to do with this new information\n        return decision\n    def post(self, shared, prep_res, exec_res):\n        # If the LLM decided to search, save the search query\n        if exec_res[\"action\"] == \"search\":\n            shared[\"search_query\"] = exec_res[\"search_query\"]\n        # Return which action to take - this tells our flow where to g\nnext!\n        return exec_res[\"action\"]  # Will be either \"search\" or \"answe\nStep 2: Building Our Second Node: SearchWeb \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial10/20\n\nLet's build it:\nThe prep method here just grabs the search query that was saved by the DecideA\nnode.\nThe exec method connects to a search API, sends the query, and formats the resu\nIn a real implementation, you would need to sign up for a search API service like\nclass SearchWeb(Node):\n    def prep(self, shared):\n        # Simply get the search query we saved earlier\n        return shared[\"search_query\"]\n    def exec(self, search_query):\n        # This is where we'd connect to Google to search the internet\n        # Set up our connection to Google\n        search_client = GoogleSearchAPI(api_key=\"GOOGLE_API_KEY\")\n        # Set search parameters\n        search_params = {\n            \"query\": search_query,\n            \"num_results\": 3,\n            \"language\": \"en\"\n        }\n        # Make the API request to Google\n        results = search_client.search(search_params)\n        # Format the results into readable text\n        formatted_results = f\"Results for: {search_query}\\n\"\n        # Process each search result\n        for result in results:\n            # Extract the title and snippet from each result\n            formatted_results += f\"- {result.title}: {result.snippet}\\\n        return formatted_results\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial11/20\n\nGoogle Custom Search API and get your own API key.\nThe post method saves our search results by adding them to our shared context. T\nit returns \"decide\" to tell our flow to go back to the DecideAction node so it can th\nabout what to do with this new information.\nThe AnswerQuestion node is our \"responder.\" Its job is simply to:\n1. Take all the information we've gathered\n2. Create a friendly, helpful answer\n3. Save that answer for the user\nLet's build it:\nThe prep method gathers both the original question and all the research we've\ncollected.\n    def post(self, shared, prep_res, exec_res):\n        # Store the search results in our shared whiteboard\n        previous = shared.get(\"context\", \"\")\n        shared[\"context\"] = previous + \"\\n\\nSEARCH: \" + \nshared[\"search_query\"] + \"\\nRESULTS: \" + exec_res\n        # Always go back to the decision node after searching\n        return \"decide\"\nStep 3: Building Our Third Node: AnswerQuestion \nclass AnswerQuestion(Node):\n    def prep(self, shared):\n        # Get both the original question and all the research we've do\n        return shared[\"question\"], shared.get(\"context\", \"\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial12/20\n\nThe exec method asks the LLM to create a helpful answer based on our research.\nThe post method saves the final answer and returns \"done\" to indicate that our fl\nis complete.\nNow for the fun part - we need to connect all our nodes together to create a workin\nagent!\n    def exec(self, inputs):\n        question, context = inputs\n        # Ask the LLM to create a helpful answer based on our research\n        prompt = f\"\"\"\n### CONTEXT\nBased on the following information, answer the question.\nQuestion: {question}\nResearch: {context}\n## YOUR ANSWER:\nProvide a comprehensive answer using the research results.\n\"\"\"\n        return call_llm(prompt)\n    def post(self, shared, prep_res, exec_res):\n        # Save the answer in our shared whiteboard\n        shared[\"answer\"] = exec_res\n        # We're done! No need to continue the flow.\n        return \"done\"\nStep 4: Connecting Everything Together! \n# First, create instances of each node\ndecide = DecideAction()\nsearch = SearchWeb()\nanswer = AnswerQuestion()\n# Now connect them together - this is where the magic happens!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial13/20\n\nThat's it! We've connected our nodes into a complete flow that can:\n1. Start by deciding what to do\n2. Search for information if needed\n3. Loop back to decide if we need more information\n4. Answer the question when we're ready\nThink of it like a flowchart where each box is a node, and the arrows show where t\nnext based on decisions made along the way.\nNow let's see our agent in action:\n# Each connection defines where to go based on the action returned by \npost()\n# If DecideAction returns \"search\", go to SearchWeb\ndecide - \"search\" >> search\n# If DecideAction returns \"answer\", go to AnswerQuestion\ndecide - \"answer\" >> answer\n# After SearchWeb completes, go back to DecideAction\nsearch - \"decide\" >> decide\n# Create our flow, starting with the DecideAction node\nflow = Flow(start=decide)\nLet's Run Our Agent! \n# Create a shared whiteboard with just a question\nshared = {\"question\": \"What is the capital of France?\"}\n# Run our flow!\nflow.run(shared)\n# Print the final answer\nprint(shared[\"answer\"])\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial14/20\n\nHere's what happens when our agent runs:\nFirst, our agent thinks about the question:\nOur agent decides it doesn't know enough yet, so it needs to search for informatio\nThe SearchWeb node now searches for \"capital of France\" and gets these results:\nIt saves these results to our shared context.\nOur agent looks at the question again, but now it has some search results:\nFirst Round: The Initial Decision 樂\nthinking: |\n  The question is asking about the capital of France. I don't have any\nprior search results to work with.\n  To answer this question accurately, I should search for information \nabout France's capital.\naction: search\nreason: I need to look up information about the capital of France\nsearch_query: capital of France\nSecond Round: Searching the Web \nResults for: capital of France\n- The capital of France is Paris\n- Paris is known as the City of Light\nThird Round: The Final Decision 樂\nthinking: |\n  Now I have search results that clearly state \"The capital of France \nParis\".\n  This directly answers the question, so I can provide a final answer.\naction: answer\nreason: I now have the information needed to answer the question\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial15/20\n\nThis time, our agent decides it has enough information to answer!\nFinally, the AnswerQuestion node generates a helpful response:\nAnd we're done! Our agent has successfully:\n1. Realized it needed to search for information\n2. Performed a search\n3. Decided it had enough information\n4. Generated a helpful answer\nFourth Round: Answering the Question \nThe capital of France is Paris, which is also known as the City of \nLight.\nThe Whole Process Visualized:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial16/20\n\nIf you’re technically inclined and want to read or experiment with the complete co\nfor this tutorial, you can find it here!\nYou can also see how this same loop-and-branch pattern appears in larger framew\nby checking out these snippets:\nOpenAI Agents: run.py#L119 for a workflow in graph.\nPydantic Agents: _agent_graph.py#L779 organizes steps in a graph.\nLangchain: agent_iterator.py#L174 demonstrates the loop structure.\nLangGraph: agent.py#L56 for a graph-based approach.\nNow you know the secret - LLM agents are just loops with branches:\nDive Deeper: Explore the Code & Beyond\nConclusion: The Secret to Understanding Agents\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial17/20\n\n1. Think about the current state\n2. Branch by choosing one action from multiple options\n3. Do the chosen action\n4. Get results from that action\n5. Loop back to think again\nThe \"thinking\" happens in the prompt (what we ask the LLM), the \"branching\" is\nwhen the agent chooses between available tools, and the \"doing\" happens when w\ncall external functions. Everything else is just plumbing!\nNext time you see a complex agent framework with thousands of lines of code,\nremember this simple pattern and ask yourself: \"Where are the decision branches \nloops in this system?\"\nArmed with this knowledge, you'll be able to understand any agent system, no mat\nhow complex it may seem on the surface.\nWant to learn more about building simple agents? Check out PocketFlow on GitHub!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n100 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial18/20\n\n5 more comments...\nWrite a comment...\nMar 22\nEdited\nLiked by Zachary Huang\n1 reply by Zachary Huang\nSolaris\nPocket Flow examples design documents are really detailed. As a software engineer, writing\nan important best practice that helps understand and consider the implementation thorough\nthis approach is especially needed for critical thinking / productive reviews of what the LLM \ndeveloping, so its great to see them as part of Pocketʼs workflow. Thank you for the excellen\n\nLIKE (2)REPLY\nMay 11\nLiked by Zachary Huang\n2 replies by Zachary Huang and others\nG K\nHey, great post and framework!\nI just started to work with pocketflow and it seems to be really easy to maintain consistency.\nI do have a quick question, though:\nHow does Pocketflow differ from LangGraph, aside from LangGraph having extra features lik\nLangGraph Platform?\nOther than being easy to maintain, what are some other advantages of using Pocketflow ove\nLangGraph?\nLIKE (1)REPLY\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial19/20\n\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:57 PMLLM Agents are simply Graph — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/llm-agent-internal-as-a-graph-tutorial20/20"
  },
  {
    "filename": "PocketBlog250322.pdf",
    "title": "Agentic Coding: Let Agents Build Agents for yo",
    "date": "2025-03-22",
    "content": "\n\nAgentic Coding: Let Agents Build Agents for yo\nMAR 22, 2025\n12Sh\nWe all know AI agents are the future, but why build them by hand when AI agents coul\nbuild them themselves for us? Imagine a world where you simply design the blueprint a\nAI agents construct the AI agents themselves—this is Agentic Coding, where humans f\non creative, high-level design while AI agents handle all the tedious implementation de\nHave you ever wished you could just explain your app design and watch it come to\nlife? That’s the promise of Agentic Coding:\nZACHARY HUANG\n45\nWhat is Agentic Coding?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to1/23\n\nYou do what humans are best at: coming up with creative ideas and designing\nyour app should work\nAI does what it’s best at: writing the detailed code to make your ideas actually\nwork\nNow, this is possible! For instance, in the image below, you can see the agentic cod\nprocess in action. On the left side, a human designs the system for an AI app, focu\non high-level architecture and data flow. On the right side, with just a simple prom\nlike “Start Agentic Coding! Implement based on this design doc and add enough\nlogging for us to keep track,” the AI writes all the code with remarkable ease and\nprecision.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nAgentic coding in action\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to2/23\n\nThink of it like building a house — you’re the architect drawing the blueprint, and AI is\nconstruction crew doing the detailed work. You focus on the vision; AI handles the execu\nFor the past year, I’ve been trying to build AI apps using existing frameworks like\nLangChain. The experience has been frustrating for both me and the AI assistants\ntrying to help me:\nAbstractions upon abstractions — The fundamental problem with framework\nlike LangChain is abstraction overload. As Octomind’s engineering team explai\n“LangChain was helpful at first when our simple requirements aligned with its usage\npresumptions. But its high-level abstractions soon made our code more difficult to\nunderstand and frustrating to maintain.” These complex layers of code hide simp\nfunctionality behind unnecessary complexity.\nImplementation nightmares — Beyond unnecessary abstractions, these\nframeworks burden developers with dependency bloat, version conflicts, and\nconstantly changing interfaces. As developers note: “It’s unstable, the interface\nconstantly changes, the documentation is regularly out of date.” Another developer\njokes: “In the time it took to read this sentence langchain deprecated 4 classes witho\nupdating documentation.”\nWhy Current AI Building Tools Fall\nShort\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to3/23\n\nIt’s not the AI assistant’s fault — many of these frameworks are so complex that even hu\ndevelopers have trouble using them!\nAfter a year of struggle, I created Pocket Flow — a tiny framework (just 100 lines o\ncode!) that captures everything you need without the complexity. The magic happe\nwhen Pocket Flow’s simplicity meets AI agents:\nIntroducing Pocket Flow: Simple by\nDesign\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to4/23\n\nCrystal clear concepts — Simple building blocks that any AI agents can\nunderstand\nZero bloat — No vendor lock-in or mysterious dependency issues\nPerfect division of labor — You design the high-level flow, AI implements th\ndetails\nMy personal journey with frameworks like LangChain taught me that the more\ncomplex the framework, the harder it is for AI to help. Pocket Flow was born from\nrealization — designed specifically to create the perfect division of labor between\nhuman designers and AI implementers.\nWhen your AI agents aren’t fighting to understand a complex framework, they can focus\nimplementing your vision correctly.\nThis tutorial focuses specifically on setting up your environment for Agentic Coding wi\nPocket Flow. For details on implementation and how to use Pocket Flow, please refer t\nofficial documentation.\nThe fastest Development Paradigm in 2025\nWhether you’re building your first chatbot or a complex system, this guide will hel\nyou set up the perfect environment for Agentic Coding with Pocket Flow.\nFor quick questions about Pocket Flow:\nRecommended Setup: GPT Assistant\nSetup Steps: Use the GPT Assistant. No setup required, but not ideal for\ncoding.\nFor brainstorming or prototyping:\nGetting Started with Agentic Coding:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to5/23\n\nRecommended Setup: ChatGPT or Claude Project\nSetup Steps: Create a ChatGPT Project or a Claude Project, and upload th\ndocs for reference.\nFor full application development:\nRecommended Setup: Cursor AI, Windsurf, Cline\nSetup Steps: Create a new project using the project template. The .cursorr\nfile teaches AI agents how to use Pocket Flow.\nNote: This list covers the most common setup, but options are changing frequently as n\nAI coding agents emerge. The core principle remains the same: because Pocket Flow is\nsimple and minimal, any AI agent can quickly understand it just by reading the\ndocumentation. Simply share the Pocket Flow docs with your preferred AI agent to get\nstarted!\nLooking for the fastest way to learn about Pocket Flow? The Pocket Flow GPT\nAssistant is your instant knowledge companion! With zero setup required, you can\nimmediately ask questions about Pocket Flow and receive thoughtful answers with\nseconds. It’s like having a Pocket Flow expert on standby 24/7.\nGPT Assistant: Instant Answers at Yo\nFingertips\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to6/23\n\nKeep in mind that while perfect for learning and quick questions, the GPT Assista\nisn’t ideal for implementation work as it’s using an older model (likely GPT-4o). Fo\nactual coding and building, you’ll want to explore the more powerful development\noptions below.\nFor One-time Tasks: Brainstorm and\nPrototype\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to7/23\n\nHave a quick idea that you want to brainstorm or prototype, but aren’t ready for fu\nimplementation? ChatGPT and Claude Projects are good options!\n1. Open ChatGPT and create a Project\n2. Feed it knowledge by uploading the md files in Pocket Flow docs.\na. ChatGPT Project allows at most 20 files. Please exclude _config.yml,\nutility_function/index.md, design_pattern/index.md, utility_function/index.md a\nunder utility_function/, only upload utility_function/llm.md.\nWith ChatGPT:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to8/23\n\n3. Set the system prompt to be something like:\nIf a user asks you to build an AI app:\n1. In Canvas: Start by creating the design using Markdown. Think \ncarefully and thoroughly. Strictly follow the playbook. Note that \nMermaid diagrams can't be rendered, so use a ```text block instead.\n2. Confirm the design with the user before writing any code.\n3. Start writing code. You can assume packages including pocketflow ar\ninstalled.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to9/23\n\n4. Start a conversation! For example: “Help me build a chatbot for a directory of PD\nFor the best result, please choose the best model like O1.\nIt is highly recommended to enable Canvas\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to10/23\n\n5. Verify and improve the high-level system design, then ask it to implement the c\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to11/23\n\n1. Head to Claude and start a new Project\n2. Feed it knowledge by uploading the md files under Pocket Flow docs. Please\nexclude _config.yml, utility_function/index.md, design_pattern/index.md, and\nutility_function/index.md.\nWith Claude:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to12/23\n\n3. Set the system prompt to be something like:\nIf a user asks you to build an AI app: \n1. In Artifact: Start by creating the design using Markdown using \nmermaid. Think carefully and thoroughly. Strictly follow the guide.md.\n2. Confirm the design with the user before writing any code. \n3. Start writing code. You can assume packages including pocketflow ar\ninstalled.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to13/23\n\n4. Start a conversation! For example: “Help me build a chatbot for a directory of PD\nFor the best result, please choose the best model like Sonnet-3.7 with extended\nthinking.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to14/23\n\n5. Verify and improve the high-level system design, then ask it to implement the c\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to15/23\n\nReady to build a production-ready application? This is where the real magic of Ag\nCoding happens:\n1. Create a New Window, and click on the Clone Repo.\n2. Enter the URL for the ready-to-use Pocket Flow Template:\nhttps://github.com/The-Pocket/PocketFlow-Template-Python.\nThis template includes a special .cursorrules file that teaches Cursor AI how t\nwork with Pocket Flow\nFor Serious Development: The Full\nAgentic Coding Experience\nCursor AI:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to16/23\n\n3. You can verify the setup by asking Cursor AI: “What is Pocket Flow?”\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to17/23\n\n4. Start building LLM systems!\nPro Tip: Use Chat mode during the design phase to avoid the AI getting ahead of\nitself, then switch to Agent mode during implementation.\n1. Create a New Window, click on the Explorer side bar icon, then Clone\nRepository.\n2. Enter the URL for the ready-to-use Pocket Flow Template:\nhttps://github.com/The-Pocket/PocketFlow-Template-Python.\nThis template includes a special .windsurfrules file that teaches Windsurf how\nwork with Pocket Flow\nWindsurf:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to18/23\n\n3. You can verify the setup by asking Windsurf AI: “What is Pocket Flow?”\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to19/23\n\n4. Start building LLM systems!\nPro Tip: Use Chat mode during the design phase to avoid the AI getting ahead of\nitself, then switch to Write mode during implementation.\nNote: As of March 2025, Cline’s Agent doesn’t work that well with rule files. This secti\nwill be updated as compatibility improves.\n1. Create a New Window, and click on the Clone Git Repository....\n2. Enter the URL for the ready-to-use Pocket Flow Template:\nhttps://github.com/The-Pocket/PocketFlow-Template-Python.\nThis template includes a special .clinerules file that teaches Cline how to work\nwith Pocket Flow\n3. You can verify the setup by asking Cline AI: “Answer based on environment det\nWhat’s Pocket Flow?”\nCline:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to20/23\n\n4. Start building LLM systems!\nPro Tip: Use Chat mode during the design phase to avoid the AI getting ahead of\nitself, then switch to Write mode during implementation.\nOnce you’ve set up your environment, the next step is understanding the Agentic\nCoding workflow.\nMore tutorials coming soon! Stay tuned! In the meanwhile, check out these resour\nAgentic Coding Guidance — Official documentation\nThe Pocket GitHub — Example projects\nPocket Flow YouTube Tutorials — Step-by-step visual guides\nWhatʼs Next?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to21/23\n\nFor more examples and detailed documentation, visit the Pocket Flow GitHub.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n45 Likes\nDiscussion about this post\nPreviousNext\nWrite a comment...\nMar 22\nEdited\nLiked by Zachary Huang\n1 reply by Zachary Huang\nSolaris\nPocket Flow examples design documents are really detailed. As a software engineer, writing\nan important best practice that helps understand and consider the implementation thorough\nthis approach is especially needed for critical thinking / productive reviews of what the LLM \ndeveloping, so its great to see them as part of Pocketʼs workflow. Thank you for the excellen\n\nLIKE (2)REPLY\nMay 11\nLiked by Zachary Huang\nG K\nHey, great post and framework!\nI just started to work with pocketflow and it seems to be really easy to maintain consistency.\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to22/23\n\n10 more comments...\n2 replies by Zachary Huang and others\nI do have a quick question, though:\nHow does Pocketflow differ from LangGraph, aside from LangGraph having extra features lik\nLangGraph Platform?\nOther than being easy to maintain, what are some other advantages of using Pocketflow ove\nh\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:56 PMAgentic Coding: Let Agents Build Agents for you!\nhttps://pocketflow.substack.com/p/agentic-coding-the-most-fun-way-to23/23"
  },
  {
    "filename": "PocketBlog250324.pdf",
    "title": "Build AI Agent Memory From Scratch — Tutoria",
    "date": "2025-03-24",
    "content": "\n\nBuild AI Agent Memory From Scratch — Tutoria\nFor Dummies\nMAR 24, 2025\n11Sh\nEver wondered why some chatbots remember your name days later, while others forget \nyou said 5 minutes ago? This guide explains AI memory in super simple terms — no te\nbackground needed!\nHave you ever told a chatbot your name, only for it to ask again in the same\nconversation? Or been surprised when it remembered your birthday weeks later? L\nbreak down how AI memory actually works — the simple truth!\nGreat news: it’s way easier than you think! In this super-friendly guide, you’ll\ndiscover:\nZACHARY HUANG\n19\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch1/21\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThe shockingly simple trick behind AI memory\nHow chatbots keep track of what you’ve told them\nWhy good memory makes the difference between helpful and frustrating AI\nFor this guide, we’ll use Pocket Flow — a tiny framework (just 100 lines!) that cuts\nthrough all the fancy jargon to show you how AI memory really works. While most\ntools hide all the important stuff under complicated code, PocketFlow puts everyth\nright in front of you so you can actually understand it.\nWant to see the working code? You can check out and run the complete implementation\nGitHub: PocketFlow Chat Memory.\nMost AI tools are like pre-built furniture with hidden screws and hard-to-read\ninstructions. Pocket Flow is different — it’s like a simple DIY starter kit with just \nlines of code that includes only the essential tools you need to build something rea\nand useful!\nWhat makes this perfect for learning:\nBasic tools only: Just the essential tools you actually need, not a confusing\nworkshop full of advanced equipment\nClear instructions: Every step is visible and understandable, like a DIY tutori\nwith pictures for each step\nExpand at your own pace: Start simple, then add more advanced features whe\nyou’re comfortable\nWhy Learn Memory with Pocket Flow?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch2/21\n\nThat’s it! Everything else is just details around these core concepts.\nImagine your AI as a bustling coffee shop. PocketFlow provides the following\nbuilding blocks:\nNodes are like different stations (taking orders, checking recipes, brewing coff\narchiving receipts).\nFlow is like the daily routine that keeps each station running smoothly.\nShared Store is like your master order binder, keeping track of all current ord\nrecipes, and past receipts.\nIn our coffee shop system:\n1. Each station (Node) has three simple jobs:\nPrep: Gather what you need (like the right cup or recipe).\nExec: Perform the main task (like brewing the drink).\nPost: Update the binder and decide what to do next (like archiving an old rece\n2. The shop’s routine (Flow) moves between stations based on needs:\n“If we need a recipe, look it up in the binder.”\n“If we have too many orders on the counter, move some receipts to the archive\nThe Simple DIY Kit from Pocket Flow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch3/21\n\nThink of AI memory like a simple note-taking system:\nShort-term memory: “Sticky notes” on your desk for recent info.\nLong-term memory: A “filing cabinet” for older info sorted by topic.\nRetrieval: Flipping through that cabinet to find what you need.\nJust as you’d forget details if you never wrote them down, an AI forgets unless it\nsystematically stores and retrieves information. To handle lots of older messages\nwithout losing track, an AI might use embeddings or summaries. Imagine you have a\nof vacation photos:\nEmbeddings are like giving each photo a “fingerprint” that captures what’s in\n— so later, if you search for “beach,” you can quickly pull out all the beach pho\nSummaries work like writing “cliff notes” on the back of each picture (“family\nthe beach in Maui”), then reading those notes to decide which photo to grab.\nWhat is Memory in Easy Terms?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch4/21\n\nBoth methods help the AI skip flipping through every word, either by matching\n“fingerprints” (embeddings) or by checking short “cliff notes” (summaries) to insta\nrecall the details. In this tutorial, we will focus on embeddings.\nWant to see these methods in action? Frameworks like LangChain provide:\nConversation Buffer Window\nConversation Summary Memory\nVector Store Retriever Memory\nFeeling intimidated? No worries — we’ll walk through simple examples with mini\nrunnable code in Pocket Flow.\nLet’s break down what we need to build our memory system:\nHow to DIY Memory from Scratch?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch5/21\n\nSelf-Loop Flow: Think of this as the librarian’s daily routine. They listen to\nquestions, check references, answer patrons, and file away old materials — th\nstart over with the next visitor.\nShared Store: Like the library’s central information system, with both the ope\ndesk (short-term memory for current questions) and archive room (long-term\nmemory for older topics).\nPicture a library customer service desk. It’s a continuous loop where information fl\nbetween you, the librarian, and the archive shelves.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch6/21\n\n1. Question Node: The front desk librarian jots down your question.\n2. Retrieve Node: The librarian checks the catalog and archived collections.\n3. Answer Node: The librarian uses the found resources to help you.\n4. Embed Node: The archivist who labels and files older notes.\nNo fancy math — just a neat loop that keeps all your conversations at your fingert\nLet’s see how our “librarian” handles a real conversation over time:\nDay 1: You mention your pet\n1. You tell the librarian: “I have a golden retriever named Max who loves to play\nfetch.”\n2. The librarian jots this down in a “current notes” binder at the front desk.\n3. You chat about a few other things.\n4. Eventually, once there are too many notes, the librarian moves some details to\narchive shelves in the back.\n5. To make it easier to find later, the librarian files the note about “golden retriev\nMax, fetch” under a special topic label (an “embedding”).\n6. Now it’s safely stored in the archive for long-term reference.\nA week later: You ask about your dog\n1. You return and ask: “What was my dog’s name again?”\n2. The librarian writes your question down and assigns it a topic label.\n3. They check the archive shelves for any labels matching “dog,” “golden retrieve\nor “Max.”\n4. They find the original note about your golden retriever, Max.\nBefore We Code: Letʼs Walk Through\nthe Librarian Example\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch7/21\n\n5. They bring that note to the front desk.\n6. The librarian says: “Your dog’s name is Max. He’s a golden retriever who loves\nplay fetch.”\nIt feels like real remembering because:\nThe librarian initially organized your info before putting it away.\nThey used a topic-based label (embedding) for archiving.\nWhen you asked again, they looked up that label, retrieved the note, and\ncombined it with your current question to give a complete answer.\nNow let’s build such a librarian-inspired memory system from scratch!\nFollowing along with the code? You can find the complete working implementation of th\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch8/21\n\nmemory components at GitHub: PocketFlow Chat Memory to explore the details.\nThe Shared Store is our single “source of truth” for everything your AI needs to\nremember. It’s where we keep both short-term details (like the most recent\nconversation) and long-term archives (where older chats get embedded and indexe\n1. messages: Acts like short-term memory, holding recent user and assistant\nmessages.\n2. vector_index: A data structure (like a search index) for retrieving conversation\n“topic fingerprint.”\n3. vector_items: A list of older, archived chats plus their embeddings, so they can\npulled back into the conversation.\nAll our Nodes (Question, Retrieve, Answer, Embed) will read and write from this\ndictionary, keeping everything in sync. That’s the beauty of a single “notebook” fo\nyour AI’s memory!\nStep 1: Set Up the Shared Store\n# Shared store: a simple dictionary to hold everything\nshared = {\n  # Short-term memory: your \"sticky notes\" for the current conversatio\n  \"messages\": [],\n  # Long-term memory: the \"filing cabinet\" that stores archived chats\n  \"vector_index\": None,   # a placeholder for an index structure\n  \"vector_items\": []      # a list of archived conversations\n}\nStep 2: Define Each Node\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch9/21\n\nFor the prep: Like a librarian opening a fresh notebook page. We create a pla\nstore our conversation if none exists yet.\nFor the exec: Our librarian asks \"How can I help you?\" and waits for your\nquestion. If you say \"exit,\" we close up shop.\nFor the post: The librarian writes your question in the log book. If you said\n\"exit,\" we say goodbye. Otherwise, we save your message and move on to chec\nour records.\na. Question Node — Receives user inp\nand adds it to short-term memory\ndef prep(self, shared):\n    if \"messages\" not in shared:\n        shared[\"messages\"] = []\n        print(\"Welcome to the interactive chat!\")\n    return None\ndef exec(self, _):\n    user_input = input(\"\\nYou: \")\n    # If user types \"exit\", we'll stop the conversation\n    if user_input.strip().lower() == \"exit\":\n        return None\n    return user_input\ndef post(self, shared, prep_res, exec_res):\n    # If exec_res is None, the user wants to exit\n    if exec_res is None:\n        print(\"Goodbye!\")\n        return None  # No more nodes to call (end of flow)\n    # Otherwise, we add their message to our short-term list\n    shared[\"messages\"].append({\"role\": \"user\", \"content\": exec_res\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch10/21\n\nFor the prep: Our librarian reads your latest question and checks if we have a\narchives to search. If either is missing, we skip this step.\nFor the exec: Our librarian creates a \"topic card\" for your question and searc\nthe archives for the closest match – like finding which file cabinet might cont\ninformation about \"golden retrievers.\"\n    # Then decide the next node to call. Usually a RetrieveNode.\n    return \"retrieve\"\nb. Retrieve Node — Searches the\narchives for relevant info\ndef prep(self, shared):\n    if not shared.get(\"messages\"):\n        return None\n   # Find the most recent user message\n    latest_user_msg = next(\n        (msg for msg in reversed(shared[\"messages\"]) if msg[\"role\"\n== \"user\"), \n        None\n    )\n    # Check if we have a vector index (where archived items are \nstored)\n    if \"vector_index\" not in shared or not shared[\"vector_index\"]:\n        return None\n    # Return everything we need for the retrieval step\n    return {\n        \"query\": latest_user_msg[\"content\"] if latest_user_msg els\n\"\",\n        \"vector_index\": shared[\"vector_index\"],\n        \"vector_items\": shared.get(\"vector_items\", [])\n    }\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch11/21\n\nFor the post: Our librarian keeps any relevant file they found on the desk. Eit\nway, we proceed to formulating an answer.\ndef exec(self, inputs):\n    if not inputs:\n        return None\n    query = inputs[\"query\"]\n    vector_index = inputs[\"vector_index\"]\n    vector_items = inputs[\"vector_items\"]\n    # (Pseudo) Create an embedding for the query\n    # real code might call an external embedding function\n    query_embedding = get_embedding(query)  \n    # Search the archived items for a match\n    best_match, best_distance = search_vectors(vector_index, \nquery_embedding)\n    # If nothing is found, return None\n    if best_match is None:\n        return None\n    # Return the best matching conversation and distance\n    return {\n        \"conversation\": vector_items[best_match],\n        \"distance\": best_distance\n    }\ndef post(self, shared, prep_res, exec_res):\n    if exec_res is None:\n        # No relevant info found; we just move on\n        shared[\"retrieved_conversation\"] = None\n    else:\n        # Save the retrieved conversation so the Answer Node can u\nit\n        shared[\"retrieved_conversation\"] = exec_res[\"conversation\"\n    # Continue to the Answer Node\n    return \"answer\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch12/21\n\nFor the prep: Our librarian gathers all needed resources: recent conversation\nnotes and any relevant archived files, arranging them for easy reference.\nFor the exec: With all information at hand, our librarian crafts a thoughtful\nresponse that incorporates both recent and past knowledge.\nc. Answer Node — Combines new and\nold info to generate a response\ndef prep(self, shared):\n    # Start with the most recent messages (e.g., last few user & \nassistant turns)\n    recent_messages = shared.get(\"messages\", [])\n    # Optionally add retrieved data\n    retrieved_conv = shared.get(\"retrieved_conversation\")\n    # Combine them into a single context packet\n    context = []\n    if retrieved_conv:\n        # Mark this as a 'system' note indicating it's relevant \nbackground\n        context.append({\"role\": \"system\", \"content\": \"Relevant \narchived info:\"})\n        context.extend(retrieved_conv)\n        context.append({\"role\": \"system\", \"content\": \"End of \narchived info.\"})\n    context.extend(recent_messages)\n    return context\ndef exec(self, context):\n    if not context:\n        return None\n    # Example function that sends context to an LLM\n    # In practice, you'd replace call_llm(...) with your own model \ncall\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch13/21\n\nFor the post: Our librarian writes down their answer, then decides if it's time\narchive older notes (if we have more than 6 messages) or just continue helping\nFor the prep: If our desk is getting cluttered (more than 6 messages), our libra\ntakes the oldest conversation pair and prepares it for filing.\n    response = call_llm(context)\n    return response\ndef post(self, shared, prep_res, exec_res):\n    # If there's no response, end the conversation\n    if exec_res is None:\n        return None\n    # Add the assistant's answer to our short-term memory\n    shared[\"messages\"].append({\"role\": \"assistant\", \"content\": \nexec_res})\n    # For example, if our messages are piling up, we might archive \nolder ones\n    if len(shared[\"messages\"]) > 6:\n        # We'll show how the 'archive' step works in the next node\n        return \"embed\"\n    # Otherwise, loop back to the question node for the next user \nquery\n    return \"question\"\nd. Embed (Archive) Node — Moves\nolder conversations into long-term\nmemory\ndef prep(self, shared):\n    # If we have fewer than 6 messages, there's nothing to archive\n    if len(shared.get(\"messages\", [])) <= 6:\n        return None\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch14/21\n\nFor the exec: Our librarian creates a label for the file by combining the\nconversation into one document and giving it a special \"topic fingerprint\" for\nretrieval later.\nFor the post: Our librarian files the labeled conversation in the archives, crea\na filing system if needed, then returns to the front desk ready for the next\nquestion.\n    # Extract the oldest user + assistant pair (2 messages)\n    oldest_pair = shared[\"messages\"][:2]\n    # Remove them from short-term memory\n    shared[\"messages\"] = shared[\"messages\"][2:]\n    return oldest_pair\ndef exec(self, conversation):\n    if not conversation:\n        return None\n    # Combine the user & assistant messages into one text for \nembedding\n    user_msg = next((m for m in conversation if m[\"role\"] == \n\"user\"), {\"content\": \"\"})\n    assistant_msg = next((m for m in conversation if m[\"role\"] == \n\"assistant\"), {\"content\": \"\"})\n    combined_text = f\"User: {user_msg['content']}\\nAssistant: \n{assistant_msg['content']}\"\n    # Create an embedding (pseudo-code)\n    embedding = get_embedding(combined_text)\n    return {\n        \"conversation\": conversation,\n        \"embedding\": embedding\n    }\ndef post(self, shared, prep_res, exec_res):\n    if not exec_res:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch15/21\n\nNow let’s make the system run by connecting each node into a self-loop flow and\nchoosing a starting point:\n        # Nothing to archive, just go back to questions\n        return \"question\"\n    # Initialize our archive if it's missing\n    if \"vector_index\" not in shared or shared[\"vector_index\"] is \nNone:\n        shared[\"vector_index\"] = create_index()\n        shared[\"vector_items\"] = []\n    # Add the embedding to the index\n    position = add_vector(shared[\"vector_index\"], \nexec_res[\"embedding\"])\n    # Keep track of the archived conversation itself\n    shared[\"vector_items\"].append(exec_res[\"conversation\"])\n    print(f\"✅ Archived a conversation at index position \n{position}.\")\n    print(f\"✅ Total archived: {len(shared['vector_items'])}\")\n    # Return to the question node to continue the chat\n    return \"question\"\nStep 3. Connect the Nodes in a Self-\nLoop Flow\n# Create your node instances\nquestion_node = QuestionNode()\nretrieve_node = RetrieveNode()\nanswer_node = AnswerNode()\nembed_node = EmbedNode()\n# Connect the flow:\n# Main flow path\nquestion_node - \"retrieve\" >> retrieve_node\nretrieve_node - \"answer\" >> answer_node\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch16/21\n\nAs soon as we call chat_flow.run(shared), the system:\nEnters the Question Node (prep → exec → post).\nJumps to the node name returned by the post step (“retrieve”).\nContinues through Retrieve, Answer, Embed as each node’s post method dict\nKeeps looping until a node returns None (meaning it's time to stop)\nAll the Flow class does is respect these returns — once a node finishes its post, Fl\ncalls the next node by name. If a node ever returns None, the entire conversation e\nThat's our self-loop in action:\nQuestion → Retrieve → Answer → Embed → Question → ... → None (exit)\nThat’s it! You now have a working self-loop where each node does its job — collecting u\ninput, retrieving old chats, generating answers, and archiving older messages. Once you \nthis code, your AI will “remember” and “forget” just like a neatly organized notebook\n# When we need to embed old conversations\nanswer_node - \"embed\" >> embed_node\n# Loop back for next question\nanswer_node - \"question\" >> question_node\nembed_node - \"question\" >> question_node\n# Create the flow starting with question node\nchat_flow = Flow(start=question_node)\n# Set up an empty \"notebook\"\nshared = {}\n# Start the conversation loop\nchat_flow.run(shared)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch17/21\n\nReady to run this code? Here’s how:\n1. Clone the GitHub: PocketFlow Chat Memory\n2. Set up your API key:\n3. Run the application:\nHere’s a simple example showing how your AI’s memory works in practice:\nUser: “Remember, my cat is Whiskers”\nAssistant: “Got it! I’ll keep that in mind.”\n(The system saves “Whiskers” to short-term memory.)\nUser: “What’s the weather today?”\nAssistant: “I don’t have real-time info right now, but you can check a weather app!”\n(This question doesn’t impact memory storage.)\n...\nUser: “What’s my cat’s name again?”\nAssistant: “Your cat’s name is Whiskers.”\n(The system pulls “Whiskers” from memory.)\nStep 4. Run and Test\nexport OPENAI_API_KEY=\"your-api-key-here\"\npip install -r requirements.txt\npython main.py\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch18/21\n\nBehind the Scenes (Simplified):\nShort-Term stores recent info (like the cat’s name).\nLong-Term archives older details once short-term gets full.\nFlow decides whether to use short-term or check long-term memory when you\nsomething.\nEven if you ask unrelated questions in between, the system can still recall\n“Whiskers” whenever you need it!\nAI Memory Demystified: The Simple\nSecret\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch19/21\n\nYou’ve now learned the straightforward secret behind AI memory. No fancy magic\njust smart organization and looping processes. Here’s what makes it tick:\n1. Self-Loop Flow: A simple cycle that continuously handles your input, finds re\npast info, generates helpful answers, and archives older messages.\n2. Shared Store: One organized place to hold both short-term (“sticky notes”) an\nlong-term (“filing cabinet”) memory.\n3. Memory Retrieval: Quickly finding relevant conversations from the archives w\nneeded.\n4. Contextual Responses: Combining new questions and retrieved info to form\nmeaningful answers.\nNext time you interact with an AI assistant that seems to “remember” things, you’\ninstantly recognize these simple ideas at work.\nReady to build your own AI system with memory? The complete working code for this tut\nis available at GitHub: Pocket Flow Chat Memory. Clone the repository, run the code, a\nstart experimenting with your own memory-enabled chatbot today!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n19 Likes∙1 Restack\nDiscussion about this post\nPreviousNext\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch20/21\n\n1 more comment...\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:55 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch21/21"
  },
  {
    "filename": "PocketBlog250401.pdf",
    "title": "Retrieval Augmented Generation (RAG) from",
    "date": "2025-04-01",
    "content": "\n\nRetrieval Augmented Generation (RAG) from\nScratch — Tutorial For Dummies\nAPR 01, 2025\n42Sh\nEver wondered how AI tools like ChatGPT can answer questions based on specific\ndocuments they've never seen before? This guide breaks down Retrieval Augmented\nGeneration (RAG) in the simplest possible way with minimal code implementation!\nHave you ever asked an AI a question about your personal documents and received\ncompletely made-up answer? Or maybe you've been frustrated when chatbots prov\noutdated information? These are common problems with traditional LLMs (Large\nLanguage Models), but there's a solution: Retrieval Augmented Generation (RAG\nIn this beginner-friendly tutorial, you'll learn:\nZACHARY HUANG\n20\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag1/24\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThe key concepts behind RAG systems in plain language\nHow to build a working RAG system step-by-step\nWhy RAG dramatically improves AI responses for your specific documents\nWe'll use PocketFlow - a simple 100-line framework that strips away complexity. Unlike o\nframeworks with convoluted abstractions, PocketFlow lets you see the entire system at o\ngiving you the fundamentals to build your understanding from the ground up.\nImagine RAG is like giving an AI its own personal research librarian before it answ\nyour questions. Here's how the magic happens:\n1. Document Collection: You provide your documents (company manuals, articl\nbooks) to the system, just like books being added to a library.\n2. Chunking: The system breaks these down into bite-sized, digestible pieces - l\nlibrarians dividing books into chapters and sections rather than working with\nentire volumes.\n3. Embedding: Each chunk gets converted into a special numerical format (vecto\nthat captures its meaning - similar to creating detailed index cards that\nunderstand concepts, not just keywords.\n4. Indexing: These vectors are organized in a searchable database - like a magica\ncard catalog that understands the relationships between different topics.\n5. Retrieval: When you ask a question, the system consults its index to find the m\nrelevant chunks related to your query.\nWhat's RAG (In Human Terms)?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag2/24\n\n6. Generation: The AI crafts an answer using both your question AND these hel\nreferences, producing a much better response than if it relied solely on its pre\ntrained knowledge.\nThe result? Instead of making things up or giving outdated information, the AI\ngrounds its answers in your specific documents, providing accurate, relevant\nresponses tailored to your information.\nBefore our RAG system can work effectively, we need to break our documents into\nsmaller, digestible pieces. Think of chunking like preparing a meal for guests - you\nwouldn't serve a whole turkey without carving it first!\nThe size of your chunks directly impacts the quality of your RAG system:\nToo large chunks: Your system retrieves too much irrelevant information (like\nserving entire turkeys)\nToo small chunks: You lose important context (like serving single peas)\nJust right chunks: Your system finds precisely what it needs (perfect portions\nLet's explore some practical chunking methods:\nThe simplest approach divides text into equal-sized pieces, regardless of content:\nChunking: Breaking Documents into Manageable\nPieces\nWhy Chunking Matters\n1. Fixed-Size Chunking: Simple but Imperfect\ndef fixed_size_chunk(text, chunk_size=50):\n    chunks = []\n    for i in range(0, len(text), chunk_size):\n        chunks.append(text[i:i+chunk_size])\n    return chunks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag3/24\n\nThis code loops through text, taking 50 characters at a time. Let's see how it work\na sample paragraph:\nInput Text:\nOutput Chunks:\nNotice the problem? The word \"Artificial\" is split between chunks 1 and 2.\n\"Industries\" is split between chunks 2 and 3. This makes it hard for our system to\nunderstand the content properly.\nA smarter approach is to chunk by complete sentences:\nThe quick brown fox jumps over the lazy dog. Artificial intelligence h\nrevolutionized many industries. Today's weather is sunny with a chance\nof rain. Many researchers work on RAG systems to improve information \nretrieval.\nChunk 1: \"The quick brown fox jumps over the lazy dog. Arti\"\nChunk 2: \"ficial intelligence has revolutionized many indus\"\nChunk 3: \"tries. Today's weather is sunny with a chance of \"\nChunk 4: \"rain. Many researchers work on RAG systems to imp\"\nChunk 5: \"rove information retrieval.\"\n2. Sentence-Based Chunking: Respecting Natural Boundaries\nimport nltk  # Natural Language Toolkit library\ndef sentence_based_chunk(text, max_sentences=1)\n    sentences = nltk.sent_tokenize(text)\n    chunks = []\n    # Group sentences, 1 at a time\n    for i in range(0, len(sentences), max_sentences):\n        chunks.append(\" \".join(sentences[i:i+max_sentences]))\n    return chunks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag4/24\n\nThis method first identifies complete sentences, then groups them one at a time:\nOutput Chunks:\nMuch better! Each chunk now contains a complete sentence with its full meaning\nintact.\nDepending on your documents, these approaches might also work well:\nParagraph-Based: Split text at paragraph breaks (usually marked by newlines)\nSemantic Chunking: Group text by topics or meaning (often requires AI\nassistance)\nHybrid Approaches: Combine multiple strategies for optimal results\nWhile many sophisticated chunking methods exist, for most practical applications\n\"Keep It Simple, Stupid\" (KISS) principle applies. Starting with Fixed-Size Chunk\nof around 1,000 characters per chunk is often sufficient and avoids overcomplica\nyour system.\nThe best chunking approach ultimately depends on your specific documents and use case \nlike a chef adjusts portions based on the meal and guests!\nChunk 1: \"The quick brown fox jumps over the lazy dog.\"\nChunk 2: \"Artificial intelligence has revolutionized many industries.\"\nChunk 3: \"Today's weather is sunny with a chance of rain.\"\nChunk 4: \"Many researchers work on RAG systems to improve information \nretrieval.\"\n3. Additional Chunking Strategies\nChoosing the Right Approach\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag5/24\n\nNow that we've chopped up our documents, how does the system find the most\nrelevant chunks for our questions? This is where embeddings come in! Embeddin\nare the magic that powers our retrieval system. Without them, we couldn't find the\nright information for our questions!\nAn embedding transforms text into a list of numbers (a vector) that captures its\nmeaning. Think of it as creating a special \"location\" in a meaning-space where sim\nideas are positioned close together.\nFor example, if we take these three sentences:\n1. \"The cat sat on the mat.\" \n2. \"A feline rested on the floor covering.\" \n3. \"Python is a popular programming language.\" \nA good embedding system would place sentences 1 and 2 close together (since they\ndescribe the same concept), while sentence 3 would be far away (completely differe\ntopic).\nWhen we convert these sentences to embeddings, we might get something like thi\na simplified 2D space:\nOn a graph, the cat-related sentences would cluster in the upper right, while the\nprogramming sentence would sit in the lower left - visually showing their semanti\nrelationships!\nEmbeddings: Making Retrieval Possible\nWhat Are Embeddings?\nVisualizing Embeddings in Action\nSentence 1 (): [0.8, 0.2]\nSentence 2 (): [0.7, 0.3] \nSentence 3 (): [-0.5, -0.9]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag6/24\n\nWith embeddings, measuring similarity is as simple as calculating the distance\nbetween points:\nDistance from  to : Very small (about 0.14 units) → Very similar!\nDistance from  to : Very large (about 1.95 units) → Not related at all!\nThis confirms what we intuitively know - the cat sentences are closely related, wh\nthe programming sentence is completely different.\nHere's a beginner-friendly way to create embeddings by counting characters:\nCreating Embeddings: From Simple to Advanced\n1. Simple Approach: Character Frequency\ndef get_simple_embedding(text):\n    # Create a vector to store character frequencies\n    embedding = np.zeros(26, dtype=np.float32)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag7/24\n\nLet's see what this looks like for our three example sentences:\nNotice how sentences 1 and 2 have different values because they use different wor\nwhile sentence 3 has a very different pattern altogether. This simple vector only\ncaptures the characters used, not their meaning.\nLimitation: This simple approach can't recognize that \"cat\" and \"feline\" are relate\nconcepts since they share no characters!\nIn a real RAG system, you'd use sophisticated models like OpenAI's embedding A\n    # Count character frequencies in the text\n    for char in text:\n        embedding[ord(char) % 26] += 1.0\n    # Normalize the vector\n    norm = np.linalg.norm(embedding)\n    if norm > 0:\n        embedding /= norm\n    return embedding\n \"The cat sat on the mat.\" → [0.2, 0, 0, ...] \n(high values at positions for 't', 'a', ' ', etc.)\n \"A feline rested on the floor covering.\" → [0.1, 0.2, 0, ...] \n(different characters but similar number of spaces)\n \"Python is a popular programming language.\" → [0.1, 0.2, 0.1, ...]\n(completely different character pattern)\n2. Professional Approach: AI-Powered Embeddings\ndef get_openai_embedding(text):\n    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \n\"YOUR_API_KEY\"))\n    response = client.embeddings.create(\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag8/24\n\nThese advanced embeddings capture deep semantic relationships in high-dimensi\nspace (typically 1,536 dimensions for OpenAI's embeddings). They understand tha\n\"cat\"  and \"feline\"  mean the same thing, even with completely different\ncharacters!\nEven though sentences 1 and 2 use different words, their embeddings have similar\npatterns because they express similar concepts. Meanwhile, sentence 3's embeddin\nhas a completely different pattern because it's about a different topic entirely.\nIn our RAG pipeline:\n1. We embed all document chunks and store these vectors\n2. When a user asks a question, we embed the question too\n        model=\"text-embedding-ada-002\",\n        input=text\n    )\n    # Extract the embedding vector from the response\n    embedding = response.data[0].embedding\n    return np.array(embedding, dtype=np.float32)\n \"The cat sat on the mat.\" → [0.213, -0.017, 0.122, ...] \n(pattern encoding \"animal resting on object\")\n \"A feline rested on the floor covering.\" → [0.207, -0.024, 0.118, \n...] \n(very similar pattern, also encoding \"animal resting on object\")\n \"Python is a popular programming language.\" → [-0.412, 0.158, 0.367\n...] \n(completely different pattern encoding \"programming language\")\nHow Embeddings Drive Our RAG System\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag9/24\n\n3. We find the document chunks whose embeddings are closest to the question's\nembedding\nHowever, as your document collection grows into thousands or millions of chunks, search\nthrough all embeddings becomes slow. That's where vector databases come in - specializ\nsystems designed to make this search lightning-fast!\nImagine having to search through a million book pages to find an answer - it woul\ntake forever! Vector databases solve this problem by organizing our embeddings in\nclever way that makes searching lightning-fast.\nWhen you ask a question, your RAG system needs to compare it against potentially\nthousands or millions of document chunks. There are two ways to do this:\nIn this approach, we check every single document chunk one by one - like going\nthrough every page in a library:\nVector Databases: Making Retrieval Fast\nWhy We Need Vector Databases\n1. Simple Approach: The Exhaustive Search\ndef retrieve_naive(question_embedding, chunk_embeddings):\n    best_similarity, best_chunk_index = -1, -1\n    for idx, chunk_embedding in enumerate(chunk_embeddings):\n        similarity = get_similarity(question_embedding, chunk_embeddin\n        if similarity > best_similarity:\n            best_similarity, best_chunk_index = similarity, idx\n    return best_chunk_index\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag10/24\n\nThis works perfectly for a few dozen documents, but becomes painfully slow with\nthousands or millions of chunks.\nVector databases are like having a magical librarian who organizes books so effect\nthat they can instantly find what you need without checking every shelf.\nLet's see how this works in two simple steps:\nStep 1: Building the Magical Index\nFirst, we organize all our document embeddings into a special structure:\nThis is like creating a detailed map of where every document \"lives\" in our meanin\nspace.\nStep 2: Fast Retrieval Using the Index\nWhen a question comes in, we use our magical index to find the most relevant chu\nin an instant:\nInstead of checking every document, the index knows exactly where to look - givin\nthe top 5 most relevant chunks in milliseconds!\nThe speed of vector databases comes from three clever techniques:\n2. Professional Approach: Smart Indexing with Vector Databases\ndef create_index(chunk_embeddings):\n    dimension = chunk_embeddings.shape[1]  # e.g. 128 or 1536\n    index = faiss.IndexFlatL2(dimension)   # flat = exact search\n    index.add(chunk_embeddings)            # add all document vectors\n    return index\ndef retrieve_index(index, question_embedding, top_k=5):\n    _, chunk_indices = index.search(question_embedding, top_k)\n    return chunk_indices\nWhat Makes Vector Databases So Efficient?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag11/24\n\n1. Smart Indexing Algorithms: Methods like HNSW (Hierarchical Navigable Sm\nWorlds) create shortcuts through the embedding space, so the system only nee\nto check a small fraction of documents.\n2. Vector Compression: These databases can shrink embeddings to save memory\nwhile preserving their relationships - like having a compressed map that still\nshows all the important landmarks.\n3. Parallel Processing: Modern vector databases use multiple CPU/GPU cores\nsimultaneously, checking many possibilities at once - like having a team of\nlibrarians all searching different sections of the library at the same time.\nWith these techniques, vector databases can search through millions of documents in\nmilliseconds - making RAG systems practical for even the largest document collection\nNow that you understand chunking, embeddings, and vector databases, here's the\nbeautiful simplicity of RAG that many frameworks overcomplicate:\nRAG is just two straightforward workflows working together!\nThink of RAG like your personal research assistant, organized into two efficient\nprocesses:\nPutting RAG Together: Just Two Simple Workflow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag12/24\n\nThis happens just once, before any questions are asked:\nChunking: Break documents into bite-sized pieces (like dividing a book into\nmemorable paragraphs)\nEmbedding: Convert each chunk into a numerical vector (like giving each\nparagraph a unique \"location\" in meaning-space)\nIndexing: Organize these vectors for efficient retrieval (like creating a magica\nmap of all your knowledge)\nThis happens each time someone asks a question:\nQuery Embedding: Transform the question into a vector (finding its \"location\nthe same meaning-space)\nRetrieval: Find the document chunks closest to the question (locate the most\nrelevant knowledge)\nAugmented Generation: Create an answer using both the question and retriev\ncontext (craft a response grounded in your specific documents)\n1. Offline Flow: Preparing Your Knowledge Base\n2. Online Flow: Answering Questions in Real-Time\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag13/24\n\nThat's it! The magic of RAG isn't in complex algorithms - it's in how these two simpl\nworkflows work together to provide accurate, relevant answers based on your specific\nknowledge!\nPocketFlow makes building RAG systems delightfully simple. Unlike complex\nframeworks with layers of abstraction, PocketFlow uses minimal building blocks i\njust 100 lines of code to clearly show how everything works.\nThink of PocketFlow as a well-organized kitchen where:\nNodes are cooking stations that perform specific tasks:\nFlow is the recipe that coordinates these stations:\nBuilding RAG with PocketFlow\nclass BaseNode:\n    def __init__(self): self.params, self.successors = {}, {}\n    def add_successor(self, node, action=\"default\"): \n        self.successors[action] = node\n        return node\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass\n    def post(self, shared, prep_res, exec_res): pass\n    def run(self, shared): \n        p = self.prep(shared); \n        e = self.exec(p); \n        return self.post(shared, p, e)\nclass Flow(BaseNode):\n    def __init__(self, start): super().__init__(); self.start = start\n    def get_next_node(self, curr, action): \n        return curr.successors.get(action or \"default\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag14/24\n\nShared Store is a common workspace where all nodes can access ingredients:\nEach Node performs three simple operations:\nPrep: Gather what's needed from the shared store\nExec: Perform its specific task\nPost: Store results and decide what happens next\nThe Flow manages the entire process, moving data smoothly from one node to the\nnext based on specific conditions.\n    def orch(self, shared, params=None):\n        curr, p = copy.copy(self.start), (params or {**self.params})\n        while curr: \n            curr.set_params(p)\n            c = curr.run(shared)\n            curr = copy.copy(self.get_next_node(curr, c))\n    def run(self, shared): \n        pr = self.prep(shared)\n        self.orch(shared)\n        return self.post(shared, pr, None)\n# Connect nodes together\nload_data_node = LoadDataNode()\nsummarize_node = SummarizeNode()\nload_data_node >> summarize_node\n# Create flow\nflow = Flow(start=load_data_node)\n# Pass data through shared store\nshared = {\"file_name\": \"data.txt\"}\nflow.run(shared)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag15/24\n\nWith these simple building blocks, PocketFlow makes RAG systems easy to build, underst\nand modify!\nLet's create an AI assistant that can answer questions from your documents. Our g\nis to build a simple but powerful RAG system that:\n1. Processes your documents only once (offline flow)\n2. Takes user questions\n3. Retrieves the most relevant information\n4. Generates accurate, document-grounded answers\nLet's see what happens when you ask our system:\nWhat's the capital of France?\n1. ChunkDocuments Node:\nInput (Prep): Your collection of documents\nProcess (Exec): Divides each document into manageable chunks\nOutput (Post): Collection of document chunks (including one with \"Paris\nthe capital of France\")\n2. EmbedDocuments Node:\nInput (Prep): Document chunks\nProcess (Exec): Converts each chunk into a numerical vector\nOutput (Post): Collection of document embeddings\nBuilding a RAG From Scratch with PocketFlow\nStep-By-Step Walkthrough with a Real Example\nOffline Phase (Happens Once)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag16/24\n\n3. CreateIndex Node:\nInput (Prep): Document embeddings\nProcess (Exec): Builds a searchable vector index\nOutput (Post): Ready-to-use vector database\n1. EmbedQuery Node:\nInput (Prep): \"What's the capital of France?\"\nProcess (Exec): Converts question into an embedding vector\nOutput (Post): Question embedding\n2. RetrieveDocuments Node:\nInput (Prep): Question embedding + vector database\nProcess (Exec): Finds the most similar document chunk\nOutput (Post): Retrieves \"Paris is the capital of France\" chunk\n3. GenerateAnswer Node:\nInput (Prep): Original question + retrieved chunk\nProcess (Exec): Crafts response using both inputs\nOutput (Post): \"The capital of France is Paris.\"\nNow let's implement this with code!\nThis node breaks documents into smaller, manageable pieces:\nOnline Phase (Happens Every Question)\nBuilding the Offline Flow\nNode 1: The ChunkDocumentsNode\nclass ChunkDocumentsNode(BatchNode):\n    def prep(self, shared):\n        return shared[\"texts\"]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag17/24\n\nThe prep gets documents from shared storage, exec divides each document into\nchunks, and post combines all chunks into a single list for the next node.\nThis node converts each text chunk into a numerical vector:\nThe prep retrieves text chunks, exec converts each chunk into an embedding vec\nand post stores all embeddings as a single array.\nThis node builds a searchable index for fast retrieval:\n    def exec(self, text):\n        return fixed_size_chunk(text)\n    def post(self, shared, prep_res, exec_res_list):\n        all_chunks = []\n        for chunks in exec_res_list:\n            all_chunks.extend(chunks)\n        shared[\"texts\"] = all_chunks\n        print(f\"✅ Created {len(all_chunks)} chunks\")\n        return \"default\"\nNode 2: The EmbedDocumentsNode\nclass EmbedDocumentsNode(BatchNode):\n    def prep(self, shared):\n        return shared[\"texts\"]\n    def exec(self, text):\n        return get_embedding(text)\n    def post(self, shared, prep_res, exec_res_list):\n        embeddings = np.array(exec_res_list, dtype=np.float32)\n        shared[\"embeddings\"] = embeddings\n        print(f\"✅ Created {len(embeddings)} document embeddings\")\n        return \"default\"\nNode 3: The CreateIndexNode\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag18/24\n\nThe prep gets embeddings, exec creates and populates a vector index, and post\nsaves the index for query processing.\nThis node converts a user question into the same vector format:\nclass CreateIndexNode(Node):\n    def prep(self, shared):\n        return shared[\"embeddings\"]\n    def exec(self, embeddings):\n        print(\" Creating search index...\")\n        dimension = embeddings.shape[1]\n        index = faiss.IndexFlatL2(dimension)\n        index.add(embeddings)\n        return index\n    def post(self, shared, prep_res, exec_res):\n        shared[\"index\"] = exec_res\n        print(f\"✅ Index created with {exec_res.ntotal} vectors\")\n        return \"default\"\nBuilding the Online Flow\nNode 4: The EmbedQueryNode\nclass EmbedQueryNode(Node):\n    def prep(self, shared):\n        return shared[\"query\"]\n    def exec(self, query):\n        print(f\" Embedding query: {query}\")\n        query_embedding = get_embedding(query)\n        return np.array([query_embedding], dtype=np.float32)\n    def post(self, shared, prep_res, exec_res):\n        shared[\"query_embedding\"] = exec_res\n        return \"default\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag19/24\n\nThe prep gets the user's question, exec creates an embedding using the same me\nas for documents, and post stores this embedding for retrieval.\nThis node finds the most relevant document chunks:\nThe prep gets query embedding and index, exec searches for the closest matchin\ndocument chunk, and post saves the retrieved information.\nThis node creates the final answer using the retrieved context:\nNode 5: The RetrieveDocumentNode\nclass RetrieveDocumentNode(Node):\n    def prep(self, shared):\n        return shared[\"query_embedding\"], shared[\"index\"], \nshared[\"texts\"]\n    def exec(self, inputs):\n        print(\" Searching for relevant documents...\")\n        query_embedding, index, texts = inputs\n        distances, indices = index.search(query_embedding, k=1)\n        best_idx = indices[0][0]\n        distance = distances[0][0]\n        most_relevant_text = texts[best_idx]\n        return {\n            \"text\": most_relevant_text,\n            \"index\": best_idx,\n            \"distance\": distance\n        }\n    def post(self, shared, prep_res, exec_res):\n        shared[\"retrieved_document\"] = exec_res\n        print(f\" Most relevant text: \\\"{exec_res['text']}\\\"\")\n        return \"default\"\nNode 6: The GenerateAnswerNode\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag20/24\n\nThe prep gets the question and retrieved document, exec creates a prompt and c\nan LLM, and post saves the generated answer.\nclass GenerateAnswerNode(Node):\n    def prep(self, shared):\n        return shared[\"query\"], shared[\"retrieved_document\"]\n    def exec(self, inputs):\n        query, retrieved_doc = inputs\n        prompt = f\"\"\"\nBriefly answer the following question based on the context provided:\nQuestion: {query}\nContext: {retrieved_doc['text']}\nAnswer:\n\"\"\"\n        answer = call_llm(prompt)\n        return answer\n    def post(self, shared, prep_res, exec_res):\n        shared[\"generated_answer\"] = exec_res\n        print(\"\\n烙 Generated Answer:\")\n        print(exec_res)\n        return \"default\"\nConnecting Everything Together\n# Create offline flow for document processing\nchunk_docs_node = ChunkDocumentsNode()\nembed_docs_node = EmbedDocumentsNode()\ncreate_index_node = CreateIndexNode()\n# Connect nodes in sequence\nchunk_docs_node >> embed_docs_node >> create_index_node\noffline_flow = Flow(start=chunk_docs_node)\n# Create online flow for answering questions\nembed_query_node = EmbedQueryNode()\nretrieve_doc_node = RetrieveDocumentNode()\ngenerate_answer_node = GenerateAnswerNode()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag21/24\n\nThis connects our nodes into two flows - one for document processing (run once) a\none for answering questions (run for each query).\nThe complete working code for this tutorial is available at GitHub: PocketFlow RAG\nCookbook.\nNow you understand the elegant simplicity of RAG systems:\n1. Offline Flow: Process your documents once → Create vectors → Build searcha\nindex\n2. Online Flow: Process questions → Find relevant context → Generate grounde\nanswers\nThis simple pattern powers even the most sophisticated RAG systems. Next time y\nencounter a complex RAG framework, look for these two workflows beneath the\nabstractions, and you'll understand how it works.\nThe power of RAG lies in its simplicity and effectiveness. By grounding AI respon\nin your specific documents, RAG dramatically improves accuracy, reduces\nhallucinations, and enables AI systems to work with your custom knowledge.\nWith what you've learned, you can now build your own RAG systems for any doma\nspecific knowledge base!\n# Connect nodes in sequence\nembed_query_node >> retrieve_doc_node >> generate_answer_node\nonline_flow = Flow(start=embed_query_node)\nConclusion: The Beauty of RAG Simplicity\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag22/24\n\nTry Pocket Flow today and experience how 100 lines can replace hundreds of thousand\nGitHub Repository | Documentation | TypeScript Version\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n20 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nWrite a comment...\nApr 4\nLiked by Zachary Huang\n1 reply by Zachary Huang\nz4021\nI just finished watching the whole thing! It was freakin' awesome! Got me all fired up to make\nbunch of cool stuff.\nLIKE (1)REPLY\nApr 1\nLiked by Zachary Huang\nIan Malcolm\nHow easy would it be to use an external database for RAG?\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag23/24\n\n2 more comments...\n1 reply by Zachary Huang\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMRetrieval Augmented Generation (RAG) from Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/retrieval-augmented-generation-rag24/24"
  },
  {
    "filename": "PocketBlog250405.pdf",
    "title": "AI Codebase Knowledge Builder (Full Dev",
    "date": "2025-04-05",
    "content": "\n\nAI Codebase Knowledge Builder (Full Dev\nTutorial!)\nAPR 05, 2025\n174Sh\nEver stared at a new codebase feeling completely lost? What if an AI could read it for y\nand create a friendly tutorial explaining exactly how it works? This guide shows you ho\nbuild a system that does exactly that! The AI system is open-sourced on GitHub.\nLet's be real: You've just joined a new team or stumbled upon an exciting open-sou\nproject. You're pumped to contribute, but when you open the repository... oh boy.\nHundreds of files. Thousands of functions. Code that seems to be talking to other \nZACHARY HUANG\n48\n1. Life's too short to stare at others' code in\nconfusion\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full1/24\n\nthat's talking to who-knows-what. And you're sitting there thinking, \"Where the h\ndo I even begin?\"\nSound familiar? Don't worry, we've all been there!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nLet's cut to the chase: understanding someone else's code is hard. Not just regular\nhard - it's tear-your-hair-out frustrating. Studies show developers spend up to 60%\ntheir time just trying to understand code rather than writing it. That's weeks or\nmonths of your life spent muttering things like:\n\"What the heck does this class actually do?\"\n\"How on earth does this component connect to that one?\"\n\"Why in the world was it designed this way?\"\n\"Can someone please explain the big picture here?!\"\nAnd the fun doesn't stop there! Documentation is often outdated or—let's be hone\ncompletely non-existent. Comments are as rare as unicorns. Variable names might\nwell be written in hieroglyphics. It's like being handed a 1000-piece puzzle with ha\nthe pieces missing, no picture on the box, and someone saying \"Good luck, have fu\nPicture this: You're exploring CrewAI, a cool multi-agent framework. Curious abo\nhow it works, you paste some code into ChatGPT and ask\nHow does CrewAI's multi-agent chat system work internally?\nChatGPT confidently responds:\nThe Painful Reality of New Codebases\nWhy Current AI Solutions Fall Short\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full2/24\n\n\"CrewAI's multi-agent system operates through a structured framework that orchestrat\ninteractions between specialized AI agents. Each agent has a specific role, custom\nknowledge base, and defined goals. The system includes a central orchestration layer,\ncommunication protocols, and context management...\"\nSuper helpful, right? ...Nope, not really. Here's why current AI explanations leave y\nscratching your head:\n1. They give you buzzword salad, not actual insights - You get fancy terms like\n\"orchestration layer\" and \"context management\" without any clue what these\nactually mean in practice\n2. They barely scratch the surface - They'll tell you what the code does but never\nexplain why it's designed that way or what problem it's actually solving\nThe end result? Your brain is now swimming with technical jargon, but you still h\nzero idea how the system actually works. It's like someone handed you all the\ningredients for a gourmet cake but forgot the recipe—technically complete but\npractically useless.\nIntroducing Codebase Knowledge Builder\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full3/24\n\nWhat if there was a better way? A system that could:\nDevour entire codebases and identify the core ideas and how they play togeth\nTransform complicated code into tutorials so clear your grandma could\nunderstand them\nBuild your understanding step-by-step from the basics to the advanced stuff \nway that actually makes sense\nThat's exactly what we're building today: a tool that transforms any GitHub reposi\ninto a personalized guidebook that actually helps you understand how the code wo\nThis project is open-sourced on GitHub.\nCheck out some example tutorials!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full4/24\n\n1. AutoGen Core - Build AI teams that talk, think, and solve problems together l\ncoworkers!\n2. Flask: Craft web apps with minimal code that scales from prototype to produc\n3. MCP Python SDK - Build powerful apps that communicate through an elegan\nprotocol without sweating the details!\n4. OpenManus - Build AI agents with digital brains that think, learn, and use too\njust like humans do!\nThis project is powered by PocketFlow - a tiny but mighty agent framework that l\nus build complex workflows with minimal code. We'll also use Gemini 2.5 Pro,\nGoogle's latest AI with serious code-understanding superpowers. Together, they'll\ncreate a system that feels almost magical in its ability to make sense of complex co\nWhether you're a seasoned dev tired of banging your head against unfamiliar code, a te\nlead who wants to make onboarding less painful, or just someone curious about AI's pote\nto make programming more accessible - this tutorial is for you. Let's dive in!\nCode isn't just a collection of functions and variables—it's a carefully designed sys\nof abstractions working together to solve problems. Yet most documentation focu\non individual pieces, missing the forest for the trees. Our Codebase Knowledge\nBuilder takes a fundamentally different approach.\n2. From Code Chaos to Crystal Clarity: Our Secre\nSauce\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full5/24\n\nHere's the thing about understanding code: knowing what each function does is li\nknowing the names of all the parts in a car engine—utterly useless if you don't kno\nhow they work together to make the car move!\nWhat you actually need is:\nThe big-picture blueprint (what are the key pieces?)\nThe master plan (why was it built this way?)\nThe relationship map (how do these pieces talk to each other?)\nOur approach mirrors how your brain naturally learns—and it's dead simple:\n1. The Eagle's View - First, we zoom out and see the entire forest: What's this co\ntrying to do? What are the key pieces? How do they fit together? This mental \nis your secret weapon against code confusion.\n2. The Deep Dive - Then we swoop in on each important piece: How does it wor\nWhat clever tricks does it use? Why was it built this way? We explore thoroug\nbut always keep its place in your mental map crystal clear.\nFrom Confusion to Clarity: Our Two-Step Magic Trick\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full6/24\n\nThis is exactly how the best teachers work—they don't drown you in details from d\none. They give you the big picture first, then fill in the juicy details in a way that\nactually makes sense and sticks in your brain.\nLet's take Flask—that super popular Python web framework—and see how our\napproach transforms it from cryptic code into crystal-clear concepts:\nStep 1: The Eagle's View 礪\nInstead of drowning you in details, we start with: \"Flask is basically a LEGO set fo\nbuilding websites. You snap together routes (URLs) with functions that handle\nrequests, and—boom—you've got yourself a web app! It's designed to be lightweig\nso you're not carrying around features you'll never use.\"\nStep 2: The Deep Dive \nOnce you've got that mental map, we zoom into the key pieces:\n\"The real genius of Flask is how these five key pieces work together:\nThe App object (the brain that runs everything)\nRoutes (the traffic cops that direct requests to the right place)\nView Functions (the workers that actually do stuff)\nTemplates (the pretty face that users see)\nRequest/Response objects (the messengers carrying data back and forth)\nWhen someone visits your site, the App checks its routing table, finds the matchin\nView Function, grabs any data from the Request, does its magic, maybe renders a\nTemplate, and sends back a Response. Simple!\"\nSee the difference? Instead of just throwing documentation at you, we've given yo\nmental model that actually makes sense. Apply this to any codebase, and suddenly\nyou're not lost anymore—you're confidently exploring with a map in hand!\nFrom Huh? to Aha!: Let's See This Magic in Action\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full7/24\n\nBut how do we actually build this magical system? We need a framework that's as \nand intuitive as the tutorials we want to create. Enter PocketFlow—the perfect par\nfor our AI-powered adventure.\nWhile most AI frameworks hit you with a tsunami of complexity, PocketFlow take\nopposite approach. It strips away the unnecessary fluff to reveal something beauti\nelegance through simplicity.\nAt just 100 lines of code, PocketFlow proves that AI workflows don't need to be\ncomplicated. This crystal-clear design makes it perfect for our Codebase Knowled\nBuilder - not just because humans can understand it easily, but because AI agents \ntoo! It's like creating building blocks so intuitive that both your 5-year-old and you\nrobot assistant can play with them.\nThink of PocketFlow like a well-organized kitchen where:\nNodes are cooking stations performing specific tasks:\n3. PocketFlow + AI Agents: The Ultimate Code-\nBuilding Dream Team\nThe Kitchen Analogy: Understanding PocketFlow's Buildi\nBlocks\nclass BaseNode:\n    def __init__(self): \n        self.params, self.successors = {}, {}\n    def add_successor(self, node, action=\"default\"): \n        self.successors[action] = node\n        return node\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass\n    def post(self, shared, prep_res, exec_res): pass\n    def run(self, shared): \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full8/24\n\nFlow is the recipe that coordinates these stations:\nShared Store is the countertop where all stations can access ingredients and t\n        p = self.prep(shared)\n        e = self.exec(p)\n        return self.post(shared, p, e)\nclass Flow(BaseNode):\n    def __init__(self, start): \n        super().__init__()\n        self.start = start\n    def get_next_node(self, curr, action):\n        return curr.successors.get(action or \"default\")\n    def orch(self, shared, params=None):\n        curr, p = copy.copy(self.start), (params or {**self.params})\n        while curr: \n            curr.set_params(p)\n            c = curr.run(shared)\n            curr = copy.copy(self.get_next_node(curr, c))\n    def run(self, shared): \n        pr = self.prep(shared)\n        self.orch(shared)\n        return self.post(shared, pr, None)\n# Connect nodes together\nload_data_node = LoadDataNode()\nsummarize_node = SummarizeNode()\nload_data_node >> summarize_node\n# Create flow\nflow = Flow(start=load_data_node)\n# Pass data through shared store\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full9/24\n\nEach Node follows a simple three-step process:\nPrep: Gather what's needed from the shared store (like gathering ingredients)\nExec: Perform its specialized task (like cooking the ingredients)\nPost: Store results and determine what happens next (like serving the dish and\ndeciding what to make next)\nThe Flow orchestrates the entire process, moving data seamlessly from one node t\nthe next based on specific conditions, much like a chef moving between stations in\nkitchen.\nHere's the real magic: PocketFlow isn't just simple for humans—it's dead simple f\nAI agents too! This unleashes a development superpower called Agentic Coding:\nYou sketch the high-level architecture (what humans are great at)\nAI agents handle all the detail work and implementation (what AIs excel at)\nIt's like being the architect who draws a blueprint, then having a team of robots bu\nthe entire house overnight while you sleep. No more tedious implementation,\ndebugging weird edge cases, or wrestling with syntax errors!\nTraditional coding means designing the system, implementing every detail yourse\ndebugging for hours, and finally shipping something days or weeks later. With Ag\nCoding? Design the system, let AI agents implement everything, and ship tomorro\nmorning. It's that simple.\nFor our Codebase Tutor, this means you just outline the workflow (like we'll do in \nnext section), and AI agents handle all the nitty-gritty implementation. You don't g\nbogged down in framework complexities or fine-tuning prompt details—you just t\nthe agents what you want, and they make it happen.\nshared = {\"file_name\": \"data.txt\"}\nflow.run(shared)\nAgentic Coding: The Fastest Way to Build Anything\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full10/24\n\nFor a detailed guide on setting up this magical development environment, check th\ndedicated Agentic Coding guide and the PocketFlow Documentation.\nSo how does this codebase tutorial builder actually work? It's actually pretty cleve\nwe've built a team of specialized components that work together, each handling a\nspecific part of the tutorial-creation process. Let's take a look at who does what.\nOur system works like a well-organized assembly line, with each component passi\nits output to the next:\n4. Behind the Scenes: How Our Code Tutor\nActually Works\nThe Step-by-Step Process\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full11/24\n\nThis mirrors how you'd naturally approach learning something complex - gather\nmaterials, identify the key concepts, understand how they relate, figure out what t\nlearn first, dive into each topic, and finally put everything together. Our system jus\nautomates the whole thing.\nLet's meet each component and see what they bring to the table:\nThis component fetches all the relevant code files while skipping the stuff you don\nneed.\nMeet the Team (No Capes Required)\n1. FetchRepo: The Efficient Librarian\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full12/24\n\nWHAT IT SEES: A GitHub repository URL and optional filters\nWHAT IT DOES: Downloads the code files while skipping tests, build artifac\nand other non-essentials\nWHAT IT DELIVERS: A clean collection of files ready for analysis\nSample Output:\nThis component spots the important concepts hiding in the code.\nWHAT IT SEES: All the code files collected by FetchRepo\nWHAT IT DOES: Analyzes class definitions, patterns, and code structure to\nidentify core abstractions\nWHAT IT DELIVERS: A list of key concepts with clear descriptions\nSample Output:\nFound and processed 15 Python files from https://github.com/the-\npocket/PocketFlow:\n- pocketflow/__init__.py (core framework code)\n- pocketflow/utils.py (utility functions)\n- pocketflow/nodes/__init__.py (node definitions)\n...\n2. IdentifyAbstractions: The Pattern Finder\nIdentified 6 core abstractions:\n1. BaseNode: The fundamental building block for creating workflow \ncomponents\n   Files: pocketflow/__init__.py, pocketflow/nodes/__init__.py\n2. Flow: Orchestrates the execution of nodes based on their outputs\n   Files: pocketflow/__init__.py, examples/simple_flow.py\n...\n3. AnalyzeRelationships: The Connection Mapper\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full13/24\n\nThis component figures out how all the key concepts connect and interact with ea\nother.\nWHAT IT SEES: The abstractions from the previous step and their code\nWHAT IT DOES: Analyzes function calls, inheritance, data flow, and\ndependencies\nWHAT IT DELIVERS: A map of how everything fits together\nSample Output:\nThis component figures out the most logical order to teach each concept.\nWHAT IT SEES: The abstractions and their relationships\nWHAT IT DOES: Analyzes dependencies to determine what needs to be learn\nfirst\nWHAT IT DELIVERS: A sensible learning sequence that builds knowledge st\nby step\nSample Output:\nProject Summary: \"PocketFlow is a minimal framework for building AI \nworkflows using a graph-based approach...\"\nRelationships:\n- BaseNode → Flow (contained in): Flow contains and manages BaseNode \ninstances\n- Flow → BaseNode (orchestrates): Flow controls when and how Nodes \nexecute\n- SharedMemory → Node (provides data): Nodes access data through the \nSharedMemory\n...\n4. OrderChapters: The Learning Planner\nRecommended learning sequence:\n1. BaseNode (foundational concept)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full14/24\n\nThis component creates easy-to-understand explanations with helpful analogies.\nWHAT IT SEES: Each abstraction, its description, and relevant code\nWHAT IT DOES: Creates beginner-friendly chapters with examples and\nexplanations\nWHAT IT DELIVERS: Complete, readable content for each chapter\nSample Output:\nThis component puts everything together into a polished tutorial that flows nicely\nWHAT IT SEES: The project summary, relationships, and all chapter content\nWHAT IT DOES: Creates visuals, sets up navigation, and organizes the conte\n2. SharedMemory (required to understand data flow)\n3. Flow (builds on understanding of Nodes)\n4. BatchNode (specialized type of Node)\n...\n5. WriteChapters: The Clear Explainer\nChapter 1: The BaseNode\nImagine a worker at a station in a factory. Their job is simple: take \ninputs, \ndo something specific with them, and pass the results to the next \nstation. \nThis is exactly what a BaseNode does in PocketFlow!\nA BaseNode has three key responsibilities:\n1. **Prep**: Gather what's needed (like collecting ingredients)\n2. **Exec**: Do the actual work (like cooking the ingredients)\n3. **Post**: Decide what happens next (like serving the dish)\nLet's look at how this appears in the code:\n...\n6. CombineTutorial: The Final Organizer\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full15/24\n\nWHAT IT DELIVERS: A complete, ready-to-use tutorial\nSample Output:\nIn the next section, we'll look at how these components are actually implemented \nand you'll be surprised at how simple the code really is!\nReady to see what's actually under the hood? You might expect complicated code t\npower such a clever system, but the beauty of our approach is its simplicity. Let's l\nat the actual implementation—you'll be surprised at how readable it is!\nNote: We've simplified things a bit to focus on what matters. Think of this as th\ndirector's cut that skips the boring parts. You can find the full code on GitHub.\nTutorial complete! Available at: /output/pocketflow_tutorial/\n- index.md (Project overview with visualization)\n- 01_base_node.md\n- 02_shared_memory.md\n- 03_flow.md\n...\n5. The Nuts and Bolts: Simple Code That Makes t\nMagic Happen\nThe Shared Memory Structure\nshared = {\n    \"repo_url\": \"https://github.com/the-pocket/PocketFlow\",  # User \ninput\n    \"codebase\": [],       # The entire codebase from the repository\n    \"core_abstractions\": [],  # Key concepts identified in the code\n    \"abstraction_relationships\": {},  # How concepts connect to each \nother\n    \"chapter_order\": [],   # Best sequence for learning\n    \"chapters\": []         # Actual tutorial content\n}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full16/24\n\nThink of this as the team's shared whiteboard. Everyone can read what's already th\nand add their own findings for others to use later—no need to pass papers around \nrepeat work.\nJust 13 lines of code to handle all the GitHub downloading! This node basically say\n\"Give me a repo URL, let me grab all the relevant files (skipping the junk), and I'll \nthe good stuff where everyone else can find it.\"\nNode Implementations\n1. FetchRepo: Gathering the Code\nclass FetchRepo(Node):\n    def prep(self, shared):\n        # Get repository URL from shared memory\n        repo_url = shared[\"repo_url\"]\n        return {\"repo_url\": repo_url}\n    def exec(self, prep_res):\n        # Download codebase from GitHub\n        # Skip unimportant files like tests, docs, etc.\n        # Returns the full codebase\n        return download_codebase_from_github(prep_res[\"repo_url\"])\n    def post(self, shared, prep_res, exec_res):\n        # Store codebase in shared memory for next nodes\n        shared[\"codebase\"] = exec_res\n2. IdentifyAbstractions: Finding the Core Concepts\nclass IdentifyAbstractions(Node):\n    def prep(self, shared):\n        # Format the codebase for analysis\n        return shared[\"codebase\"]\n    def exec(self, prep_res):\n        codebase = prep_res\n        # Ask AI with codebase directly in the prompt\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full17/24\n\nHere's where the AI brain kicks in. We're essentially asking: \"Hey Gemini, take a l\nat this code and tell me what the main concepts are.\" Then we save what it finds fo\nthe next steps. Clean and simple!\nAnother straightforward AI prompt, but this time we're asking: \"Now that you kn\nthe main pieces, how do they fit together?\" The LLM does the heavy lifting of\nunderstanding function calls, inheritance, and other relationships.\n        prompt = f\"Given this codebase: {codebase}, identify 5-10 core\nconcepts...\"\n        return call_llm(prompt)\n    def post(self, shared, prep_res, exec_res):\n        # Store identified core abstractions\n        shared[\"core_abstractions\"] = exec_res\n3. AnalyzeRelationships: Mapping the Connections\nclass AnalyzeRelationships(Node):\n    def prep(self, shared):\n        # Pass core abstractions and codebase\n        return {\"core_abstractions\": shared[\"core_abstractions\"], \n                \"codebase\": shared[\"codebase\"]}\n    def exec(self, prep_res):\n        # Ask AI with data directly in the prompt\n        prompt = f\"Given these core concepts: \n{prep_res['core_abstractions']} and this codebase: \n{prep_res['codebase']}, analyze how they connect...\"\n        return call_llm(prompt)\n    def post(self, shared, prep_res, exec_res):\n        # Store abstraction relationships\n        shared[\"abstraction_relationships\"] = exec_res\n4. OrderChapters: Creating a Learning Path\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full18/24\n\nThis time we ask: \"What's the best order to learn these things?\" The AI considers\ndependencies (you can't understand X until you know Y) and creates a logical learn\nsequence.\nclass OrderChapters(Node):\n    def prep(self, shared):\n        # Pass the data needed for analysis\n        return {\"core_abstractions\": shared[\"core_abstractions\"],\n                \"relationships\": shared[\"abstraction_relationships\"]}\n    def exec(self, prep_res):\n        # Ask AI with data directly in the prompt\n        prompt = f\"Given these concepts: {prep_res['core_abstractions\nand relationships: {prep_res['relationships']}, what's the best teachi\norder?\"\n        return call_llm(prompt)\n    def post(self, shared, prep_res, exec_res):\n        # Store the recommended chapter order\n        shared[\"chapter_order\"] = exec_res\n5. WriteChapters: Creating the Content\nclass WriteChapters(BatchNode):\n    def prep(self, shared):\n        # Create batches for each concept/chapter\n        chapters = []\n        for concept_idx in shared[\"chapter_order\"]:\n            concept = shared[\"core_abstractions\"][concept_idx]\n            relevant_code = extract_relevant_code(concept, \nshared[\"codebase\"])\n            chapters.append({\n                \"concept\": concept,\n                \"code\": relevant_code,\n                \"previous_chapters\": shared.get(\"completed_chapters\", \n[])\n            })\n        return chapters\n    def exec(self, item):\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full19/24\n\nThis is our longest bit of code, but it's still pretty readable. For each concept, we\ngather the relevant code snippets and ask the AI to write a tutorial chapter about i\nWe also track the chapters we've already written so each new chapter can build on\nwhat came before.\nI have also done some prompt engineering based on my personal experience of wr\nsystem design docs. The prompt guides the AI to begin with high-level motivation\nexplaining what problem each abstraction solves, break complex ideas into key\nconcepts, and them explain internal implementation step-by-step.\n        # Create richer, more structured prompt\n        prompt = f\"\"\"Write a beginner-friendly chapter about \n{item['concept']['name']} with code: {item['code']} and previous \nchapters: {self.completed_chapters if hasattr(self, \n'completed_chapters') else []}\n        Guide:\n        - Start with problem/motivation and a concrete use case\n        - Break complex ideas into simpler concepts\n        - Show usage examples with inputs/outputs\n        - Keep code blocks under 20 lines\n        - Explain implementation with simple step-by-step walkthrough\n        - Include minimal diagrams if helpful\"\"\"\n        chapter = call_llm(prompt)\n        # Track chapters for continuity\n        if not hasattr(self, \"completed_chapters\"):\n            self.completed_chapters = []\n        self.completed_chapters.append(chapter)\n        return chapter\n    def post(self, shared, prep_res, exec_res_list):\n        # Store all chapters and tracking info\n        shared[\"chapters\"] = exec_res_list\n6. CombineTutorial: The Final Assembly\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full20/24\n\nThe finishing touches! This takes all our chapters, creates pretty visualizations, an\npackages everything into a complete tutorial with an index page and navigation.\nclass CombineTutorial(Node):\n    def prep(self, shared):\n        # Gather all components for the final tutorial\n        return prepare_tutorial_components(shared)\n    def exec(self, prep_res):\n        # Create output directory\n        # Generate visualization diagram\n        # Write index.md with overview\n        # Write each chapter file\n        return assemble_final_tutorial(prep_res)\n    def post(self, shared, prep_res, exec_res):\n        # Store path to completed tutorial\n        shared[\"final_output_dir\"] = exec_res\n        print(f\"Tutorial complete! Files are in: {exec_res}\")\nConnecting Everything Together\ndef create_tutorial_flow():\n    # Create all nodes\n    fetch_repo = FetchRepo()\n    identify_abstractions = IdentifyAbstractions()\n    analyze_relationships = AnalyzeRelationships()\n    order_chapters = OrderChapters()\n    write_chapters = WriteChapters()\n    combine_tutorial = CombineTutorial()\n    # Connect nodes in sequence\n    fetch_repo >> identify_abstractions >> analyze_relationships\n    analyze_relationships >> order_chapters >> write_chapters\n    write_chapters >> combine_tutorial\n    return Flow(start=fetch_repo)\n# Use like this:\nflow = create_tutorial_flow()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full21/24\n\nHere's where the magic happens! Just look at those >> operators connecting\neverything together. It's like reading a story: fetch the repo, identify key concepts,\nanalyze their relationships, figure out teaching order, write chapters, combine\neverything. Then we create the flow and run it with a GitHub URL. That's it!\nAnd there you have it—you can now turn any GitHub repo into a beginner-friendl\ntutorial. The real power comes from clever prompting and letting the AI do what i\ndoes best.\nThroughout this tutorial, you've learned three powerful skills that will forever cha\nhow you approach new codebases:\n1. A Systematic Way to Read Code - The Eagle's View and Deep Dive approach\ngives you a methodical process that's far better than just asking ChatGPT abo\ncode snippets. You start with the big picture architecture, then strategically zo\ninto the important implementation details.\n2. System Design for Knowledge Building - How to build a workflow of speciali\ncomponents that follow the Eagle's View and Deep Dive approach, working\ntogether to transform raw code into clear tutorials with the right learning\nsequence.\n3. Agentic Coding with PocketFlow - How to use PocketFlow's simple but powe\nframework to create a clear division of labor where you design the high-level fl\nwhile AI agents implement the details, dramatically speeding up development\nLooking ahead, there are some limitations to keep in mind:\nContext Size - Don't expect it to read the whole Linux source code for you!\nMassive codebases simply can't be stuffed into current model context window\nshared = {\"repo_url\": \"https://github.com/example/repo\"}\nflow.run(shared)\n6. What You've Learned & The Road Ahead\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full22/24\n\nand would need a more aggressive system design with chunking and\nsummarization techniques.\nFrontend Visualization - I'll be honest - I'm mostly a backend person myself, \nI'm not entirely sure how to best represent front end codebase knowledge. Ma\nthrough React component trees, state management, and event-driven\narchitectures? Not sure - interesting to explore in the future!\nBut don't let these minor points hold you back! The Codebase Knowledge Builder\nalready delivers incredible value, turning those intimidating repositories into clea\napproachable tutorials that make sense on both a conceptual and practical level.\nThe days of staring helplessly at unfamiliar code are over. You now have a reliable\nguide that reveals the true design behind any codebase, letting you understand in\nhours what used to take weeks.\nReady to explore code with confidence? The AI Codebase Knowledge Builder is open-sour\nand waiting for you! Experience how PocketFlow's elegant 100 lines of code can transform\nyour development workflow today. GitHub | Documentation\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n48 Likes∙4 Restacks\nDiscussion about this post\nPreviousNext\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full23/24\n\n15 more comments...\nWrite a comment...\nApr 6\nLiked by Zachary Huang\n2 replies by Zachary Huang and others\nJames CHu\nTHIS IS SERIOUSLY GOLD NUGGET! No flattery, clean and a Masterpiece of work! Amazing!\nLIKE (5)REPLY\nApr 30\nLiked by Zachary Huang\n1 reply by Zachary Huang\nJoe Berns\nI tried to run it on a larger codebase, and keep getting token limit exceeded issue: The input\ncount (1069372) exceeds the maximum number of tokens allowed . Is there any way around\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:53 PMAI Codebase Knowledge Builder (Full Dev Tutorial!)\nhttps://pocketflow.substack.com/p/ai-codebase-knowledge-builder-full24/24"
  },
  {
    "filename": "PocketBlog250409.pdf",
    "title": "MCP Simply Explained: Function Calling",
    "date": "2025-04-09",
    "content": "\n\nMCP Simply Explained: Function Calling\nRebranded or Genuine Breakthrough?\nAPR 09, 2025\n2Sh\nEver wished your AI assistant could actually do more than just chat? Like send real em\nschedule your meetings, analyze your spreadsheets, or search the web for you? The Mod\nContext Protocol (MCP) aims to make this possible, but is it really revolutionary? Let's\nbreak it down!\nLet's face it - getting AI models to do real-world tasks has always been hit or miss\nSure, ChatGPT can write you a nice email... but can it actually send it? Claude can\nZACHARY HUANG\n22\n1. Introduction: The Model Context Protocol\nBuzz\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling1/19\n\ndescribe how to analyze your data... but can it run the analysis for you? Wouldn't i\namazing if your AI assistant could seamlessly tap into all your favorite tools and\nactually get things done?\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThat's exactly why Anthropic introduced MCP in November 2024, and it's taking t\nAI world by storm! The GitHub repo skyrocketed to 30K stars in less than six mon\nEven tech giants quickly jumped on board - Google planned to integrate it into the\nsystems, and OpenAI released MCP for their agent.\nBut here's what everyone's wondering: Is MCP truly revolutionary, or just a fancy\nrebrand of what we already had? Despite all the excitement, there's still plenty of\nconfusion about what MCP actually is. What is it exactly? Is it another AI agent? A\nsophisticated tool routing management system? Or something else entirely? And w\nall the hype surrounding it, is it truly revolutionary or just an incremental\nimprovement?\nIn this simple tutorial, we'll:\nStart with the basics: how function calling (the predecessor to MCP) actually\nworks\nBuild up to MCP by showing what problems it solves that function calling\ncouldn't\nCompare both approaches so you can spot the key differences\nShow real examples of what MCP can (and can't) do for you\nHelp you understand if MCP is worth getting excited about\nNo tech jargon overload or marketing hype - just minimal, working code examples\na clear explanation of why MCP might be the missing piece that finally lets your A\nassistant become the productivity partner you've been waiting for.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling2/19\n\nTo see these concepts in action, check out our simple working example code that demonst\nboth function calling and MCP side-by-side. Let's dive in!\nTo understand MCP, we first need to understand function calling - its predecessor\nThink of function calling as teaching your AI to \"phone a friend\" when it needs ex\nhelp. The AI handles the conversation, but knows when to call in specialists for ta\nit's bad at. And AI models can be terrible at certain tasks! Ever asked ChatGPT ho\nmany r's are in \"strawberry\" and watched it confidently give the wrong answer? O\nseen Claude botch simple math? Function calling fixes this by connecting AIs to\nspecialized tools that actually work.\nLet's use a calculator as our working example. When a user asks \"What is 1,567 ×\n428?\", instead of the AI trying to calculate it (and probably failing), function callin\nlets it use a real calculator and return the correct answer: 670,676.\nHere's what a complete function calling workflow looks like:\n1. Implement Functions: First, we create our calculator functions (add, multiply\netc.)\n2. List Functions: We tell the AI what calculator functions are available\n3. Select Function: When user asks \"What is 1,567 multiplied by 428?\", AI select\n\"multiply_numbers\" with parameters a=1567, b=428\n4. Call Function: The system executes multiply_numbers(1567, 428) and returns\n670,676 to the user\n2. Function Calling in Plain English\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling3/19\n\nFirst, we build basic calculator functions:\nNothing fancy here - just functions that take two numbers and do math. The magi\nhappens when we connect them to our AI.\nNow we need to describe these functions to the AI. It's like creating a menu that s\n\"Here's what's available, here's what each thing does, and here's what you need to\nprovide\":\nStep 1: Implement Functions\ndef add_numbers(a, b): return a + b\ndef subtract_numbers(a, b): return a - b\ndef multiply_numbers(a, b): return a * b\ndef divide_numbers(a, b): return a / b\nStep 2: List Functions\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling4/19\n\nWhen a user asks something, the AI needs to figure out which tool to use. There a\ntwo main ways to do this:\nMost AI providers now have built-in methods for this:\ndef get_functions():\n    return [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"add_numbers\",\n                \"description\": \"Add two numbers together\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"a\": { \"type\": \"number\", \"description\": \"First\nnumber\" },\n                        \"b\": { \"type\": \"number\", \"description\": \"Secon\nnumber\" }\n                    }\n                }\n            }\n        },\n        ... # Other operations follow the same pattern\n    ]\nStep 3: Select Function\nThe Official Way (APIs)\ndef select_function(tools, question):\n    from openai import OpenAI\n    client = OpenAI()\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": question}],\n        tools=tools\n    )\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling5/19\n\nIf your model doesn't have function calling built in, you can hack it with a smart\nprompt:\n    # Get the function details\n    tool_call = response.choices[0].message.tool_calls[0]\n    function_name = tool_call.function.name\n    function_args = json.loads(tool_call.function.arguments)\n    return function_name, function_args\nThe DIY Way (Clever Prompting)\ndef select_function(tools, question):\n    from openai import OpenAI\n    import yaml\n    prompt = f\"\"\"\n## Question\n{question}\n## Tools\n{tools}\n## Respond in this format:\n```yml\nthinking: <your reasoning>\ntool:\n  name: <tool_name>\n  parameters:\n    <param_name>: <param_value>\n    ...\n```\"\"\"\n    client = OpenAI()\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    response_text = response.choices[0].message.content\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling6/19\n\nEither way, if you ask \"What's 1,567 multiplied by 428?\", you'll get back something\nlike:\nFinally, we run the chosen function with the extracted numbers:\nPut it all together and you get:\n    yaml_str = response_text.split(\"```yml\")[1].split(\"```\")[0].strip(\n    result_data = yaml.safe_load(yaml_str)\n    function_name = result_data[\"tool\"][\"name\"]\n    parameters = result_data[\"tool\"][\"parameters\"]\n    return function_name, parameters\n(\"multiply_numbers\", {\"a\": 1567, \"b\": 428})\nStep 4: Call Function\ndef call_function(function_name, arguments):\n    # Map function names to actual functions\n    functions = {\n        \"add_numbers\": add_numbers,\n        \"subtract_numbers\": subtract_numbers,\n        \"multiply_numbers\": multiply_numbers,\n        \"divide_numbers\": divide_numbers\n    }\n    # Run it!\n    return functions[function_name](**arguments)\ndef process_math_question(question):\n    tools = get_functions()\n    function_name, arguments = select_function(tools, question)\n    result = call_function(function_name, arguments)\n    return result\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling7/19\n\nThe real power is that the AI knows when to ask for help, picks the right tool for t\njob, pulls the necessary information from your question, and formats everything\ncorrectly.\nThis works for way more than just math - weather checks, appointment schedulin\ndatabase searches - function calling bridges the gap between AI's language skills a\nreal-world tools.\nBut traditional function calling has a huge limitation: your tools and AI must live \nthe same process. Think of it like this: it's as if your smartphone and coffee maker\nto be physically attached to each other with a cable to work together. Not very\npractical, right?\nWhat does this mean in real life? If you want to add a cool spreadsheet analyzer to\nClaude, you can't - because you don't have access to Claude's internal code. You ca\nadd new capabilities to Cursor unless they specifically build a way for you to plug\nthings in. Every AI system would need your exact code reimplemented specifically\ntheir environment.\nThis limitation is exactly what MCP was designed to solve, as we'll see next.\nEver tried connecting your AI to a closed-source app? Or wished you could just sa\n\"Claude, use my calculator\" without coding? MCP tears down the walls between y\nAI and your tools.\n# Example\nanswer = process_math_question(\"What is 1,567 multiplied by 428?\")\nprint(f\"The answer is: {answer}\")  # 670,676\nThe Big Problem With Function Calling\n3. MCP: Function Calling With Superpowers\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling8/19\n\nMCP's Big Idea: Split It Up! MCP breaks this problem by separating the tools from\nAI using them:\nMCP Server is where your actual tools live. Your calculator, weather checker, \nemail sender goes here. It runs completely separate from the AI and can be\nwritten in any programming language. It's like setting up a food truck that ser\njust one specialized dish - but does it really well.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling9/19\n\nMCP Client serves as the connector (usually part of the AI agent). It finds wha\ntools are available, helps the AI format requests correctly, and handles\ncommunication with servers. Think of it as the food delivery app that knows a\nthe food trucks in town and how to place orders with each one.\nZach's Note: The original MCP terminology with \"Server, Client, Host\" can be confusi\nCommon architecture only has client and server, but don't further separate \"hosts\" and\n\"clients\" this way. This separation likely derives from extension/plugin system architec\n(like VS Code's extension model or browser extension systems). The traditional client-s\nmodel is sufficient for understanding.\nLet's remake our calculator with MCP:\nCLIENT SIDE: Nothing to do yet! The client doesn't need to know how these\nwork - that's the point!\nSERVER SIDE: This is where your tool actually lives.\nStep 1: Implement Functions\nfrom fastmcp import FastMCP\n# Create a server with a name\nmcp = FastMCP(\"Math Operations Server\")\n# Add some math tools\n@mcp.tool()\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers together\"\"\"\n    return a + b\n@mcp.tool()\ndef subtract(a: int, b: int) -> int:\n    \"\"\"Subtract b from a\"\"\"\n    return a - b\n# ... more functions ...\n# Fire it up\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling10/19\n\nCLIENT SIDE: The client connects to the server and asks what it can do.\nSERVER SIDE: The server responds with details about each tool - what they'r\ncalled, what they do, what inputs they need. It's like a menu board at that food\ntruck - listing everything they serve along with ingredients and prices. FastMC\nhandles this automatically by exposing a standard protocol endpoint when\nmcp.run().\nCLIENT SIDE: The client is responsible for deciding which function to use b\non the user's request. This typically involves asking the LLM to make this\ndecision.\nif __name__ == \"__main__\":\n    mcp.run()\nStep 2: List Functions\nimport os\nMCP_SERVER_PATH = os.environ.get(\"MCP_SERVER_PATH\", \"simple_server.py\"\ndef list_functions():\n    \"\"\"Find out what tools are available.\"\"\"\n    async def _get_tools():\n        server_params = StdioServerParameters(\n            command=\"python\",\n            args=[MCP_SERVER_PATH]\n        )\n        async with stdio_client(server_params) as (read, write):\n            async with ClientSession(read, write) as session:\n                await session.initialize()\n                tools_response = await session.list_tools()\n                return tools_response.tools\n    return asyncio.run(_get_tools())\nStep 3: Select Function\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling11/19\n\nSERVER SIDE: Not involved in this step - the server simply waits for function\ncalls. Like our food truck chef waiting for orders to come in.\ndef select_function(tools, question):\n    \"\"\"Figure out which tool to use.\"\"\"\n    from openai import OpenAI\n    import yaml\n    prompt = f\"\"\"\n## Question\n{question}\n## Tools\n{tools}\n## Respond in this format:\n```yml\nthinking: <your reasoning>\ntool: \n  name: <tool_name>\n  parameters:\n    <param_name>: <param_value>\n    ...\n```\"\"\"\n    client = OpenAI()\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    response_text = response.choices[0].message.content\n    yaml_str = response_text.split(\"```yml\")[1].split(\"```\")[0].strip(\n    result_data = yaml.safe_load(yaml_str)\n    tool_name = result_data[\"tool\"][\"name\"]\n    parameters = result_data[\"tool\"][\"parameters\"]\n    return tool_name, parameters\nStep 4: Call Function\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling12/19\n\nCLIENT SIDE: Sends the request to the server.\nSERVER SIDE: Does the actual work and returns the result. The server runs t\ntool and returns the answer - all without the AI needing to know how the tool\nworks! Just like you don't need to know how to cook pad thai to order it from \nfood truck.\nMCP completely changes how AI and tools work together:\nTools Connect, Don't Embed: Tools aren't stuffed inside AI apps; they conne\nthrough a standard protocol. It's like Bluetooth for AI - connect anything that\nspeaks the same language.\nEverything's Modular: Each tool can update independently without changing\nAI - swap out your calculator without disrupting your email sender.\nBuild Once, Use Everywhere: Create a tool and use it with any MCP-compati\nAI. Write a weather checker once and use it with Claude, Cursor, or your cust\nbot.\ndef call_function(tool_name, parameters):\n    \"\"\"Run a tool on the MCP server.\"\"\"\n    async def _call_tool():\n        server_params = StdioServerParameters(\n            command=\"python\",\n            args=[MCP_SERVER_PATH]\n        )\n        async with stdio_client(server_params) as (read, write):\n            async with ClientSession(read, write) as session:\n                await session.initialize()\n                result = await session.call_tool(tool_name, parameters\n                return result.content[0].text\n    return asyncio.run(_call_tool())\nThe Bottom Line on MCP\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling13/19\n\nThis is incredibly useful for closed-source AI systems where you want to add new\ncapabilities but can't modify the code, and for non-technical folks who don't want\nmess with integration.\nCheck out the MCP Example on GitHub for a demo that shows the difference between M\nand function calls with just a simple toggle.\nWith all the excitement around MCP, let's do a reality check on some common cla\n⚖ Partially Accurate\nMCP is marketed as \"a USB-C port for AI applications,\" but let's break this down\nThere are two types of standards that people often confuse:\nAt the application level, OpenAI and Anthropic already had standardized for\nfor function definitions. They have annoying differences (OpenAI uses\nparameters; Anthropic uses input_schema) so standardization is helpful.\nAt the transport level, MCP does shine with multiple transport options (stdio\nSSE). Unlike OpenAI's ChatGPT Plugins which only use HTTP/REST, which i\nlimited for local calls. This flexibility enables both local and remote operation\nSo yes, MCP brings better standardization, but it's not necessarily \"the first.\"\n❌ Not Accurate\n4. The Myth or the Hype?\n\"MCP is the first standardized way for tools\"\n\"As the number of functions grows, MCP makes it\nsimpler for agents to select them\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling14/19\n\nThis claim is like saying having 500 restaurants in your food delivery app makes it\neasier to decide what to eat for dinner. Having 500 tools via MCP instead of 500 di\nfunctions doesn't magically solve the selection problem. The selection is still done\nthe client which still needs custom logic to decide which tool to use, typically with\nanother LLM call. Both approaches face the same challenge: LLMs are notorious\nBAD at choosing the right tool from many options. MCP makes the integration w\navailable tools easier but doesn't make the AI any better at picking between them.\n❌ Not Accurate\nThis isn't unique to MCP. ChatGPT's plugins already allow new tools from Instaca\nShopify , Slack , Wolfram , Zapier , and more. However, ChatGPT's plugins have show\nthat simple integration isn't enough - you need smart design around each tool for \nactually improve results. Having access to tools doesn't guarantee they'll be used\neffectively. Adding tons of tools often makes performance worse, not better. Most\nagents struggle when choosing between more than ~10 tools. Effective tool use ne\nthoughtful workflow design, not just plugging in more tools.\n⚖ Partially Accurate\nThere's some truth here, but let's not oversell it. MCP does provide a standardized\n/tools/list endpoint for consistent discovery, but the discovery mechanism is\npretty basic - just a flat list of tools. Provide the same list to a traditional function \nsystem, and you get similar results. Where MCP truly shines is from an economic\nperspective - once you have a standard, you attract both MCP function providers a\nconsumers. It's like the App Store effect - the standard attracts developers, which\nattracts users, which attracts more developers. Such convergence makes discovery\neasier through a growing ecosystem, rather than through technical superiority.\n\"MCP uniquely allows users to add new abilities to\nagents on-the-fly, that aren't pre-specified\"\n\"MCP tool discovery is superior\"\n\"MCP is more secure\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling15/19\n\n⚖ Partially Accurate\nWe need to clarify what kind of security we're talking about:\nProcess isolation: ✅ Yes! Separate processes mean your WhatsApp message t\nwon't crash your Claude AI. It's like having your email and browser in separat\napps - if your browser crashes, you don't lose your email draft.\nUser data protection: ⚠ Maybe not. Your WhatsApp messages could still be\nleaked if you're using a malicious MCP server. MCP includes human approval\ntool execution and standardized error handling, which helps. But this is like\nhaving a security guard who just asks \"Are you sure?\" before letting you do\nsomething potentially dangerous. Better than nothing, but not foolproof.\n✅ Accurate\nThis is where MCP genuinely shines. With traditional function calling, adding new\nfunctions means changing your agent code. With MCP, functions live on servers\ncompletely separate from the client. New tools can be added without touching clie\ncode at all.\nIt's like how you can install a new app on your phone without having to update the\noperating system. You can connect any language and environment - Python AI to\nJavaScript tools, local to cloud, whatever works best. For building AI-facing functi\nthis flexibility is super valuable! You design the right operations, expose it as an M\nserver, and don't worry about the agent.\nSo is MCP right for you? It depends on who you are:\n⚠ For Technical Agent Developers: MCP solves the integration part, but if\nyou're focused on building high-performance, reliable systems, integration is \n\"MCP allows function updates without modifying the\nagent code\"\n5. Conclusion: Who is MCP For?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling16/19\n\nthe beginning - actually the easy part. There are much harder aspects of system\ndesign and tool orchestration that remain. For critical tasks, you might want t\ndesign custom function calls tailored to your specific needs rather than relyin\nthe standardized approach. The added abstraction layer may not provide\nsignificant benefits for sophisticated agent development.\nI'll be writing a follow-up tutorial on function call design best practices for buil\nhigh-performance agents - stay tuned!\n✅ For Non-Technical Users: MCP offers a \"magical\" experience, allowing AI\nassistants like Claude to seamlessly integrate with your tools. It's like giving y\nsmart speaker the ability to control not just your lights, but also your custom-\nrobot butler. It's perfect when you need to augment off-the-shelf and potentia\nclosed-source AI agents like Claude AI. If your tasks aren't overly complex an\nyou just want something that \"works out of the box\" without diving into code\nMCP delivers exactly that experience.\n✅ For Tool Builders: MCP shines brightest here, letting you build once and\nconnect to any compatible AI system without modifying source code. You can\ncreate tools in any language you prefer, expose them either locally or remotely\nmake them standardized and discoverable across the ecosystem. It's like build\na Lego piece that fits with any Lego set, no matter who made it. This dramatic\nsimplifies distribution - build a great tool and every MCP-compatible system \nuse it immediately.\nWith what you've learned, you can now evaluate whether MCP makes sense for yo\nspecific needs - whether you're building advanced AI systems, looking to augment\nyour favorite assistant with custom capabilities, or creating tools that AI can lever\nThe real power of MCP isn't technical superiority but rather its potential to\ndemocratize AI tool creation and connection for everyone.\nWant to see the differences in action? We've created a simple example implementation th\nlets you toggle between traditional function calling and MCP with minimal code changes!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling17/19\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n22 Likes\nDiscussion about this post\nPreviousNext\nWrite a comment...\nMay 5\nLiked by Zachary Huang\nMichael Roos\nGreat article, been loving all your posts.\nI've always considered MCP great for 3rd party integrations, in more of a plugin style model\ntool calling still has uses for developing more complex AI driven algorithms, like giving it an a\nfunction or a DB read function and the model can solve more things all in one prompt, and y\nokay with tool calls being tightly coupled\nWould be great to see an article on PocketFlow and how you'd approach implementing tool \nand LLM driven state transitions to do more complex and non-linear tasks.\nLIKE (2)REPLY\nMay 20\nLiked by Zachary Huang\nLixx\nThank you for your article. It has been of great help to me.\nLIKE (1)REPLY\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling18/19\n\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:37 PMMCP Simply Explained: Function Calling Rebranded or Genuine Breakthrough?\nhttps://pocketflow.substack.com/p/mcp-simply-explained-function-calling19/19"
  },
  {
    "filename": "PocketBlog250413.pdf",
    "title": "A2A Protocol Simply Explained: Here are 3 key",
    "date": "2025-04-13",
    "content": "\n\nA2A Protocol Simply Explained: Here are 3 key\ndifferences to MCP!\nAPR 13, 2025\n1Sh\nImagine a world where your AI Agents don't just work FOR you, but work WITH each\nother! Google's Agent-to-Agent (A2A) protocol promises to turn solo AI performers int\ncollaborative team players. But how does it stack up against Anthropic's Model Contex\nProtocol (MCP)? Time to break down the buzz!\nThink about how you work with colleagues on complex projects. You share\ninformation, ask questions, and build on each other's expertise. Now imagine your\nZACHARY HUANG\n19\nIntroduction: The Dawn of Collaborative AI\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here1/16\n\nAgents doing the same thing—not just working in isolation, but actively collaborat\nto solve your problems.\nThat's exactly what Google is aiming for with their new Agent-to-Agent (A2A)\nprotocol, released on April 9, 2025. Instead of each AI Agent being a lone worker, \nturns them into team players. Your research Agent could seamlessly pass findings \nyour writing Agent, or your travel planner could check with your finance Agent to\nensure hotel options fit your budget—all without you having to play middleman. T\ndeveloper community is clearly excited—over 7,000 GitHub stars in just days after\nlaunch says it all. But this isn't the first attempt at getting AI systems to work\ntogether. Anthropic introduced their Model Context Protocol (MCP) with similar \nnot long ago.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nSo what's a developer to make of these options? Is A2A just MCP with a different\nname? Should you invest time learning one over the other? Or do they serve diffe\npurposes entirely?\nIn this simple tutorial, I'll cut through the marketing hype to:\nExplain both protocols in plain language anyone can understand\nHighlight the 3 technical differences that impact how you'll use them\nReveal how these protocols might actually complement rather than compete w\neach other\nNo technical jargon overload—just clear insights into how these protocols are\nreshaping AI collaboration. By the end, you'll understand exactly what A2A brings\nthe table that MCP doesn't (and vice versa). Ready to see what all the buzz is about\nLet's dive in!\nMCP vs. A2A: Explained to Grandmother\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here2/16\n\nImagine you're planning a dream vacation to Hawaii. There's so much to figure ou\nYou need to:\nCheck weather forecasts to pick the best month\nFind flights within your budget\nPlan activities based on local recommendations\nConvert your dollars to understand local prices\nThat's a lot of different tasks requiring different expertise! Now, suppose you have\nAI Agent like Claude to help you. You ask, \"Claude, what's the weather like in Ma\nnext week?\"\nBut here's the problem: Claude was trained on older data and doesn't know today\nweather or next week's forecast. It's like asking your smart friend about the weath\nin a city they haven't visited recently – they simply don't know! This is where our t\nimportant standards come in to save the day.\nModel Context Protocol (MCP) is like giving any AI Agent the ability to use\nspecialized tools when needed.\nBefore MCP, the conversation might go like this:\nYou: \"What's the weather in Maui next week?\"\nClaude: \"I don't have access to real-time weather data or forecasts. You'd need \ncheck a weather service for that information.\"\nPretty disappointing, right? But with MCP:\nYou: \"What's the weather in Maui next week?\"\nClaude: [internally uses MCP to connect to a weather service] \"According to the late\nMCP: Giving AI Agents Super Powers\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here3/16\n\nforecast, Maui will be sunny with temperatures around 82°F next week, with a b\nshower expected on Wednesday afternoon.\"\nWhat's actually happening behind the scenes is like a magic trick with four simple\nsteps:\n1. Discover Available Superpowers: Claude peeks into its toolbox asking, \"What\ncool gadgets do I have today?\" and discovers there's a weather service ready to\nuse!\n(Code Reference: Uses list_tools method)\n2. Make the Perfect Request: Claude crafts a crystal-clear message: \"Hey Weath\nTool, what's the forecast for Maui next week?\" (but in computer-speak)\n(Code Reference: Uses call_tool)\n3. Get the Expert Answer: The weather service does its weather-magic and repli\n\"Maui: 82°F, sunny, with a sprinkle on Wednesday!\"\n(Code Reference: Uses Tool.run)\n4. Translate to Human-Friendly: Claude takes this weather-speak and turns it in\nfriendly, conversational response just for you\n(Code Reference: Gets result from call_tool)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here4/16\n\nThe magic here is that MCP provides a standard way for ANY AI Agent to connec\nANY tool. It's like creating a universal adapter that works with all appliances and \npower outlets.\nFor tool builders, this means they only need to build their weather API, calculator\nemail sender once following the MCP standard, and it will work with Claude, GPT\nGemini, or any other MCP-compatible Agent.\nFor users like you and grandma, it means your AI can suddenly do all sorts of thin\ncouldn't do before - check real-time weather, send actual emails, book real\nappointments, all without being explicitly programmed for each task.\nBut what about that complex Hawaii trip planning? You need more than just weat\ndata - you need specialized expertise in flights, hotels, activities, budgeting, and m\nThis is where Agent-to-Agent (A2A) protocol shines. While MCP connects an AI t\ntools, A2A connects specialized AI Agents to each other.\nImagine having a travel dream team:\nA flight-finding specialist who knows every airline and route\nA hotel expert who can match accommodations to your preferences\nA local guide specialist familiar with Hawaiian activities and culture\nA budget manager who helps keep spending in check\nWith A2A, your personal Agent can delegate specific parts of your vacation planni\nto these specialists, then collect and organize their expert answers.\nBefore A2A, the conversation might go like this:\nYou: \"Plan my 5-day trip to Hawaii in June with a $3000 budget.\"\nPersonal Agent: \"I can provide some general recommendations, but I don't hav\nA2A: Assembling Your AI Dream Team\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here5/16\n\naccess to current flight prices or hotel availability. For activities, I can suggest\npopular options, but can't confirm if they'll fit your specific dates or budget.\"\nNot very helpful for actually booking your dream vacation! But with A2A:\nYou: \"Plan my 5-day trip to Hawaii in June with a $3000 budget.\"\nPersonal Agent: [internally delegates to specialist agents] \"I've prepared a complet\nday Hawaii itinerary for June! Your round-trip flights from LAX ($650) plus the\nbeachfront hotel in Maui ($1200) leave $1150 for activities. I've scheduled snork\nat Molokini Crater on day 2 ($145/person), a traditional luau on day 3 ($120/pers\nand the Road to Hana tour on day 4 ($210/person). That leaves about $675 for me\nand souvenirs. Would you like me to book any of these options?\"\nBehind the scenes, your personal Agent uses A2A to orchestrate this vacation\nsymphony:\n1. Find the Right Experts: Your Personal Agent flips through its digital Rolodex\n\"business cards\" (AgentCard) to see which specialist agents can help with trave\nactivities, and budgeting. (Code Reference: Uses A2ACardResolver to fetch the car\n2. Divide and Conquer: The Personal Agent splits your vacation dream into\nmanageable pieces:\nJob 1: Find flights/hotels → Travel Agent\nJob 2: Suggest activities → Local Guide Agent\nJob 3: Check budget → Budget Agent\n3. Assign the Flight Mission:\nThe Personal Agent wraps Job 1 into a neat digital package (Task) with a\ntracking number like \"task-123\"\nIt ships this package to the Travel Agent using the tasks/send comman\n(Code Reference: Uses A2AClient.send_task with TaskSendParams)\nThe Travel Agent gets to work hunting for the perfect flights and hotels!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here6/16\n\nPersonal Agent → Travel Agent: \"Find affordable flights to Hawaii from L\nand hotel options in Maui for 5 days in June, for a couple with a total budg\n$3000.\"\nTravel Agent → Personal Agent: \"Found round-trip LAX to OGG (Maui) f\n$650/person on Hawaiian Airlines. The Aloha Beach Resort has rooms for\n$240/night, totaling $1200 for 5 nights. Both options include free cancellat\n4. Repeat for Activities and Budget:\nThe Personal Agent does the same package-and-send dance for the other \ngiving each specialist their own mission and tracking number.\nPersonal Agent → Local Guide: \"What are the best activities for a couple \nMaui for 5 days in June with about $1150 left after flights and hotel?\"\nLocal Guide → Personal Agent: \"Recommended activities: Molokini Crat\nsnorkeling ($145/pp), traditional luau at the Old Lahaina Luau ($120/pp), an\nRoad to Hana guided tour ($210/pp). These are highly rated and available i\nJune.\"\nPersonal Agent → Budget Agent: \"Does this plan fit within $3000: $650\nflights, $1200 hotel, $475 for main activities, plus food and souvenirs?\"\nBudget Agent → Personal Agent: \"The essentials total $2325, leaving $675\nmeals and souvenirs. This is approximately $135/day for food and extras, w\nis reasonable for Hawaii if you mix restaurant meals with more affordable\noptions.\"\n5. Play the Waiting Game:\nJust like tracking a delivery, the Personal Agent periodically asks, \"Is task-\ndone yet?\" using the tasks/get command (Code Reference: Uses\nA2AClient.get_task)\nWhen an agent responds with \"completed\" (TaskStatus, TaskState), the Pers\nAgent grabs the goodies in the response package (Artifact).\n6. Create Vacation Magic: The Personal Agent weaves together all the expert\nrecommendations into one beautiful, ready-to-enjoy vacation plan just for you\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here7/16\n\nYour personal Agent then compiles all this specialist knowledge into one cohesive\nplan. The entire process is seamless to you - you just get a complete, expert-crafted\nvacation itinerary!\nThe real magic happens when MCP and A2A work together:\n1. Your personal Agent uses A2A to connect with specialized AI agents\n2. Each specialized agent uses MCP to connect with specific tools they need\n3. The result is a network of AI Agents, each with their own superpowers, all\nworking together on your behalf\nIt's like having both a team of expert consultants (A2A) AND giving each consulta\ntheir own specialized equipment (MCP). Together, they can accomplish complex ta\nthat no single AI could handle alone.\nThe Beautiful Combination\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here8/16\n\nThe key difference is who's talking to whom:\nMCP: AI Agents talking to tools (Claude + weather service)\nA2A: AI Agents talking to other AI Agents (Trip planner + hotel expert)\nAnd the best part? Build once, connect anywhere. These standards ensure that new\ntools and new Agents can join the ecosystem without requiring custom code for ea\npossible combination.\nTo see minimal working code examples of these protocols in action:\nFor a simple MCP implementation, check out the PocketFlow MCP Example\nFor a basic A2A implementation, visit the PocketFlow A2A Example\nThat whole \"MCP talks to tools, A2A talks to agents\" explanation? It's a good star\nbut if you're hungry for more, you might be thinking, \"Wait, isn't that too simplist\nYou'd be right! The boundary between \"tools\" and \"agents\" is actually pretty fuzzy\nfact, as OpenAI's documentation shows, you can even use entire agents as tools!\nImagine asking your AI Agent to use another AI Agent as a tool - it gets meta pret\nquickly.\nIf you're not satisfied with the surface-level explanation and want to dig deeper, yo\nin the right place. Let's peel back the layers and look at the actual code-level\ndifferences that make these protocols fundamentally distinct - beyond just who's\ntalking to whom!\nQuick disclaimer: What follows is Zach's personal understanding of these differen\nbased on working with both protocols. I could be wrong about some details! If you\nspot something off, drop me a note - I'm all about learning together here.\nBeyond Tools vs. Agents: The Real Technical\nDifferences\nDifference 1: Natural Language vs. Structured Schema\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here9/16\n\nWith A2A, you simply say \"How much is 100 USD in Canadian dollars?\" With MC\nyou need to match exactly what the currency tool expects - like {\"currency_fro\n\"USD\", \"currency_to\": \"CAD\", \"amount\": 100}. It's a completely differ\napproach to communication!\nA2A embraces natural language just like we humans talk to each other:\nThe receiving agent interprets this request however it's able to - just like when you\na friend for help. There's no strict format required.\nMCP, on the other hand, demands exact parameters that match a predefined schem\nIf you don't provide exactly what the tool expects (maybe it wants \"from_currency\ninstead of \"currency_from\"), the call fails. No wiggle room here!\nThink about calling customer service. With A2A, it's like talking to a helpful\nrepresentative who can understand your problem even if it doesn't fit neatly into\ncategories. With MCP, it's like filling out a rigid form that only accepts specific in\nin specific fields.\nA2A's Human-Like Communication\n# A2A Client sending a task\nuser_message = Message(\n    role=\"user\", \n    parts=[TextPart(text=\"How much is 100 USD in CAD?\")]\n)\nMCP's Precise Parameter Requirements\n# MCP Client calling a tool\ntool_name = \"get_exchange_rate\"\n# Must match EXACTLY what the tool expects\narguments = {\"currency_from\": \"USD\", \"currency_to\": \"CAD\"}\nWhy This Matters\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here10/16\n\nThe natural language approach of A2A means it can handle \"out of the box\" reque\nand adapt to new situations - like asking \"Is $100 USD enough for dinner for two i\nToronto?\" A natural language agent can figure out this requires currency knowled\nplus local restaurant pricing. Meanwhile, MCP's strict schema approach means\nreliable, predictable results - perfect when you need exact answers to standard\nquestions.\nA2A treats work as complete tasks with a lifecycle, while MCP treats them as\nindividual function calls. It's like the difference between a project manager (A2A) \na calculator (MCP).\nA2A is built around the concept of a \"Task\" that has a complete lifecycle with mul\nstates:\nTasks can flow naturally through different states - they can start, require more inp\nproduce partial results, and eventually complete or fail. The protocol itself manage\nthis lifecycle, making it perfect for complex, multi-stage work with uncertainty.\nMCP operations are fundamentally single-stage - they either succeed or fail:\nDifference 2: Task Lifecycle vs. Function Calls\nA2A's Multi-Stage Task Management\n# A2A Task has explicit states in its lifecycle\n{\n    \"id\": \"task123\",\n    \"status\": {\n        \"state\": \"running\",  # Can be: pending → running → \ncompleted/failed\n        \"startTime\": \"2025-04-12T10:30:00Z\"\n    },\n    \"artifacts\": [...]  # Partial results as they're created\n}\nMCP's Single-Stage Operations\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here11/16\n\nIf a tool needs more information, it can't request it within the protocol - it must ei\nreturn an error or the client application must handle creating a new, separate requ\nProgress updates are optional add-ons, not core to the operation's lifecycle.\nThink about renovating a house vs. using individual tools. A2A is like hiring a\ncontractor who manages the entire renovation project - they'll handle all the stage\ngive you updates, and work through unexpected issues. MCP is like calling individ\nspecialists - the plumber does one thing, the electrician another, with no one track\nthe overall project.\nA2A shines for complex, multi-stage work where there's uncertainty and a need fo\nadaptability. Research projects, creative work, and problem-solving all fit this mod\nMCP excels when you need precise, individual operations with predictable inputs \noutputs - calculations, data retrievals, and specific transformations.\nA2A describes what agents can do in general terms, while MCP spells out exactly w\nfunctions are available and how to call them.\nA2A describes an agent's abilities in high-level, flexible terms:\n# MCP has no built-in \"in-progress\" or \"needs more input\" states\nresult = client.call_tool(\"get_exchange_rate\", {\"from\": \"USD\", \"to\": \n\"CAD\"})\n# If arguments are invalid or missing, it simply fails with an error\n# There's no protocol-level \"input-required\" state\nWhy This Matters\nDifference 3: High-Level Skills vs. Specific Functions\nA2A's Capability Descriptions\n# A2A AgentCard example\nagent_skill = AgentSkill(\n    id=\"research_capability\",\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here12/16\n\nIt's like a resume that tells you what someone is good at, not exactly how to assign\nthem work.\nMCP precisely defines each available function:\nIt's like an instruction manual that leaves nothing to interpretation.\nThink about delegating work. A2A is like telling a team member \"You're in charge\nthe research portion of this project\" - they'll figure out the details based on their\nexpertise. MCP is like giving exact step-by-step instructions: \"Search these three\ndatabases using these exact terms and format the results this way.\"\n    name=\"Research and Analysis\",\n    description=\"Can research topics and provide analysis.\",\n    examples=[\n        \"Research quantum computing advances\",\n        \"Analyze market trends for electric vehicles\"\n    ]\n    # Notice: no schema for how to invoke these skills!\n)\nMCP's Function Specifications\n# MCP tool definition\n{\n  \"name\": \"get_exchange_rate\",\n  \"description\": \"Get exchange rate between currencies\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"currency_from\": {\"type\": \"string\"},\n      \"currency_to\": {\"type\": \"string\"}\n    },\n    \"required\": [\"currency_from\", \"currency_to\"]\n  }\n}\nWhy This Matters\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here13/16\n\nA2A's approach allows for creativity, initiative, and handling unexpected situation\nThe agent can adapt its approach based on what it discovers along the way.\nMCP's approach ensures consistency, predictability, and precise control over exac\nwhat happens and how.\nThese three technical differences reflect fundamentally different visions of AI\ncollaboration:\nMCP's Philosophy: \"Tell me EXACTLY what you want done and how to do it\nA2A's Philosophy: \"Tell me WHAT you want accomplished, I'll figure out HO\nThink of MCP as building with Lego pieces - precise, predictable, combinable in c\nways. A2A is more like clay - flexible, adaptable, able to take forms you might not \ninitially imagined.\nThe beauty is that you don't have to choose! Many sophisticated systems will\nimplement both: MCP for precise tool execution and A2A for collaborative proble\nsolving between specialized agents.\nWe've unpacked the key differences between A2A and MCP, and here's the bottom\nline: these aren't competing standards—they're complementary approaches solvin\ndifferent parts of the same puzzle.\nThink of MCP as building precise tools and A2A as assembling skilled teams. The\nmagic happens when you combine them:\nMCP gives individual AI Agents superpowers through standardized tool\nconnections\nA2A enables those powered-up Agents to collaborate on complex tasks\nThe Philosophy Difference\nConclusion: The Future is Collaborative AI\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here14/16\n\nTogether, they form an ecosystem where specialized expertise and capabilitie\ncan flow seamlessly\nFor developers, this means you don't have to choose sides in some imaginary proto\nwar. Instead, ask yourself: \"Do I need precise tool execution (MCP), agent\ncollaboration (A2A), or both?\" The answer depends entirely on your use case.\nWhere do we go from here? Expect to see increasing integration between these\nprotocols as the AI ecosystem matures. The companies behind them understand th\ninteroperability is the future—siloed AI Agents will become a thing of the past. Th\nmost powerful applications won't just use one Agent with a few tools; they'll\norchestrate entire teams of specialized agents working together. As a developer,\npositioning yourself at this intersection means you'll be building the next generati\nof truly collaborative AI systems.\nLooking to implement these protocols in your projects? Check out the minimal examples\nMCP and A2A on GitHub!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n19 Likes∙1 Restack\nDiscussion about this post\nPreviousNext\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here15/16\n\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMA2A Protocol Simply Explained: Here are 3 key differences to MCP!\nhttps://pocketflow.substack.com/p/a2a-protocol-simply-explained-here16/16"
  },
  {
    "filename": "PocketBlog250416.pdf",
    "title": "Build Chain-of-Thought From Scratch - Tutoria",
    "date": "2025-04-16",
    "content": "\n\nBuild Chain-of-Thought From Scratch - Tutoria\nfor Dummies\nAPR 16, 2025\n42S\nEver ask an AI a tricky question and get a hilariously wrong answer? Turns out, AI nee\nlearn how to \"think step-by-step\" too! This guide shows you how to build that thinking\nprocess from scratch, explained simply with code using the tiny PocketFlow framework\nWe've all seen it. You ask an AI assistant to solve a multi-step math problem, plan\ncomplex trip, or tackle a logic puzzle, and... facepalm. The answer is confidently w\ncompletely misses the point, or sounds like it just guessed. Why does this happen \nwith super-smart AI?\nOften, it's because the AI tries to jump straight to the answer without \"thinking it\nthrough.\" When we face tough problems, we break them down, figure out the step\nZACHARY HUANG\n16\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch1/18\n\nmaybe jot down some notes, and work towards the solution piece by piece. Good n\nwe can teach AI to do the same!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThis step-by-step reasoning is called Chain-of-Thought (CoT), and it's a huge deal\nAI right now. It's why the latest cutting-edge models like OpenAI's O1, DeepSeek\nGoogle's Gemini 2.5 Pro, and Anthropic's Claude 3.7 are all emphasizing better\nreasoning and planning abilities. They know that thinking is key to truly smart A\nInstead of just talking about it, we're going to build a basic Chain-of-Thought sys\nourselves, from scratch! In this beginner-friendly tutorial, you'll learn:\nWhat Chain-of-Thought really means (in simple terms).\nHow a basic CoT loop works using code.\nHow to make an AI plan, execute steps, and even evaluate its own work.\nWe'll use PocketFlow – a super-simple, 100-line Python framework. Forget complicate\nframeworks that hide everything! PocketFlow lets you see exactly how the thinking proce\nbuilt, making it perfect for understanding the core ideas from the ground up. Let's teach o\nto show its work!\nSo, what exactly is this \"Chain-of-Thought\" or CoT? Think of it like teaching an A\nsolve problems like a meticulous detective solving a complex case, rather than just\nmaking a wild guess.\nHere's how the AI tackles a problem using Chain-of-Thought:\nChain-of-Thought: How AI Learns to Show Its\nWork\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch2/18\n\n1. Understand the Case: First, the AI looks carefully at the problem you gave it \nlike a detective studying the initial crime scene and available clues.\n2. Make an Initial Plan: Based on the problem, the AI drafts a high-level plan – \nof steps it thinks it needs to take.\nDetective: \"Okay, first I need to interview the witness, then check the alibi, the\nanalyze the fingerprints.\"\n3. Execute One Step: The AI focuses on just the first pending step in its plan and\nthe work required for that step.\nDetective: Conducts the first witness interview.\n4. Analyze the Results (Self-Critique!): After completing the step, the AI looks a\nresult. Did it work? Does the information make sense? Is it leading towards th\nsolution? This evaluation step is crucial.\nDetective: \"Hmm, the witness seemed nervous. Does their story match the know\nfacts?\"\n5. Update the Case File & Plan: The AI records the results of the step (like addi\nnotes to a case file) and updates its plan. It marks the step as done, adds any new\nfindings, and crucially, might change or add future steps based on the evaluati\nDetective: \"Okay, interview done. Add 'Verify witness alibi' to the plan. And m\n'Re-interview later if alibi doesn't check out'.\"\n6. Repeat Until Solved: The AI loops back to Step 3, executing the next step on i\nupdated plan, analyzing, and refining until the entire plan is complete and the\nproblem is solved.\nThe Core Idea: Instead of one giant leap, Chain-of-Thought breaks problem-solvi\ninto a cycle of Plan -> Execute -> Evaluate -> Update.\nPocketFlow: The Tiny Toolkit We Need\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch3/18\n\nAlright, so we understand the idea behind Chain-of-Thought – making the AI act \na detective, step-by-step. But how do we actually build this process in code withou\ngetting lost in a giant, confusing mess?\nThis is where PocketFlow comes in. Forget massive AI frameworks that feel like\ntrying to learn rocket science overnight. PocketFlow is the opposite: it's a brilliant\nsimple tool, exactly 100 lines of Python code, designed to make building AI\nworkflows crystal clear.\nThink of PocketFlow like setting up a mini automated assembly line for our AI's\nthinking process:\nShared Store (The Central Conveyor Belt): This is just a standard Python\ndictionary (e.g., shared = {}). It holds all the information – the problem, th\nplan, the history of thoughts – and carries it between steps. Every step can rea\nfrom and write to this shared dictionary.\nNode (A Worker Station): This is a Python class representing a single task or\nstage on our assembly line. For CoT, we'll mostly use just one main worker sta\nnode. Each node has a standard way of working defined by three core method\nHere's what those methods do:\n# Our 'conveyor belt' starts with the problem\nshared = {\"problem\": \"Calculate (15 + 5) * 3 / 2\", \"thoughts\": []}\nclass Node:\n    def __init__(self): self.successors = {}\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass\n    def post(self, shared, prep_res, exec_res): pass\n    def run(self,shared): p=self.prep(shared); e=self._exec(p); return\nself.post(shared,p,e)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch4/18\n\n1. prep: Gets the station ready by pulling necessary data from the shared st\n(conveyor belt).\n2. exec: Performs the station's main job using the prepared data. This is wh\nour CoT node will call the LLM.\n3. post: Takes the result, updates the shared store, and signals which stati\nshould run next (or if the process should loop or end).\nFlow (The Assembly Line Manager): This is the controller that directs the\nshared data from one Node to the next based on the signals returned by the\npost method. You define the connections between stations.\nConnecting nodes is super intuitive:\nclass Flow(Node):\n    def __init__(self, start): self.start = start\n    def _orch(self,shared,params=None):\n        curr = self.start\n        while curr: action=curr.run(shared); \ncurr=curr.successors.get(action)\n# Define our main thinking station\nthinker_node = ChainOfThoughtNode()\n# Define the connections for looping and ending\nthinker_node - \"continue\" >> thinker_node # Loop back on \"continue\"\nthinker_node - \"end\" >> None # Stop on \"end\" (or go to a final node)\n# Create the flow manager, starting with our thinker node\nflow = Flow(start=thinker_node)\n# Run the assembly line!\nflow.run(shared)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch5/18\n\nWhy PocketFlow Rocks for This: Its simplicity and clear structure (Node, Flow, Shar\nStore) make it incredibly easy to visualize and build even sophisticated processes like \nChain-of-Thought loop, RAG systems, or complex agent behaviors, without getting bogg\ndown in framework complexity. You see exactly how the data flows and how the logic wo\nNow, here's the really neat part about implementing Chain-of-Thought with\nPocketFlow, something often obscured by complex frameworks:\nThe entire step-by-step thinking process can be handled by one single Node\nlooping back onto itself.\nForget needing a complicated chain of different nodes for planning, executing,\nevaluating, etc. We can build this intelligent behavior using an incredibly simple g\nstructure:\nThat's it! This simple graph structure powers our CoT engine:\n1. One Core Node (ChainOfThoughtNode): This is our \"thinker station\". It\ncontains all the logic for interacting with the LLM, managing the plan, and\nevaluating steps.\n2. One Loop Edge (\"continue\"): This arrow goes from the node back to itself. W\nthe node finishes a thinking cycle and decides more work is needed, it sends t\nChain-of-Thought: It's Just a Loop!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch6/18\n\n\"continue\" signal.\n3. One Exit Edge (\"end\"): This arrow points away (potentially to None or a fina\nreporting node). When the node determines the problem is solved, it sends th\n\"end\" signal.\n4. PocketFlow's Role: The Flow manager simply follows these arrows. It runs th\nChainOfThoughtNode, gets the signal (\"continue\" or \"end\") from its po\nmethod, and routes execution accordingly based on the connections we define\n(thinker_node - \"continue\" >> thinker_node).\nNo complex state machines, no hidden magic – just one node whose internal logic\ndecides whether to continue the loop or finish. The sophisticated, step-by-step\nreasoning emerges from the combination of:\nThe intelligence packed inside the ChainOfThoughtNode (specifically, how\nuses the LLM in its exec step).\nThis ultra-simple looping graph structure enabled by PocketFlow.\nLet's look inside that ChainOfThoughtNode to see how it makes the loop work.\nOur ChainOfThoughtNode is where the step-by-step magic happens. Each time\nPocketFlow runs this node (which is every loop cycle), it executes a simple three-p\nprocess defined by its prep, exec, and post methods. Let's walk through this cy\nusing our example problem: Calculate (15 + 5) * 3 / 2. We'll show simp\nPython code for each step first, then explain it.\nFirst, the node needs to grab the necessary information from the shared dictiona\n(our central data store) to know the current state of the problem.\nInside the Thinker Node: The Prep-Think-Upda\nCycle\n1. prep: Gathering the Ingredients\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch7/18\n\nExplanation: This prep method acts like getting ingredients before cooking. \nlooks into the shared dictionary and pulls out:\nThe original problem statement.\nThe thoughts history: A list containing the results (thinking, plan) from \nprevious cycles. It starts empty.\nThe current_plan: Usually found within the last entry in the thoughts\nhistory. If the history is empty, the plan is initially None.\nExample (Start of Loop 1): shared is {\"problem\": \"Calculate (15 + \n* 3 / 2\", \"thoughts\": []}. prep returns {\"problem\": \"...\",\n\"history\": [], \"plan\": None}.\nExample (Start of Loop 2): shared now contains the result of Loop 1, like\n{\"thoughts\": [{\"thinking\": \"...\", \"planning\": [...], ...}\nprep returns {\"problem\": \"...\", \"history\": [thought1], \"plan\nplan_from_thought1}.\nThis is the main event where we ask the LLM (AI Brain) to perform one cycle of\nChain-of-Thought reasoning. The key is the prompt we send.\ndef prep(self, shared):\n    problem = shared.get(\"problem\")\n    thoughts_history = shared.get(\"thoughts\", [])\n    # Helper to get the latest plan from the history\n    current_plan = self.get_latest_plan(thoughts_history)\n    return {\"problem\": problem, \"history\": thoughts_history, \"plan\": \ncurrent_plan}\n2. exec: The Core Thinking - Prompting the LLM\ndef exec(self, prep_res):\n    # prep_res holds the context from prep()\n    problem = prep_res[\"problem\"]\n    history_text = self.format_history(prep_res[\"history\"]) # Make \nhistory readable\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch8/18\n\n    plan_text = self.format_plan(prep_res[\"plan\"]) # Make plan readab\n    # --- Construct the Prompt ---\n    prompt = f\"\"\"\nYou are solving a problem step-by-step.\nProblem: {problem}\nHistory (Previous Steps):\n{history_text}\nCurrent Plan:\n{plan_text}\nYour Task Now:\n1. Evaluate the LATEST step in History (if any). State if \ncorrect/incorrect.\n2. Execute the NEXT 'Pending' step in the Current Plan. Show your wor\n3. Update the FULL plan (mark step 'Done', add 'result', fix if needed\n4. Decide if the overall problem is solved (`next_thought_needed: \ntrue/false`).\nOutput ONLY in YAML format:\n```yaml\nthinking: |\n  Evaluation: <Your evaluation>\n  <Your work for the current step>\nplanning:\n  # The FULL updated plan list\n  - description: ...\n    status: ...\n    result: ...\nnext_thought_needed: <true or false>\n```\n\"\"\"\n    # --- Call LLM and Parse ---\n    llm_response_text = call_llm(prompt) # Function to call the LLM AP\n    # Assume extracts and parses the YAML block\n    structured_output = \nyaml.safe_load(self.extract_yaml(llm_response_text))\n    return structured_output\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch9/18\n\nExplanation: The exec method orchestrates the LLM interaction:\n1. It takes the problem, history, and plan provided by prep.\n2. It formats the history and plan into readable text.\n3. It builds the prompt. Notice how the prompt explicitly tells the LLM the \nsteps: Evaluate -> Execute -> Update Plan -> Decide Completion. It also\nspecifies the required YAML output format.\n4. It calls the LLM with this detailed prompt.\n5. It receives the LLM's response and parses the structured YAML part into \nPython dictionary (e.g., {'thinking': '...', 'planning': [...]\n'next_thought_needed': True}).\nExample Prompt Built (Start of Loop 2):\nYou are solving a problem step-by-step.\nProblem: Calculate (15 + 5) * 3 / 2\nHistory (Previous Steps):\nThought 1:\n  thinking: |\n    Evaluation: N/A\n    Calculate 15 + 5 = 20.\n  planning: [...] # Plan with step 1 Done\nCurrent Plan:\n- {'description': 'Calculate 15 + 5', 'status': 'Done', 'result': 20}\n- {'description': 'Multiply result by 3', 'status': 'Pending'}\n# ... other steps ...\nYour Task Now:\n1. Evaluate the LATEST step...\n2. Execute the NEXT 'Pending' step... ('Multiply result by 3')\n# ... etc ...\nOutput ONLY in YAML format:\n# ...\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch10/18\n\nAfter the exec step gets the LLM's response, post saves the progress and tells\nPocketFlow whether to continue looping or stop.\nExplanation: The post method is the cleanup and signaling step:\n1. It takes the dictionary returned by exec (containing the LLM's latest\nthinking, planning, and next_thought_needed flag).\n2. It appends this entire dictionary to the thoughts list in the shared\ndictionary, building our step-by-step record.\n3. It checks the next_thought_needed flag.\n4. It returns the string \"continue\" if more steps are needed, or \"end\" if th\nLLM indicated the plan is complete.\nExample (End of Loop 2): exec_res contains {'next_thought_needed'\nTrue, ...}. post appends this to shared['thoughts'] and returns\n\"continue\".\n3. post: Saving Progress & Signaling the Loop\ndef post(self, shared, prep_res, exec_res):\n    # exec_res is the structured dict from exec() like {'thinking': .\n'planning': ..., 'next_thought_needed': ...}\n    if \"thoughts\" not in shared: shared[\"thoughts\"] = []\n    shared[\"thoughts\"].append(exec_res) # Add the latest thought cycle\nresults to history\n    # Decide the signal based on LLM's decision\n    if exec_res.get(\"next_thought_needed\", True):\n        signal = \"continue\"\n    else:\n        # Optional: Extract final answer for convenience\n        shared[\"final_answer\"] = \nself.find_final_result(exec_res.get(\"planning\", []))\n        signal = \"end\"\n    return signal # Return \"continue\" or \"end\" to PocketFlow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch11/18\n\nExample (End of Final Loop): exec_res contains {'next_thought_neede\nFalse, ...}. post appends this, maybe saves the final answer, and returns\n\"end\".\nSo, the ChainOfThoughtNode completes one cycle (prep -> exec -> post) and\nreturns a signal (\"continue\" or \"end\"). But how does the looping actually happe\nThat's managed by the PocketFlow Flow object, which acts like our assembly line\nmanager.\nHere's how we set it up in code:\nThis combination of the node's internal logic (producing the signal in post) and t\nFlow's simple routing based on those signals creates the powerful Chain-of-Thou\nloop.\nMaking it Loop: The PocketFlow Flow\n# 1. Create an instance of our thinker node\nthinker_node = ChainOfThoughtNode()\n# 2. Define the connections (the workflow rules)\n# If the node signals \"continue\", loop back to itself\nthinker_node - \"continue\" >> thinker_node\n# If the node signals \"end\", stop the flow (or go to a final node)\nthinker_node - \"end\" >> None\n# 3. Create the Flow manager, telling it where to start\ncot_flow = Flow(start=thinker_node)\n# Now we can run the process\n# Remember 'shared' holds our initial problem and accumulates thoughts\nshared = {\"problem\": \"Calculate (15 + 5) * 3 / 2\", \"thoughts\": []}\ncot_flow.run(shared)\n# After run() finishes, shared[\"final_answer\"] (if set in post)\n# and shared[\"thoughts\"] will contain the full process history.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch12/18\n\nLet's watch our Chain-of-Thought loop tackle a problem. For illustration, we'll us\nsimple multi-step arithmetic calculation: Calculate (15 + 5) * 3 / 2.\nNote: While this example is simple, this exact looping structure can handle much more\ncomplex reasoning, including problems like the Jane Street die-rolling probability puzzl\noften used in quant interviews. To see the detailed output for that challenging\nproblem, check out the Chain-of-Thought Cookbook example on GitHub.\nHere’s a summary of what happens inside the loop when the Flow runs, focusing \nthe LLM's output and highlighting the plan changes:\nLLM Task: Create initial plan, execute step 1.\nLLM Output (YAML): (Showing full plan this time)\npost Result: Saves Thought 1. Returns \"continue\".\nLLM Task: Evaluate Thought 1, execute step 2.\nLLM Output (YAML): (Using ... for unchanged parts)\nSee It In Action: Solving a Problem Step-by-St\nLoop 1 / Thought 1: Handling the Parentheses\nthinking: |\n  Evaluation: N/A (First step)\n  Problem is (15 + 5) * 3 / 2. Handle parentheses first.\n  Calculate 15 + 5 = 20.\nplanning:\n  - {'description': 'Calculate parentheses (15 + 5)', 'status': 'Done\n'result': 20} # <-- Step Executed & Updated\n  - {'description': 'Multiply result by 3', 'status': 'Pending'}\n  - {'description': 'Divide result by 2', 'status': 'Pending'}\n  - {'description': 'State final answer', 'status': 'Pending'}\nnext_thought_needed: true\nLoop 2 / Thought 2: Multiplication\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch13/18\n\npost Result: Saves Thought 2. Returns \"continue\".\nLLM Task: Evaluate Thought 2, execute step 3.\nLLM Output (YAML): (Using ... for unchanged parts)\npost Result: Saves Thought 3. Returns \"continue\".\nthinking: |\n  Evaluation: Correct. Addition 15 + 5 = 20 was right.\n  Next: Multiply previous result (20) by 3.\n  Calculate 20 * 3 = 60.\nplanning:\n  - {'description': 'Calculate parentheses (15 + 5)', 'status': 'Done\n'result': 20}\n  - {'description': 'Multiply result by 3', 'status': 'Done', 'result\n60} # <-- Step Executed & Updated\n  - {'description': 'Divide result by 2', 'status': 'Pending'}\n  - {'description': 'State final answer', 'status': 'Pending'}\nnext_thought_needed: true\nLoop 3 / Thought 3: Division\nthinking: |\n  Evaluation: Correct. Multiplication 20 * 3 = 60 was right.\n  Next: Divide previous result (60) by 2.\n  Calculate 60 / 2 = 30.\nplanning:\n  - {'description': 'Calculate parentheses (15 + 5)', 'status': 'Done\n'result': 20}\n  - {'description': 'Multiply result by 3', 'status': 'Done', 'result\n60}\n  - {'description': 'Divide result by 2', 'status': 'Done', 'result': \n30} # <-- Step Executed & Updated\n  - {'description': 'State final answer', 'status': 'Pending'}\nnext_thought_needed: true\nLoop 4 / Thought 4: Conclusion\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch14/18\n\nLLM Task: Evaluate Thought 3, execute step 4 (Conclusion).\nLLM Output (YAML): (Using ... for unchanged parts)\npost Result: Saves Thought 4. Saves 30 to shared['final_answer']. Ret\n\"end\". The Flow stops.\nThe method we built orchestrates thinking from the outside. However, some cuttin\nedge AI models are being developed to handle complex reasoning more autonomo\nessentially building the \"thinking\" process internally. Examples include models\nexplicitly trained for reasoning like OpenAI's O1, DeepSeek-R1, Google's Gemin\nPro, and Anthropic's Claude 3.7.\nA key concept powering some of these advanced models is the powerful synergy\nbetween step-by-step Thinking and automated Learning (like Reinforcement\nLearning). Think about learning a complex skill yourself – like mastering a new bo\ngame strategy or solving a tough math problem. You learn best not just by trying\nrandom things, but by:\n1. Thinking through your steps and plan.\nthinking: |\n  Evaluation: Correct. Division 60 / 2 = 30 was right.\n  All calculation steps are done. The final result is 30.\nplanning:\n  - {'description': 'Calculate parentheses (15 + 5)', 'status': 'Done\n'result': 20}\n  - {'description': 'Multiply result by 3', 'status': 'Done', 'result\n60}\n  - {'description': 'Divide result by 2', 'status': 'Done', 'result': \n30}\n  - {'description': 'State final answer', 'status': 'Done', 'result': \n30} # <-- Step Executed & Updated\nnext_thought_needed: false\nBeyond Our Loop: When AI Learns How to Thin\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch15/18\n\n2. Seeing the outcome.\n3. Reflecting on which parts of your thinking led to success or failure.\nThat \"thinking hard\" part makes the learning stick.\nAI Models are Learning This Too (e.g., DeepSeek-R1's Approach):\nGenerate Thinking: The AI attempts to solve a problem by generating its inte\nreasoning or \"thinking\" steps.\nProduce Answer: Based on its thinking, it comes up with a final answer.\nCheck Outcome: An automated system checks if the final answer is actually\ncorrect.\nGet Reward: If the answer is correct, the AI gets a positive \"reward\" signal.\nLearn & Improve: This reward signal teaches the AI! It updates its internal\nparameters to make it more likely to use the successful thinking patterns again n\ntime.\nThis cycle of think -> check answer -> get reward -> learn helps the AI become genuinely \nat reasoning over time. (For the nitty-gritty details on how DeepSeek-R1 does this wit\ntechniques like GRPO, check out their research paper!)\nNow you know the secret behind making AI tackle complex problems: Chain-of-\nThought is just a structured thinking loop!\n1. Plan: Create or review the step-by-step plan.\n2. Evaluate: Check the result of the previous step for correctness.\n3. Execute: Perform the next single step in the plan.\nConclusion: You've Taught an AI to Think Step\nby-Step!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch16/18\n\n4. Update: Record the results and refine the plan based on the evaluation and\nexecution.\n5. Loop (or End): Decide whether to repeat the cycle or finish.\nThe \"thinking\" – evaluating, executing, planning, and deciding – happens within t\nLLM, guided by the prompt we construct in our exec method. The looping itself \neffortlessly handled by PocketFlow's simple graph structure and the continue / \nsignals from our post method. Everything else is just organizing the information\nNext time you hear about advanced AI reasoning, remember this simple Evaluate \nExecute -> Update loop. You now have the fundamental building block to underst\nhow AI can \"show its work\" and solve problems piece by piece.\nArmed with this knowledge, you're ready to explore more complex reasoning syste\nWant to see the full code and try the challenging Jane Street quant interview question? C\nout the PocketFlow Chain-of-Thought Cookbook on GitHub!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n16 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch17/18\n\n2 more comments...\nWrite a comment...\nApr 17\nLiked by Zachary Huang\n1 reply by Zachary Huang\navi\nNice. Does this work only with reasoning models ? Or any LLM? And have you experimented\nfine tuning an LLM to implicitly do this cot ?\nLIKE (2)REPLY\nApr 28\nLiked by Zachary Huang\n1 reply by Zachary Huang\nAlex Rosenfeld\nReally appreciate your ability demonstrate the effectiveness of this flow with such an elegan\nsimple framework!\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:39 PMBuild Chain-of-Thought From Scratch - Tutorial for Dummies\nhttps://pocketflow.substack.com/p/build-chain-of-thought-from-scratch18/18"
  },
  {
    "filename": "PocketBlog250419.pdf",
    "title": "Structured Output for Beginners: 3 Must-Know",
    "date": "2025-04-19",
    "content": "\n\nStructured Output for Beginners: 3 Must-Know\nPrompting Tips\nAPR 19, 2025\n72S\nEver ask an AI to pull out key facts – like a name and email – hoping for neat, usable d\nlike name: Jane Doe, email: jane@example.com? Instead, you often get.\nrambling paragraph with the info buried inside. Sound familiar? It's like asking a chatt\nassistant for just a phone number and getting their life story! Trying to reliably parse th\nmess is frustrating. But what if you could easily get the clean output every time (like we\nin *this resume parsing example*)?\nZACHARY HUANG\n16\n1. Introduction: Taming the AI's Messy Notes\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-31/25\n\nWhile our AI buddies are getting scarily good at complex tasks (some are even lea\nto \"think step-by-step\"!), they don't always naturally format their answers in a way\ncode can easily understand. They're masters of language, but sometimes we just ne\nthe structured facts, ma'am.\nThat's where Structured Output swoops in to save the day. It's simply about getti\nthe AI to give you information back in a clean, predictable, organized format – thi\nneat lists, data fields with labels (key: value), or even simple tables – rather tha\njust a block of conversational text.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nWhy should you care? Because structured data is usable data.\nIt lets you seamlessly plug AI-generated insights into your applications.\nIt makes automating tasks like data extraction from documents a breeze.\nIt saves you from writing fragile, complex code just to parse slightly different\nphrasings of the same information.\nThe good news? You often don't need fancy, model-specific tools or complex libra\nto achieve this. While some models are adding specialized features for this, one of\nmost powerful and universal methods is surprisingly simple: just ask the AI nicely\n(but very specifically!) for the format you want.\nIn this tutorial, we'll cut through the noise and show you exactly how to do that.\nForget complicated schemas for now – we're focusing on 3 practical, easy-to-\nimplement tips using straightforward prompt engineering. These tricks will help \nreliably coax structured data out of almost any capable LLM today.\nReady to teach your AI to stop rambling and start organizing? Let's dive in!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-32/25\n\nSo, we've established that getting a wall of text back from an AI isn't always ideal.\nwhy is structure so important? Let's break it down.\nImagine you're building an app that uses an AI to analyze customer reviews. You a\nthe AI: \"Summarize this review and tell me the product mentioned and the custom\noverall sentiment.\"\nThe AI might reply:\n\"Well, it seems like the customer, Jane D., bought the 'MegaWidget 3000' and was quit\nunhappy. She mentioned it broke after just two days and found the whole experience v\nfrustrating.\"\nThat's helpful for a human, but for your app? Not so much. Your code now has to:\nFigure out where the product name is (\"MegaWidget 3000\").\nDetermine the sentiment (is \"unhappy\" or \"frustrating\" the main sentiment?)\nExtract maybe the customer name (if needed).\nHope the AI uses similar phrasing next time! If it says \"felt disappointed\" inst\nof \"unhappy,\" your sentiment parser might break.\nThis is brittle and prone to errors. What we really want is something predictable, l\nthis:\n2. Why Structure Matters: From Messy Text to\nUsable Data\nreview_analysis:\n  product_name: MegaWidget 3000\n  sentiment: Negative\n  summary: Customer reported the product broke after two days, leading\nto frustration.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-33/25\n\nThis is the power of structured output. It turns messy, conversational text into cle\norganized data that your code can reliably work with.\nGetting data in a predictable format unlocks a ton of possibilities. Here are just a \ncommon scenarios where structure is king:\n1. Extracting Key Information: Pulling specific details from text, like product in\nfrom a description:\n2. Summarizing into Bullet Points: Condensing information into easy-to-scan l\n3. Generating Configuration: Creating settings files for software or systems:\nStructure Superpowers: What Can You Do?\nproduct:\n  name: Widget Pro\n  price: 199.99\n  features:\n    - High-quality materials\n    - Professional grade\n    - Easy setup\n  description: |\n    A top-tier widget designed for serious users.\n    Recommended for advanced applications.\nsummary_points:\n  - Key finding one about the market trends.\n  - Important recommendation for the next quarter.\n  - A potential risk that needs monitoring.\nserver_config:\n  host: 192.168.1.100\n  port: 8080\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-34/25\n\n4. Classifying Text: Categorizing emails, support tickets, or social media posts:\nSee the pattern? In all these cases, the structured format makes the AI's output\nimmediately actionable by other parts of your system.\nOkay, so structured output is great. How do we actually make the AI cough it up?\nThere are generally two main paths:\n1. Native Model Features (The Built-in Tools): As AI models get more sophistic\nsome are adding built-in ways to request structured data.\nGoogle Gemini: Can often work directly with function descriptions or spe\nschemas, sometimes integrated with tools like Pydantic. (See Gemini Doc\nOpenAI Models (like GPT-4): Offer features like \"JSON Mode\" or \"Funct\nCalling\" designed to force the output into a specific JSON structure. (See\nOpenAI Docs)\nThe Catch: These native features are powerful when they work, but they are o\nmodel-specific. The way you ask Gemini for JSON might be different from ho\nyou ask OpenAI, or Anthropic's Claude. This can lock you into a specific prov\nand might require learning their particular APIs or libraries.\n2. Prompt Engineering (Just Ask Nicely!): The alternative path, and the one we'\nfocus on, is to simply tell the AI exactly how to format its response directly\n  enable_ssl: true\n  log_level: INFO\nemail_analysis:\n  category: Support Request\n  priority: High\n  keywords:\n    - login issue\n    - cannot access account\n    - urgent\nHow Do We Get This Magical Structure?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-35/25\n\nwithin your instructions (the prompt). You explicitly describe the structure y\nwant (like requesting YAML or a specific JSON format).\nThe Advantage: This approach tends to be more universal (works across man\ndifferent LLMs) and doesn't require learning model-specific APIs upfront. It\nleverages the AI's core strength: understanding and following instructions.\nWith these two main approaches in mind, let's focus on how to master the art of\n\"asking nicely.\"\nAlright, we've seen why structured output is the goal and briefly touched on the bu\nin tools some models offer. But now, let's dive into the strategy we'll be using\nthroughout this guide: Prompt Engineering.\nSounds fancy, but the core idea is incredibly simple: You tell the AI exactly what y\nwant, including the format, right there in your instructions (the prompt).\nInstead of relying on model-specific features or complex APIs, you leverage the A\nfundamental ability to follow directions. You're essentially saying, \"Hey AI, analyz\nthis text, but when you give me the answer, please put it in this specific structure.\"\nFocusing on prompt engineering for structured output has some key advantages:\n1. Universality: This is the big one. Clear instructions work across most capable\nLarge Language Models (LLMs). Write your prompt once, use it (mostly)\neverywhere.\n2. Simplicity: You don't necessarily need special libraries to get started. If you c\nwrite a clear instruction, you can start requesting structured data.\n3. Our Approach: Just Ask Nicely! (The Power\nPrompting)\nWhy This Approach Rocks (Especially for Getting\nStarted)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-36/25\n\n3. Flexibility & Control: You define the exact structure. Need nested fields? Spec\nkey names? A list of objects? You can specify it directly in your prompt. Beyo\njust the basic structure, your validation step (which we'll discuss next) can enf\ndomain-specific rules. For example, you could check if an extracted email actu\ncontains an \"@\" symbol, or ensure an extracted order_quantity is a positiv\nnumber, adding business logic right into your workflow.\nNow, are LLMs perfect at following formatting instructions every single time? Not\nalways. This is where a little robustness comes in handy. The \"ask nicely\" approac\nworks best when paired with:\nValidation: After getting the response, have your code quickly check if it mat\nthe expected structure and any domain rules you need.\nRetry Logic: If the validation fails, don't just give up! Often, simply asking the\nagain (perhaps with a slightly tweaked prompt emphasizing the format) will y\nthe correct result. (Hint: Frameworks like PocketFlow make this easy! You can confi\na Node to automatically retry on failure, even with a delay, e.g.,\nMyParsingNode(retry=3, wait=5) would retry up to 3 times, waiting 5 sec\nbetween attempts.)\nLet's look at a quick example of the \"Ask\" and \"Verify\" parts in action.\n1. The \"Ask\" (The Prompt):\nHere's how you might ask an LLM to extract basic info and return it as YAML:\nMaking It Robust: Ask, Verify, Retry\n# --- This is the instruction you'd send to the LLM ---\nprompt = \"\"\"\nExtract the person's name (string) and age (integer) from the sentence\nbelow.\nReturn the result ONLY as a YAML block.\nSentence: \"User profile states Alice is 30 years old.\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-37/25\n\nNotice how the prompt clearly states:\nThe task (extract name and age).\nThe required types (string, integer).\nThe exact output format (ONLY a YAML block).\nAn example (```yaml ...```) to guide the LLM.\n2. The \"Verify\" (Checking the Result):\nLet's imagine the LLM correctly returns the following YAML string:\nNow, before using this data in your application, you'd parse it and validate its struc\nusing simple checks:\nExample Output Format:\n```yaml\nname: Example Name\nage: 99\n```\nYour YAML output:\n\"\"\"\nprint(\"--- Example Prompt ---\")\nprint(prompt)\n# --- This is what the LLM might return (as a string) ---\nllm_response_yaml = \"\"\"\nname: Alice\nage: 30\n\"\"\"\nprint(\"\\n--- Simulated LLM YAML Response ---\")\nprint(llm_response_yaml)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-38/25\n\nIf the LLM's output didn't match this structure or failed a domain check, one of th\nassert statements would immediately raise an error. In a real application using a\nframework like PocketFlow, this failure could automatically trigger the retry\nmechanism.\nThe bottom line: By crafting clear prompts (\"Ask\") and adding validation checks\n(\"Verify\"), potentially automated with retries, you can reliably get structured data \nLLMs without getting bogged down in platform-specific complexities.\nimport yaml # You'd need PyYAML installed: pip install pyyaml\n# Parse the YAML string into a Python dictionary\nparsed_data = yaml.safe_load(llm_response_yaml)\nprint(\"\\n--- Running Validation Checks ---\")\n# --- The \"Verify\" Step using Assertions ---\nassert parsed_data is not None, \"Validation Failed: YAML didn't parse \ncorrectly.\"\nassert isinstance(parsed_data, dict), \"Validation Failed: Expected a \ndictionary.\"\nassert \"name\" in parsed_data, \"Validation Failed: Missing 'name' key.\"\nassert isinstance(parsed_data.get(\"name\"), str), \"Validation Failed: \n'name' should be a string.\"\nassert \"age\" in parsed_data, \"Validation Failed: Missing 'age' key.\"\nassert isinstance(parsed_data.get(\"age\"), int), \"Validation Failed: \n'age' should be an integer.\"\n# Example of a domain-specific check (could be added)\n# assert parsed_data.get(\"age\", -1) > 0, \"Validation Failed: Age must \npositive.\"\nprint(\"✅ Validation Successful! Data structure is correct.\")\n# Now you can confidently use the data:\n# print(f\"Extracted Name: {parsed_data['name']}\")\n# print(f\"Extracted Age: {parsed_data['age']}\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-39/25\n\nNow that we've set the stage for how we're going to ask and verify, let's get into the nitty-g\nWhat are the best ways to actually phrase these requests? Let's dive into our 3 essential t\nOur first practical tip focuses on the format you ask the AI to use. While JSON\n(JavaScript Object Notation) is incredibly common in web development and APIs,\ncan sometimes trip up LLMs, especially when dealing with text that contains quot\nmultiple lines.\nJSON requires strings to be enclosed in double quotes (\"). If your text itself contain\ndouble quotes, they must be \"escaped\" with a backslash (\\), like \\\". Similarly, liter\nnewline characters within a string need to be represented as \\n.\nWhy do LLMs often stumble over these seemingly simple rules? A key reason lies \nhow they process text: tokenization. LLMs break text down into smaller pieces\n(tokens), which might be whole words, parts of words, or individual\ncharacters/symbols. Escaping characters like \\ or formatting markers like \\n can\nsometimes get split awkwardly during this process, or the model might struggle to\nlearn the complex contextual rules for when and how to apply them correctly acro\nvast training data. LLMs are notoriously bad at escaping characters consistently \nto this underlying tokenization mechanism. (Want a deep dive into how tokenizatio\nworks and its quirks? Check out Andrej Karpathy's excellent tutorial on the topic)\nImagine asking the AI to extract a piece of dialogue:\nAlice said: \"Hello Bob.\nHow are you?\"\n4. Tip #1: Speak YAML, Not Just JSON (Easier f\nAI & You!)\nThe Problem: JSON's Strict Rules & Tokenization\nTroubles\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-310/25\n\nIf you ask for this in JSON, the AI should produce: {\"dialogue\": \"Alice sai\n\\\"Hello Bob.\\\\nHow are you?\\\"\"}. But getting those \\\" and \\n exactly ri\nevery time, can be surprisingly fragile due to the tokenization challenge.\nThis is where YAML (YAML Ain't Markup Language) often shines. YAML is desig\nto be more human-readable and has more flexible rules for strings, especially mult\nline strings, making it less susceptible to these escaping and formatting errors.\nLet's ask for the same dialogue in YAML:\nMuch cleaner! No escaping needed for the quotes, and the line break is natural. Th\nuses a block scalar style (|).\nYAML offers powerful ways to handle multi-line strings:\n1. Literal Style (|): Preserves newline characters exactly as they appear in the bl\nEach new line in your source YAML becomes a newline character (\\n) in the\nresulting string.\nExample:\nThe Solution: YAML's Friendlier Approach\nspeaker: Alice\ndialogue: |\n  Alice said: \"Hello Bob.\n  How are you?\"\nUnderstanding Multi-line Styles in YAML: |, >, and\nChomping\nliteral_style: |\n  Line 1\n  Line 2\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-311/25\n\nResulting String: \"Line 1\\nLine 2\\n\\nLine 4\\n\" (Note the double newli\nand the final one)\n2. Folded Style (>): Folds most newline characters within the block into spaces,\ntreating it like one long line broken up for readability. It does preserve blank l\n(which become \\n).\nExample:\nResulting String: \"This is actually just one long sentence, fol\nfor readability.\\nThis starts a new paragraph.\\n\" (Note the\nspace and the single \\n)\nFine-tuning Newlines with Chomping Indicators (+, -):\nYou can further control how the final newline(s) at the end of a block scalar are\nhandled by adding a chomping indicator immediately after | or >:\nDefault (Clip): No indicator (| or >). Keeps a single trailing newline if there is \nbut removes any extra trailing newlines. (This is what the examples above do).\nKeep (+): Use |+ or >+. Keeps all trailing newlines.\n  Line 4\nfolded_style: >\n  This is actually\n  just one long sentence,\n  folded for readability.\n  This starts a new paragraph.\nkeep_newlines: |+\n  Line 1\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-312/25\n\nResulting String: \"Line 1\\n\\n\" (Keeps the blank line's newline and the final\nnewline)\nStrip (-): Use |- or >-. Removes all trailing newlines, including the very last o\nif present.\nResulting String: \"Line 1\\n\" (Keeps the blank line's newline but strips the fin\none)\nWhich one to ask for?\nUse | (literal) for code, poems, addresses where line breaks are crucial.\nUse > (folded) for long paragraphs where you want readability in YAML but\nmostly flowing text in the data.\nUse chomping (+ or -) if precise control over the final newlines is critical for y\napplication (less common, but good to know!).\nWhen prompting an LLM for structured output containing potentially complex\nstrings:\nInstruct it to use YAML: Explicitly ask for the output within ```yaml ...```\nblocks.\nConsider specifying the multi-line style (| or >): If multi-line text is likely an\nstyle matters, add it to the prompt (e.g., \"Use the literal block style | for the\ndescription field\"). You usually don't need to specify chomping unless you\na specific need.\nAlways Validate: Even with YAML's flexibility, parse and validate the output \nyour code using assert or other schema checks.\nstrip_newlines: |-\n  Line 1\nActionable Advice\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-313/25\n\nBy leveraging YAML, especially its multi-line capabilities, you can significantly reduce\nchances of formatting errors caused by JSON's stricter rules and the underlying tokeniza\nchallenges faced by LLMs.\nOur second tip tackles tasks where you need the AI to identify specific items from\nyou provide. A common example is filtering or selecting items based on some crite\nIt's tempting to ask the AI to just return the text of the items it selects, but this\napproach is often unreliable, especially when dealing with real-world text which c\nbe messy.\nImagine you have a batch of recent product reviews, and you want an AI to help fl\nthe ones that seem like spam (e.g., containing suspicious links or just gibberish).\nYour input list of reviews might look something like this:\n5. Tip #2: Ask for Numbers (Indexes), Not Just\nWords!\nThe Problem: Real-World Text is Messy, Exact Matchin\nBrittle\nreview_list = [\n  \"Great product, really loved it! Highly recommend.\",  # Index 0\n  \"DONT BUY!! Its a scam! Visit my site -> www.getrichfast-\ntotallylegit.biz\", # Index 1\n  \"  Item arrived broken. Very disappointed :(  \", # Index 2 (extra \nspaces, emoticon)\n  \"????? ?????? ?????? click here for prize >>> http://phish.ing/xxx\"\nIndex 3 (gibberish, link)\n  \"Works as expected. Good value for the price.\", # Index 4\n  \"¡¡¡ AMAZING DEAL just for YOU -> check my profile link !!!\" # Index\n(weird punctuation, instruction)\n]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-314/25\n\nThis list contains actual text – with varying punctuation, capitalization, spacing,\nsymbols, and even potential typos (though none explicitly added here, imagine the\ncould exist).\nNow, you prompt the AI: \"Review the list below. Identify any reviews that appear \nspam or contain suspicious links. Return the full text of the reviews that should be\nremoved.\"\nWhat might the LLM return?\nIt might copy index 1 perfectly.\nIt might return index 3 as: \"????? ?????? ?????? click here for\nprize >>> http://phish.ing/xxx\" (Perfect copy).\nBut it could also return index 5 as: \"!!! AMAZING DEAL just for YOU -\ncheck my profile link !!!\" (Normalizing the ¡¡¡ to !!!).\nOr it might subtly change spacing or punctuation in any of them.\nIf your code tries to remove items based on the exact text returned by the LLM (e.g\nllm_output_text in review_list:), any slight alteration means the spam\nreview won't be found in your original list, even though the AI correctly identified \nLLMs aren't designed for perfect replication of potentially noisy input strings; the\nprocess meaning and generate output, sometimes introducing minor variations.\nInstead of asking for the potentially complex and variable review text, ask the AI t\noutput the index (the position number) of the reviews that should be removed.\nLet's rewrite the prompt's instruction:\n\"Analyze the list of product reviews provided below, each marked with an index\nnumber (0 to 5). Identify any reviews that seem like spam or contain suspicious\nlinks/instructions. Output ONLY a list of the integer indexes corresponding to th\nreviews that should be removed.\"\nThe Solution: Refer by Index, Not by Messy Text\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-315/25\n\nNow, the LLM's expected output for this example should be a list of numbers, like\nformatted within the requested YAML structure (tying back to Tip #1):\nThis output is:\nSimple: Just a list of integers.\nStable: Integers don't have typos, spacing issues, or punctuation variations.\nEasy to Validate: Check if the output is a list containing valid integers within\nexpected range (0-5).\nDirectly Usable: You can iterate through these indexes and reliably access or\nremove the exact original reviews from your review_list in your code,\nregardless of how messy they were.\nWhen asking an LLM to select or identify items from a list of potentially complex \nmessy strings you provide:\nPresent the list with clear indexes (or unique, simple identifiers) in the promp\n# Include this numbered list representation in your prompt:\n# Product Reviews (Output indexes of spam/suspicious ones):\n# 0: Great product, really loved it! Highly recommend.\n# 1: DONT BUY!! Its a scam! Visit my site -> www.getrichfast-\ntotallylegit.biz\n# 2:   Item arrived broken. Very disappointed :(\n# 3: ????? ?????? ?????? click here for prize >>> http://phish.ing/xxx\n# 4: Works as expected. Good value for the price.\n# 5: ¡¡¡ AMAZING DEAL just for YOU -> check my profile link !!!\nreviews_to_remove_indexes:\n  - 1\n  - 3\n  - 5\nActionable Advice\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-316/25\n\nInstruct the LLM to output only the list of indexes/identifiers corresponding\nthe selected items.\nValidate that the output is a list containing valid indexes/identifiers.\nThis dramatically increases the reliability of tasks involving selection from noisy, \nworld text inputs. Forget fragile string matching; use stable indexes!\nOur final tip might seem counter-intuitive at first: deliberately asking the AI to ad\n\"extra\" natural language within its structured output. We do this using YAML\ncomments (#) not just for human readability, but to actually improve the accuracy\nthe structured data itself.\nWhen we ask an LLM to perform a complex task (like analyzing multiple reviews a\noutputting a list of indexes to remove) and immediately generate structured data, \ncan sometimes \"rush\" the process. Without an explicit step to consolidate its find\nor reason through its choices just before committing to the structured format, erro\ncan creep in. It might miss an item, include an incorrect one, or make a mistake in\ncomplex classifications. The direct leap from analysis to final structure can be brit\nWe can mitigate this by instructing the LLM to generate a natural language comm\nexplaining its reasoning immediately before outputting the critical structured dat\nWhy This Works: Embedded Chain-of-Thought for Accuracy\nThis isn't primarily about making the output understandable for us later (though t\na bonus). It's about forcing the LLM to engage in a mini Chain-of-Thought step r\nwhen it matters most.\n6. Tip #3: Embed Reasoning with Comments!\nThe Problem: Jumping Straight to Structure Can Be\nError-Prone\nThe Solution: Force a \"Thinking Step\" with YAML\nComments\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-317/25\n\n1. Analysis: The LLM first processes the input (e.g., the list of reviews).\n2. Reasoning Step (The Comment): Before it can output the list of indexes, it mu\nfirst generate the comment summarizing why it's choosing those specific inde\nThis forces it back into a natural language reasoning mode, consolidating its\nfindings.\n3. Structured Output: Having just articulated its reasoning, the LLM is now bet\nprimed to output the correct list of indexes or the accurate structured value.\nGenerating the comment acts as a cognitive speed bump. It interrupts the direct j\nto structured output and encourages a moment of reflection, which often leads to \naccurate results, especially for tasks requiring synthesis or judgment (like picking\nmultiple items from a list or making a nuanced classification).\nExample: Review Filtering with Embedded Reasoning\nLet's revisit our spam review filtering task (Tip #2). We'll modify the prompt\ninstructions:\n\"Analyze the list of product reviews... Output ONLY a YAML block containing th\nreviews_to_remove_indexes with a list of integers. Crucially, add a YAML\ncomment line starting with # immediately before the\nreviews_to_remove_indexes list, briefly summarizing which reviews were\nidentified as spam/suspicious and why.\"\nThe LLM might then produce output like this:\n# Identified reviews 1, 3, 5 as spam/suspicious due to external links\ngibberish, or spammy language.\nreviews_to_remove_indexes:\n  - 1\n  - 3\n  - 5\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-318/25\n\nBy forcing the generation of that # Identified reviews... comment first, w\nincrease the likelihood that the following list [1, 3, 5] is accurate, because the\nLLM had to explicitly justify its selection in natural language just before outputtin\nthe numbers.\nTo leverage embedded reasoning for improved accuracy:\nIdentify critical structured outputs where the AI performs judgment or synth\n(e.g., lists of selected items, classifications, summary fields).\nInstruct the LLM to add a YAML comment (# reasoning...) immediatel\nbefore these specific fields. Frame it as needing a summary of its findings or\nrationale before the data point.\nUse it for complex decisions: This is most beneficial when the AI isn't just\nextracting simple facts, but making choices or summarizing analysis results in\nstructured format.\nThink of it as asking the AI to \"show its preliminary work\" in a comment before\nfinalizing the structured answer. This embedded reasoning step can be a powerful\ntechnique to boost the reliability and accuracy of your structured outputs.\nWe've covered three key tips: use YAML (Tip #1), prefer indexes over strings for\nselections (Tip #2), and embed reasoning with comments for accuracy (Tip #3). No\nlet's see how these come together in a practical example: parsing key information \na resume.\nWe'll use the simple PocketFlow framework to manage the process, but the core lo\nlies within the prompt we send to the LLM inside a single PocketFlow Node.\nActionable Advice\n7. Putting It Together: Parsing a Resume with\nPocketFlow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-319/25\n\nThe Goal: Extract the name, email, work experience, and identify specific target s\nfrom a messy resume text file (data.txt), outputting the results in a clean, struct\nYAML format incorporating our tips.\nHere’s a simplified look at the crucial part of the exec method within our\nResumeParserNode – the prompt construction. Notice how it explicitly asks for\nYAML, uses comments for reasoning, and expects skill indexes.\nThe Core Logic: The Prompt Inside ResumeParserNode\n# (Inside the ResumeParserNode's exec method)\n# Assume 'resume_text' holds the raw text from the resume file\n# Assume 'target_skills' is a list like [\"Management\", \"CRM\", \"Python\"\n# Assume 'skill_list_for_prompt' formats this list with indexes (0: \nManagement, 1: CRM, ...)\nprompt = f\"\"\"\nAnalyze the resume below. Output ONLY the requested information in YAM\nformat.\n**Resume:**\n```\n{resume_text} # The actual resume text goes here\n```\n**Target Skills (use these indexes):**\n```\n{skill_list_for_prompt} # The 0: Skill A, 1: Skill B, ... list\n```\n**YAML Output Requirements:**\n- Extract `name` (string).\n- Extract `email` (string).\n- Extract `experience` (list of objects with `title` and `company`).\n- Extract `skill_indexes` (list of integers found from the Target Ski\nlist).\n- **Add a YAML comment (`#`) explaining the source/reasoning BEFORE \n`name`, `email`, `experience`, and `skill_indexes`.**\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-320/25\n\nGenerate the YAML output now:\nThe beauty of PocketFlow is its simplicity. We define our ResumeParserNode\ncontaining the logic above. The node's prep method would load the resume text,\nexec (shown above) calls the LLM and validates, and post saves the result. The F\nsimply runs this single node.\n**Example Format:**\n```yaml\n# Found name at top\nname: Jane Doe\n# Found email in contact info\nemail: jane@example.com\n# Experience section analysis\nexperience:\n  # First job listed\n  - title: Manager\n    company: Corp A\n# Skills identified from the target list based on resume content\nskill_indexes:\n  # Found 0 (Management) in experience\n  - 0\n  # Found 1 (CRM) in experience\n  - 1\n# --- The rest of the exec method would ---\nresponse = call_llm(prompt)\nyaml_str = extract_yaml_from_response(response)\nstructured_result = yaml.safe_load(yaml_str)\n# --- Validation using assert statements ---\nassert \"name\" in structured_result ... etc.\nreturn structured_result\nHow PocketFlow Runs It\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-321/25\n\nExample Structured Output:\nRunning this flow against the sample resume (data.txt) with target skills like\n\"Management\", \"CRM\", \"Project management\" might produce output like this (no\nthe comments and skill indexes):\n# Found name at the top of the resume\nname: JOHN SMTIH\n# Found email address in the contact section\nemail: johnsmtih1983@gnail.com\n# Parsed work experience section\nexperience:\n  # Extracted first job title and company\n  - title: SALES MANAGER\n    company: ABC Corportaion\n  # Extracted second job title and company\n  - title: ASST. MANAGER\n    company: XYZ Industries\n  # Extracted third job title and company\n  - title: CUSTOMER SERVICE REPRESENTATIVE\n    company: Fast Solutions Inc\n# Identified indexes from the target skills list based on resume \ncontents\nskill_indexes:\n  # Found 'Team leadership & managment' (Index 0) mentioned under \nskills/experience\n  - 0\n  # Found 'Customer relationship management (CRM) software' (Index 1) \nmentioned under skills\n  - 1\n  # Found 'Project management' (Index 2) mentioned under skills\n  - 2\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-322/25\n\nValidation is Key: Remember, the exec method in the full code includes assert\nstatements to check if the LLM returned the expected keys (name, email,\nexperience, skill_indexes) and correct types (e.g., experience is a list,\nskill_indexes contains integers). This ensures the output structure is usable b\nthe program continues.\nThis was just a glimpse. To see the complete, runnable Python code using PocketF\nincluding the utils.py for the LLM call, the data.txt sample resume, and how\nexecute it yourself, head over to the PocketFlow Cookbook on GitHub:\n➡ PocketFlow Structured Output Example on GitHub\nThere you can clone the repository, install the requirements, add your API key, an\nrun python main.py to parse the resume yourself!\nAnd there you have it! Getting clean, organized, and usable structured data back f\nLarge Language Models doesn't have to be a wrestling match with complex APIs o\nbrittle text parsing. Often, the most straightforward and effective approach is sim\nto ask nicely, but specifically!\nWe've seen how crafting clear instructions within your prompt – leveraging the po\nof simple prompt engineering – can reliably coax LLMs into giving you the data\nformat you need. Let's quickly recap the three core tips we covered:\n1. Speak YAML, Not Just JSON: Bypass potential headaches with escaping quo\nand newlines by asking for YAML output (```yaml ...```). It's often easier f\nLLMs to generate correctly, especially with multi-line text, thanks to its frien\nsyntax and less sensitivity to tokenization quirks.\n2. Ask for Numbers (Indexes), Not Just Words: When dealing with classification\nselection from a predefined list (especially messy real-world text!), instruct the\nSee the Full Code in Action!\n8. Conclusion: Structure is Simple!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-323/25\n\nto return the item's index rather than the full string. This avoids fragile text\nmatching and makes your logic far more robust.\n3. Embed Reasoning with Comments for Accuracy: Use YAML comments (#)\nstrategically. Ask the AI to add a comment explaining its reasoning before crit\nstructured fields. This forces a mini \"thinking step,\" improving the accuracy a\nreliability of the final structured output.\nRemember, pairing these prompting techniques with basic validation (checking th\nstructure you get back) and potentially simple retry logic creates a surprisingly rob\nsystem for getting the structured data you need, usable across a wide range of AI\nmodels.\nSo, next time you need an AI to extract information, generate configuration, or cla\ndata, don't just hope for the best from its free-form response. Apply these tips, be\nexplicit, and watch the structured data roll in!\nReady to dive into the code? Check out the complete resume parsing example using\nPocketFlow and these techniques: PocketFlow Structured Output Example on GitHu\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n16 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-324/25\n\n5 more comments...\nWrite a comment...\nJul 7\nLiked by Zachary Huang\n1 reply by Zachary Huang\nYiming\nI noticed that your article was improperly forwarded by CSDN and paid for reading:\nhttps://blog.csdn.net/llm_way/article/details/147583065\nLIKE (1)REPLY\nJun 2\nLiked by Zachary Huang\nJim\nIt resolved a question by me.\nWhy are there so many people I saw using YAML to get their LLM answers.\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:40 PMStructured Output for Beginners: 3 Must-Know Prompting Tips\nhttps://pocketflow.substack.com/p/structured-output-for-beginners-325/25"
  },
  {
    "filename": "PocketBlog250424-2.pdf",
    "title": "Build AI Agent Memory From Scratch — Tutoria",
    "date": "2025-04-24",
    "content": "\n\nBuild AI Agent Memory From Scratch — Tutoria\nFor Dummies\nMAR 24, 2025\n11Sh\nEver wondered why some chatbots remember your name days later, while others forget \nyou said 5 minutes ago? This guide explains AI memory in super simple terms — no te\nbackground needed!\nHave you ever told a chatbot your name, only for it to ask again in the same\nconversation? Or been surprised when it remembered your birthday weeks later? L\nbreak down how AI memory actually works — the simple truth!\nGreat news: it’s way easier than you think! In this super-friendly guide, you’ll\ndiscover:\nZACHARY HUANG\n19\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch1/21\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThe shockingly simple trick behind AI memory\nHow chatbots keep track of what you’ve told them\nWhy good memory makes the difference between helpful and frustrating AI\nFor this guide, we’ll use Pocket Flow — a tiny framework (just 100 lines!) that cuts\nthrough all the fancy jargon to show you how AI memory really works. While most\ntools hide all the important stuff under complicated code, PocketFlow puts everyth\nright in front of you so you can actually understand it.\nWant to see the working code? You can check out and run the complete implementation\nGitHub: PocketFlow Chat Memory.\nMost AI tools are like pre-built furniture with hidden screws and hard-to-read\ninstructions. Pocket Flow is different — it’s like a simple DIY starter kit with just \nlines of code that includes only the essential tools you need to build something rea\nand useful!\nWhat makes this perfect for learning:\nBasic tools only: Just the essential tools you actually need, not a confusing\nworkshop full of advanced equipment\nClear instructions: Every step is visible and understandable, like a DIY tutori\nwith pictures for each step\nExpand at your own pace: Start simple, then add more advanced features whe\nyou’re comfortable\nWhy Learn Memory with Pocket Flow?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch2/21\n\nThat’s it! Everything else is just details around these core concepts.\nImagine your AI as a bustling coffee shop. PocketFlow provides the following\nbuilding blocks:\nNodes are like different stations (taking orders, checking recipes, brewing coff\narchiving receipts).\nFlow is like the daily routine that keeps each station running smoothly.\nShared Store is like your master order binder, keeping track of all current ord\nrecipes, and past receipts.\nIn our coffee shop system:\n1. Each station (Node) has three simple jobs:\nPrep: Gather what you need (like the right cup or recipe).\nExec: Perform the main task (like brewing the drink).\nPost: Update the binder and decide what to do next (like archiving an old rece\n2. The shop’s routine (Flow) moves between stations based on needs:\n“If we need a recipe, look it up in the binder.”\n“If we have too many orders on the counter, move some receipts to the archive\nThe Simple DIY Kit from Pocket Flow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch3/21\n\nThink of AI memory like a simple note-taking system:\nShort-term memory: “Sticky notes” on your desk for recent info.\nLong-term memory: A “filing cabinet” for older info sorted by topic.\nRetrieval: Flipping through that cabinet to find what you need.\nJust as you’d forget details if you never wrote them down, an AI forgets unless it\nsystematically stores and retrieves information. To handle lots of older messages\nwithout losing track, an AI might use embeddings or summaries. Imagine you have a\nof vacation photos:\nEmbeddings are like giving each photo a “fingerprint” that captures what’s in\n— so later, if you search for “beach,” you can quickly pull out all the beach pho\nSummaries work like writing “cliff notes” on the back of each picture (“family\nthe beach in Maui”), then reading those notes to decide which photo to grab.\nWhat is Memory in Easy Terms?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch4/21\n\nBoth methods help the AI skip flipping through every word, either by matching\n“fingerprints” (embeddings) or by checking short “cliff notes” (summaries) to insta\nrecall the details. In this tutorial, we will focus on embeddings.\nWant to see these methods in action? Frameworks like LangChain provide:\nConversation Buffer Window\nConversation Summary Memory\nVector Store Retriever Memory\nFeeling intimidated? No worries — we’ll walk through simple examples with mini\nrunnable code in Pocket Flow.\nLet’s break down what we need to build our memory system:\nHow to DIY Memory from Scratch?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch5/21\n\nSelf-Loop Flow: Think of this as the librarian’s daily routine. They listen to\nquestions, check references, answer patrons, and file away old materials — th\nstart over with the next visitor.\nShared Store: Like the library’s central information system, with both the ope\ndesk (short-term memory for current questions) and archive room (long-term\nmemory for older topics).\nPicture a library customer service desk. It’s a continuous loop where information fl\nbetween you, the librarian, and the archive shelves.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch6/21\n\n1. Question Node: The front desk librarian jots down your question.\n2. Retrieve Node: The librarian checks the catalog and archived collections.\n3. Answer Node: The librarian uses the found resources to help you.\n4. Embed Node: The archivist who labels and files older notes.\nNo fancy math — just a neat loop that keeps all your conversations at your fingert\nLet’s see how our “librarian” handles a real conversation over time:\nDay 1: You mention your pet\n1. You tell the librarian: “I have a golden retriever named Max who loves to play\nfetch.”\n2. The librarian jots this down in a “current notes” binder at the front desk.\n3. You chat about a few other things.\n4. Eventually, once there are too many notes, the librarian moves some details to\narchive shelves in the back.\n5. To make it easier to find later, the librarian files the note about “golden retriev\nMax, fetch” under a special topic label (an “embedding”).\n6. Now it’s safely stored in the archive for long-term reference.\nA week later: You ask about your dog\n1. You return and ask: “What was my dog’s name again?”\n2. The librarian writes your question down and assigns it a topic label.\n3. They check the archive shelves for any labels matching “dog,” “golden retrieve\nor “Max.”\n4. They find the original note about your golden retriever, Max.\nBefore We Code: Letʼs Walk Through\nthe Librarian Example\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch7/21\n\n5. They bring that note to the front desk.\n6. The librarian says: “Your dog’s name is Max. He’s a golden retriever who loves\nplay fetch.”\nIt feels like real remembering because:\nThe librarian initially organized your info before putting it away.\nThey used a topic-based label (embedding) for archiving.\nWhen you asked again, they looked up that label, retrieved the note, and\ncombined it with your current question to give a complete answer.\nNow let’s build such a librarian-inspired memory system from scratch!\nFollowing along with the code? You can find the complete working implementation of th\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch8/21\n\nmemory components at GitHub: PocketFlow Chat Memory to explore the details.\nThe Shared Store is our single “source of truth” for everything your AI needs to\nremember. It’s where we keep both short-term details (like the most recent\nconversation) and long-term archives (where older chats get embedded and indexe\n1. messages: Acts like short-term memory, holding recent user and assistant\nmessages.\n2. vector_index: A data structure (like a search index) for retrieving conversation\n“topic fingerprint.”\n3. vector_items: A list of older, archived chats plus their embeddings, so they can\npulled back into the conversation.\nAll our Nodes (Question, Retrieve, Answer, Embed) will read and write from this\ndictionary, keeping everything in sync. That’s the beauty of a single “notebook” fo\nyour AI’s memory!\nStep 1: Set Up the Shared Store\n# Shared store: a simple dictionary to hold everything\nshared = {\n  # Short-term memory: your \"sticky notes\" for the current conversatio\n  \"messages\": [],\n  # Long-term memory: the \"filing cabinet\" that stores archived chats\n  \"vector_index\": None,   # a placeholder for an index structure\n  \"vector_items\": []      # a list of archived conversations\n}\nStep 2: Define Each Node\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch9/21\n\nFor the prep: Like a librarian opening a fresh notebook page. We create a pla\nstore our conversation if none exists yet.\nFor the exec: Our librarian asks \"How can I help you?\" and waits for your\nquestion. If you say \"exit,\" we close up shop.\nFor the post: The librarian writes your question in the log book. If you said\n\"exit,\" we say goodbye. Otherwise, we save your message and move on to chec\nour records.\na. Question Node — Receives user inp\nand adds it to short-term memory\ndef prep(self, shared):\n    if \"messages\" not in shared:\n        shared[\"messages\"] = []\n        print(\"Welcome to the interactive chat!\")\n    return None\ndef exec(self, _):\n    user_input = input(\"\\nYou: \")\n    # If user types \"exit\", we'll stop the conversation\n    if user_input.strip().lower() == \"exit\":\n        return None\n    return user_input\ndef post(self, shared, prep_res, exec_res):\n    # If exec_res is None, the user wants to exit\n    if exec_res is None:\n        print(\"Goodbye!\")\n        return None  # No more nodes to call (end of flow)\n    # Otherwise, we add their message to our short-term list\n    shared[\"messages\"].append({\"role\": \"user\", \"content\": exec_res\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch10/21\n\nFor the prep: Our librarian reads your latest question and checks if we have a\narchives to search. If either is missing, we skip this step.\nFor the exec: Our librarian creates a \"topic card\" for your question and searc\nthe archives for the closest match – like finding which file cabinet might cont\ninformation about \"golden retrievers.\"\n    # Then decide the next node to call. Usually a RetrieveNode.\n    return \"retrieve\"\nb. Retrieve Node — Searches the\narchives for relevant info\ndef prep(self, shared):\n    if not shared.get(\"messages\"):\n        return None\n   # Find the most recent user message\n    latest_user_msg = next(\n        (msg for msg in reversed(shared[\"messages\"]) if msg[\"role\"\n== \"user\"), \n        None\n    )\n    # Check if we have a vector index (where archived items are \nstored)\n    if \"vector_index\" not in shared or not shared[\"vector_index\"]:\n        return None\n    # Return everything we need for the retrieval step\n    return {\n        \"query\": latest_user_msg[\"content\"] if latest_user_msg els\n\"\",\n        \"vector_index\": shared[\"vector_index\"],\n        \"vector_items\": shared.get(\"vector_items\", [])\n    }\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch11/21\n\nFor the post: Our librarian keeps any relevant file they found on the desk. Eit\nway, we proceed to formulating an answer.\ndef exec(self, inputs):\n    if not inputs:\n        return None\n    query = inputs[\"query\"]\n    vector_index = inputs[\"vector_index\"]\n    vector_items = inputs[\"vector_items\"]\n    # (Pseudo) Create an embedding for the query\n    # real code might call an external embedding function\n    query_embedding = get_embedding(query)  \n    # Search the archived items for a match\n    best_match, best_distance = search_vectors(vector_index, \nquery_embedding)\n    # If nothing is found, return None\n    if best_match is None:\n        return None\n    # Return the best matching conversation and distance\n    return {\n        \"conversation\": vector_items[best_match],\n        \"distance\": best_distance\n    }\ndef post(self, shared, prep_res, exec_res):\n    if exec_res is None:\n        # No relevant info found; we just move on\n        shared[\"retrieved_conversation\"] = None\n    else:\n        # Save the retrieved conversation so the Answer Node can u\nit\n        shared[\"retrieved_conversation\"] = exec_res[\"conversation\"\n    # Continue to the Answer Node\n    return \"answer\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch12/21\n\nFor the prep: Our librarian gathers all needed resources: recent conversation\nnotes and any relevant archived files, arranging them for easy reference.\nFor the exec: With all information at hand, our librarian crafts a thoughtful\nresponse that incorporates both recent and past knowledge.\nc. Answer Node — Combines new and\nold info to generate a response\ndef prep(self, shared):\n    # Start with the most recent messages (e.g., last few user & \nassistant turns)\n    recent_messages = shared.get(\"messages\", [])\n    # Optionally add retrieved data\n    retrieved_conv = shared.get(\"retrieved_conversation\")\n    # Combine them into a single context packet\n    context = []\n    if retrieved_conv:\n        # Mark this as a 'system' note indicating it's relevant \nbackground\n        context.append({\"role\": \"system\", \"content\": \"Relevant \narchived info:\"})\n        context.extend(retrieved_conv)\n        context.append({\"role\": \"system\", \"content\": \"End of \narchived info.\"})\n    context.extend(recent_messages)\n    return context\ndef exec(self, context):\n    if not context:\n        return None\n    # Example function that sends context to an LLM\n    # In practice, you'd replace call_llm(...) with your own model \ncall\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch13/21\n\nFor the post: Our librarian writes down their answer, then decides if it's time\narchive older notes (if we have more than 6 messages) or just continue helping\nFor the prep: If our desk is getting cluttered (more than 6 messages), our libra\ntakes the oldest conversation pair and prepares it for filing.\n    response = call_llm(context)\n    return response\ndef post(self, shared, prep_res, exec_res):\n    # If there's no response, end the conversation\n    if exec_res is None:\n        return None\n    # Add the assistant's answer to our short-term memory\n    shared[\"messages\"].append({\"role\": \"assistant\", \"content\": \nexec_res})\n    # For example, if our messages are piling up, we might archive \nolder ones\n    if len(shared[\"messages\"]) > 6:\n        # We'll show how the 'archive' step works in the next node\n        return \"embed\"\n    # Otherwise, loop back to the question node for the next user \nquery\n    return \"question\"\nd. Embed (Archive) Node — Moves\nolder conversations into long-term\nmemory\ndef prep(self, shared):\n    # If we have fewer than 6 messages, there's nothing to archive\n    if len(shared.get(\"messages\", [])) <= 6:\n        return None\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch14/21\n\nFor the exec: Our librarian creates a label for the file by combining the\nconversation into one document and giving it a special \"topic fingerprint\" for\nretrieval later.\nFor the post: Our librarian files the labeled conversation in the archives, crea\na filing system if needed, then returns to the front desk ready for the next\nquestion.\n    # Extract the oldest user + assistant pair (2 messages)\n    oldest_pair = shared[\"messages\"][:2]\n    # Remove them from short-term memory\n    shared[\"messages\"] = shared[\"messages\"][2:]\n    return oldest_pair\ndef exec(self, conversation):\n    if not conversation:\n        return None\n    # Combine the user & assistant messages into one text for \nembedding\n    user_msg = next((m for m in conversation if m[\"role\"] == \n\"user\"), {\"content\": \"\"})\n    assistant_msg = next((m for m in conversation if m[\"role\"] == \n\"assistant\"), {\"content\": \"\"})\n    combined_text = f\"User: {user_msg['content']}\\nAssistant: \n{assistant_msg['content']}\"\n    # Create an embedding (pseudo-code)\n    embedding = get_embedding(combined_text)\n    return {\n        \"conversation\": conversation,\n        \"embedding\": embedding\n    }\ndef post(self, shared, prep_res, exec_res):\n    if not exec_res:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch15/21\n\nNow let’s make the system run by connecting each node into a self-loop flow and\nchoosing a starting point:\n        # Nothing to archive, just go back to questions\n        return \"question\"\n    # Initialize our archive if it's missing\n    if \"vector_index\" not in shared or shared[\"vector_index\"] is \nNone:\n        shared[\"vector_index\"] = create_index()\n        shared[\"vector_items\"] = []\n    # Add the embedding to the index\n    position = add_vector(shared[\"vector_index\"], \nexec_res[\"embedding\"])\n    # Keep track of the archived conversation itself\n    shared[\"vector_items\"].append(exec_res[\"conversation\"])\n    print(f\"✅ Archived a conversation at index position \n{position}.\")\n    print(f\"✅ Total archived: {len(shared['vector_items'])}\")\n    # Return to the question node to continue the chat\n    return \"question\"\nStep 3. Connect the Nodes in a Self-\nLoop Flow\n# Create your node instances\nquestion_node = QuestionNode()\nretrieve_node = RetrieveNode()\nanswer_node = AnswerNode()\nembed_node = EmbedNode()\n# Connect the flow:\n# Main flow path\nquestion_node - \"retrieve\" >> retrieve_node\nretrieve_node - \"answer\" >> answer_node\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch16/21\n\nAs soon as we call chat_flow.run(shared), the system:\nEnters the Question Node (prep → exec → post).\nJumps to the node name returned by the post step (“retrieve”).\nContinues through Retrieve, Answer, Embed as each node’s post method dict\nKeeps looping until a node returns None (meaning it's time to stop)\nAll the Flow class does is respect these returns — once a node finishes its post, Fl\ncalls the next node by name. If a node ever returns None, the entire conversation e\nThat's our self-loop in action:\nQuestion → Retrieve → Answer → Embed → Question → ... → None (exit)\nThat’s it! You now have a working self-loop where each node does its job — collecting u\ninput, retrieving old chats, generating answers, and archiving older messages. Once you \nthis code, your AI will “remember” and “forget” just like a neatly organized notebook\n# When we need to embed old conversations\nanswer_node - \"embed\" >> embed_node\n# Loop back for next question\nanswer_node - \"question\" >> question_node\nembed_node - \"question\" >> question_node\n# Create the flow starting with question node\nchat_flow = Flow(start=question_node)\n# Set up an empty \"notebook\"\nshared = {}\n# Start the conversation loop\nchat_flow.run(shared)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch17/21\n\nReady to run this code? Here’s how:\n1. Clone the GitHub: PocketFlow Chat Memory\n2. Set up your API key:\n3. Run the application:\nHere’s a simple example showing how your AI’s memory works in practice:\nUser: “Remember, my cat is Whiskers”\nAssistant: “Got it! I’ll keep that in mind.”\n(The system saves “Whiskers” to short-term memory.)\nUser: “What’s the weather today?”\nAssistant: “I don’t have real-time info right now, but you can check a weather app!”\n(This question doesn’t impact memory storage.)\n...\nUser: “What’s my cat’s name again?”\nAssistant: “Your cat’s name is Whiskers.”\n(The system pulls “Whiskers” from memory.)\nStep 4. Run and Test\nexport OPENAI_API_KEY=\"your-api-key-here\"\npip install -r requirements.txt\npython main.py\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch18/21\n\nBehind the Scenes (Simplified):\nShort-Term stores recent info (like the cat’s name).\nLong-Term archives older details once short-term gets full.\nFlow decides whether to use short-term or check long-term memory when you\nsomething.\nEven if you ask unrelated questions in between, the system can still recall\n“Whiskers” whenever you need it!\nAI Memory Demystified: The Simple\nSecret\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch19/21\n\nYou’ve now learned the straightforward secret behind AI memory. No fancy magic\njust smart organization and looping processes. Here’s what makes it tick:\n1. Self-Loop Flow: A simple cycle that continuously handles your input, finds re\npast info, generates helpful answers, and archives older messages.\n2. Shared Store: One organized place to hold both short-term (“sticky notes”) an\nlong-term (“filing cabinet”) memory.\n3. Memory Retrieval: Quickly finding relevant conversations from the archives w\nneeded.\n4. Contextual Responses: Combining new questions and retrieved info to form\nmeaningful answers.\nNext time you interact with an AI assistant that seems to “remember” things, you’\ninstantly recognize these simple ideas at work.\nReady to build your own AI system with memory? The complete working code for this tut\nis available at GitHub: Pocket Flow Chat Memory. Clone the repository, run the code, a\nstart experimenting with your own memory-enabled chatbot today!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n19 Likes∙1 Restack\nDiscussion about this post\nPreviousNext\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch20/21\n\n1 more comment...\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:54 PMBuild AI Agent Memory From Scratch — Tutorial For Dummies\nhttps://pocketflow.substack.com/p/build-ai-agent-memory-from-scratch21/21"
  },
  {
    "filename": "PocketBlog250424.pdf",
    "title": "Text-to-SQL from Scratch — Tutorial For",
    "date": "2025-04-24",
    "content": "\n\nText-to-SQL from Scratch — Tutorial For\nDummies (Using PocketFlow!)\nAPR 24, 2025\n62Sh\nEver wished you could just ask your database questions in plain English instead of wre\nwith complex SQL queries? This guide breaks down Text-to-SQL in the simplest way\npossible using the PocketFlow Text-to-SQL Example!\nHave you ever stared blankly at a database, knowing the answers you need are lock\ninside, but unsure how to write the SELECT * FROM ... WHERE ... JOIN .\nGROUP BY ... magic spells to retrieve them? Or maybe you've tried asking a gen\n20\nTurn Your Questions into Database Answers, N\nSQL Required!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial1/19\n\nAI for data insights, only to be told it doesn't know your specific database structur\nThese are common hurdles when working with structured data, but there's a powe\nsolution: Text-to-SQL.\nIn this beginner-friendly tutorial, you'll learn:\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThe core concepts behind Text-to-SQL systems in plain language\nHow Large Language Models (LLMs) can translate your questions into databa\ncode (SQL)\nHow to build a working Text-to-SQL system with just a few hundreds of lines\ncode\nWe'll use the PocketFlow Text-to-SQL example - a clear, step-by-step workflow built on\nsimple PocketFlow framework. Unlike complex setups, PocketFlow lets you see exactly ho\nnatural language question becomes a database query and how potential errors are hand\ngiving you the fundamentals to understand and build your own conversational databa\ninterfaces.\nSo, how does a computer turn your plain English question like \"Show me sales figu\nfor last month\" into actual data from a database? Imagine you have a super-smart \nanalyst assistant. Here's how they (and a Text-to-SQL system) would likely tackle i\n1. Understand the Tools: First, the analyst checks the database's layout – what t\nare available (customers, orders, products?) and what information (colum\neach table holds (name, email, order_date, price?).\nHow Text-to-SQL Works: From Question to\nAnswer\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial2/19\n\n2. Translate the Request: Based on your question and their knowledge of the\ndatabase layout, they write the precise technical code (SQL) needed to find tha\nspecific information.\n3. Fetch the Data: They run this SQL code against the database.\n4. Handle Slip-ups: If the database says \"Error! I don't understand that code\" (m\na typo or wrong table name), the analyst looks at the error message, figures ou\nwhat went wrong, corrects the SQL code, and tries running it again.\n5. Present the Findings: Once the code runs successfully, they gather the results\nshow them back to you.\nText-to-SQL systems automate this entire process. Let's break down the crucial st\nBefore the system can even think about answering your question, it needs a map of\ndatabase. This map is called the schema. It details:\nTables: What are the main categories of data stored (e.g., customers, produ\norders)?\nColumns: Within each table, what specific pieces of information are tracked (\nin customers, there might be customer_id, first_name, email, city)?\nData Types: What kind of information is in each column (e.g., text, numbers,\ndates)?\n(Optional) Relationships: How do tables connect (e.g., an order belongs to a\ncustomer)?\nWhy is this essential? An AI, even a powerful one, doesn't magically know your\nspecific database. If you ask for \"customer emails,\" it needs the schema to know\nthere's a table called customers and a column called email within it. Without th\nschema, it's just guessing.\nTypically, the system automatically asks the database for this structural informatio\n(using commands like PRAGMA table_info in SQLite or similar commands in o\nStep 1: Understanding the Database Layout (Schema)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial3/19\n\ndatabase systems) before trying to generate any SQL.\nThis is where the AI magic happens. A Large Language Model (LLM) acts as the\ntranslator. It receives:\n1. Your natural language question (e.g., \"What are the names of customers in New\nYork?\").\n2. The database schema (the blueprint learned in Step 1).\nUsing this information, the LLM's job is to generate the corresponding SQL query\nFor the question above, knowing the schema includes a customers table with\nfirst_name, last_name, and city columns, it might generate:\nProviding the LLM with clear instructions and the accurate schema is vital for get\ncorrect SQL output. Sometimes, the system might ask the LLM to format the SQL\nspecific way (like within a YAML block) to make it easier for the system to extract\nreliably.\nGenerating the SQL is just the first part; now the system needs to actually run it\nagainst the database. It connects to the database and sends the generated query.\nThe outcome depends on the query type:\nSELECT Queries: If the query asks for data (like the example above), the datab\nsends back the matching rows and columns.\nStep 2: Translating English to SQL (LLM Generation)\nSELECT first_name, last_name\nFROM customers\nWHERE city = 'New York';\nStep 3: Running the Code (SQL Execution)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial4/19\n\nOther Queries (UPDATE, INSERT, DELETE): If the query modifies data, the\ndatabase typically responds with a confirmation of success (e.g., \"Query OK, 3\nrows affected\").\nThis step is the moment of truth – does the generated SQL actually work and retri\nthe intended information?\nWhat happens if the LLM makes a mistake? Maybe it misspelled a column name, u\nincorrect syntax, or tried to query a table that doesn't exist. The database won't jus\nguess – it will return an error message.\nInstead of giving up, a smart Text-to-SQL system uses this error as valuable feedba\nThis enables a debugging loop:\n1. Execution Fails: The system tries to run the SQL (from Step 3) and gets an err\nmessage back from the database (e.g., \"no such column: customer_city\").\n2. Gather Clues: The system takes the original question, the schema, the failed S\nquery, and the specific error message.\n3. Ask for Correction: It sends all this information back to the LLM, essentially\nasking, \"This query failed with this error. Can you fix it based on the original\nrequest and schema?\"\n4. Generate Corrected SQL: The LLM attempts to provide a revised SQL query \ncorrecting customer_city to city).\n5. Retry Execution: The system goes back to Step 3 to try running this new SQL\nquery.\nTo prevent getting stuck in an endless loop if the LLM can't fix the error, this cycl\nusually only repeats a limited number of times (e.g., 2 or 3 attempts). If it still fails \nthe maximum retries, the system reports the final error.\nStep 4: Fixing Mistakes (Error Handling & Debugging)\nPutting It All Together: The Text-to-SQL Workflow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial5/19\n\nUnlike some AI processes that have separate offline preparation and online answe\nphases (like RAG), Text-to-SQL typically runs as a single, dynamic workflow every\nyou ask a question. It combines the steps we've discussed into a sequence, includin\nthe potential detour for debugging:\nThe Flow Explained:\n1. The process starts by getting the database Schema (A).\n2. It then uses the schema and your question to Generate SQL (B).\n3. Next, it attempts to Execute SQL (C).\n4. If Execution Succeeds: The workflow finishes, providing you the results (E).\n5. If Execution Fails: It enters the debug loop. The error triggers an attempt to\nDebug SQL (D).\n6. The debug step generates corrected SQL, which flows back to Execute SQL (C\nanother try.\n7. This loop (C -> D -> C) continues until either execution succeeds or the maxim\nnumber of retry attempts is hit, at which point it ends with an error message (\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial6/19\n\nThe beauty of this workflow is its ability to translate your request, interact with the datab\nand even intelligently attempt to recover from errors, all orchestrated to get you the data\nasked for.\nAlright, we've seen the conceptual steps involved in tasks like Text-to-SQL. Now, \ndo we actually build a system that automates these steps, especially handling\nconditional logic like error loops? This is where PocketFlow shines!\nPocketFlow is designed to make building workflows refreshingly straightforward.\nForget getting lost in layers of complex code – PocketFlow uses tiny, understandab\nbuilding blocks (check out the core logic - it's surprisingly small!) so you can see\nexactly what's happening under the hood.\nLet's imagine building any automated process, like summarizing a document, is lik\nsetting up an assembly line:\nNodes are the Workstations: Each station has one specific job (e.g., load the\ndocument, summarize it, save the summary).\nBuilding Workflows with PocketFlow: Keep It\nSimple!\n# The basic blueprint for any workstation (Node)\nclass BaseNode:\n    def __init__(self):\n        # Where to go next? Depends on the outcome!\n        self.params, self.successors = {}, {}\n    # Define the next station for a given outcome ('default', 'error',\netc.)\n    def add_successor(self, node, action=\"default\"):\n        self.successors[action] = node\n        return node # Handy for chaining connections!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial7/19\n\nFlow is the Factory Manager: This manager knows the overall assembly line\nprocess, directing the task from one station to the next based on the outcome \nthe previous step. It ensures everything runs in the correct order.\n    # 1. Get ready: What inputs do I need from the central storage?\n    def prep(self, shared): pass\n    # 2. Do the work: Perform the station's main task.\n    def exec(self, prep_res): pass\n    # 3. Clean up & Decide: Store results back in central storage, \nchoose the next step.\n    def post(self, shared, prep_res, exec_res): pass\n    # The standard routine for running a station\n    def run(self, shared):\n        p = self.prep(shared) # Get ingredients/parts\n        e = self.exec(p)      # Do the work\n        return self.post(shared, p, e) # Store results & say what's ne\n# The Factory Manager (Flow) overseeing the process\nimport copy # Need copy to ensure nodes in loops run correctly\nclass Flow(BaseNode):\n    def __init__(self, start): # Knows where the process begins\n        super().__init__()\n        self.start = start\n    # Figures out which station is next based on the last outcome\n    def get_next_node(self, curr, action):\n        return curr.successors.get(action or \"default\")\n    # Orchestrates the entire workflow from start to finish\n    def orch(self, shared, params=None):\n        curr = copy.copy(self.start) # Start at the beginning\n        p = (params or {**self.params})\n        while curr: # Keep going until there are no more stations\n            # Allow setting node-specific params if needed (optional)\n            # curr.set_params(p)\n            action = curr.run(shared) # Run the current station\n            # Move to the next station based on the action returned\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial8/19\n\nShared Store is the Central Parts Bin / Conveyor Belt: This is where all statio\nget their inputs (like a file path) and place their outputs (like the loaded text or\nfinal summary). Every station can access this shared space.\n            curr = copy.copy(self.get_next_node(curr, action))\n    # Kicks off the whole process\n    def run(self, shared):\n        pr = self.prep(shared) # Any prep for the overall flow?\n        self.orch(shared)      # Run the main orchestration\n        return self.post(shared, pr, None) # Any cleanup for the flow?\n# Simple Example: Load text -> Summarize -> Save summary\n# (Assuming LoadTextNode, SummarizeTextNode, SaveSummaryNode exist)\n# Create the workstations\nload_node = LoadTextNode()\nsummarize_node = SummarizeTextNode()\nsave_node = SaveSummaryNode()\n# Connect the assembly line using the default path '>>'\nload_node >> summarize_node >> save_node\n# Create the Factory Manager, telling it where to start\nsummarization_flow = Flow(start=load_node)\n# Prepare the initial inputs in the parts bin ('shared' dictionary)\nshared_data = {\n    \"input_file\": \"my_document.txt\",\n    \"output_file\": \"summary.txt\"\n}\n# Tell the manager to start the assembly line!\nsummarization_flow.run(shared_data)\n# After running, 'shared_data' might contain the summary (if a node pu\nit there)\n# and the summary file \"summary.txt\" should be created.\nprint(f\"Summarization complete! Check {shared_data['output_file']}\")\n# Example: print(shared_data.get(\"summary_text\"))\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial9/19\n\nEach Node (workstation) keeps things tidy by following three simple steps:\nPrep: Grab the necessary parts and information from the shared store.\nExec: Perform its specific assembly task (like summarizing text).\nPost: Put the results back into the shared store (or save them) and signal to the\nmanager what happened (e.g., \"success, continue\" or perhaps \"error, stop\").\nThe Flow (manager) then looks at that signal and directs the work to the appropria\nnext station. This makes defining even complex processes with branches or loops \nour Text-to-SQL debugger will need) quite clear.\nWith these straightforward concepts – Nodes for tasks, Flow for orchestration, an\nShared Store for data – PocketFlow makes building sophisticated workflows\nsurprisingly manageable and easy to understand!\nOkay, let's dive into building our Text-to-SQL assistant using PocketFlow. We'll create \nspecialist stations (Nodes) for each step we discussed earlier and then connect them using\nlab manager (Flow). We'll keep the code super simple here to focus on what each station d\nRemember, the full working code with all the details is in the PocketFlow Text-to-SQL\nExample.\nThink of each node as a Python class inheriting from pocketflow.Node. Each o\nwill implement its prep, exec, and post methods.\nThis node's job is simple: connect to the database and figure out its structure (the\nschema).\nBuilding the Text-to-SQL Workflow with\nPocketFlow Nodes\nStation 1: The GetSchema Node - Mapping the Databas\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial10/19\n\nprep: Grabs the database file location from the shared whiteboard.\nexec: Connects to the database, runs a simplified query to get table structure\nand returns that schema information as a string.\npost: Puts the retrieved schema string onto the shared whiteboard for other\nnodes to use.\nThis is where the magic happens! This node takes the user's question and the sche\nasks the LLM to translate it into SQL, and stores the result.\nclass GetSchema(Node):\n    def prep(self, shared):\n        # Needs: The path to the database file\n        return shared[\"db_path\"]\n    def exec(self, db_path):\n        # Does: Connects to the DB and gets table/column info\n        print(f\" Getting schema for {db_path}...\")\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        # Simplified way to get schema info (real code is more detaile\n        cursor.execute(\"SELECT sql FROM sqlite_master WHERE \ntype='table';\")\n        schema_info = \"\\n\".join([row[0] for row in cursor.fetchall()])\n        conn.close()\n        return schema_info # The schema as a string\n    def post(self, shared, prep_res, schema_info):\n        # Stores: The schema string on the shared whiteboard\n        shared[\"schema\"] = schema_info\n        print(\"✅ Schema captured!\")\nStation 2: The GenerateSQL Node - The AI Translator\nclass GenerateSQL(Node):\n    def prep(self, shared):\n        # Needs: The user's question and the database schema\n        return shared[\"natural_query\"], shared[\"schema\"]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial11/19\n\nprep: Gets the human question (natural_query) and the schema from the\nwhiteboard.\nexec: Creates a prompt combining the schema and question, sends it to the L\n(call_llm), and gets the generated SQL query back.\npost: Stores the generated_sql on the whiteboard and resets the\ndebug_attempts counter (since this is a fresh attempt).\nTime to see if the LLM's SQL actually works! This node runs the query against the\ndatabase. It's also the crucial point where we decide if we need to enter the debugg\nloop.\n    def exec(self, inputs):\n        # Does: Asks the LLM to generate SQL\n        natural_query, schema = inputs\n        print(f\"烙 Asking LLM to translate: '{natural_query}'\")\n        prompt = f\"Given schema:\\n{schema}\\n\\nGenerate SQLite query fo\n{natural_query}\\nSQL:\"\n        sql_query = call_llm(prompt)\n        return sql_query.strip()\n    def post(self, shared, prep_res, sql_query):\n        # Stores: The generated SQL query string\n        shared[\"generated_sql\"] = sql_query\n        # Reset debug counter when generating fresh SQL\n        shared[\"debug_attempts\"] = 0\n        print(f\"✅ LLM generated SQL:\\n{sql_query}\")\nStation 3: The ExecuteSQL Node - Running the Code\nclass ExecuteSQL(Node):\n    def prep(self, shared):\n        # Needs: DB path and the SQL query to run\n        return shared[\"db_path\"], shared[\"generated_sql\"]\n    def exec(self, inputs):\n        # Does: Tries to run the SQL query\n        db_path, sql_query = inputs\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial12/19\n\nprep: Gets the database path and the generated_sql from the whiteboard.\n        print(f\" Executing SQL:\\n{sql_query}\")\n        try:\n            conn = sqlite3.connect(db_path)\n            cursor = conn.cursor()\n            cursor.execute(sql_query)\n            results = cursor.fetchall()\n            conn.close()\n            print(\"✅ SQL executed successfully!\")\n            return {\"success\": True, \"data\": results}\n        except sqlite3.Error as e:\n            # Houston, we have a problem!\n            print(f\" SQL Error: {e}\")\n            if 'conn' in locals(): conn.close()\n            return {\"success\": False, \"error_message\": str(e)}\n    def post(self, shared, prep_res, exec_result):\n        # Stores: Results OR error message. Decides next step!\n        if exec_result[\"success\"]:\n            shared[\"final_result\"] = exec_result[\"data\"]\n            print(f\" Got results: {len(exec_result['data'])} rows\")\n        else:\n            # Store the error and increment attempt counter\n            shared[\"execution_error\"] = exec_result[\"error_message\"]\n            shared[\"debug_attempts\"] = shared.get(\"debug_attempts\", 0)\n1\n            max_attempts = shared.get(\"max_debug_attempts\", 3)\n            print(f\"❗ Failed attempt {shared['debug_attempts']} of \n{max_attempts}\")\n            if shared[\"debug_attempts\"] >= max_attempts:\n                print(\" Max debug attempts reached. Giving up.\")\n                shared[\"final_error\"] = f\"Failed after {max_attempts} \nattempts. Last error: {exec_result['error_message']}\"\n            else:\n                # Return 'error_retry': Signal to the Flow to go to th\nDebugSQL node\n                print(\"樂 Attempting to debug...\")\n                return \"error_retry\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial13/19\n\nexec: Uses a try...except block. It attempts to connect and execute the S\nIf it works, it returns success and data. If it catches an sqlite3.Error, it\nreturns failure and the error message.\npost: This is the critical decision point!\nIf exec was successful, store the final_result and return None (signal\nthe default \"success\" path).\nIf exec failed, store the execution_error, increment the\ndebug_attempts counter. Check if we've hit the max_debug_attempt\nyes, store a final_error and return None (stop the loop). If no, return th\nspecific action string \"error_retry\" to tell the Flow manager to take the\ndebugging path.\nThis station jumps into action only if ExecuteSQL failed and signaled\n\"error_retry\". Its job is to ask the LLM to fix the broken SQL.\nStation 4: The DebugSQL Node - The AI Code Fixer\nclass DebugSQL(Node):\n    def prep(self, shared):\n        # Needs: All context - question, schema, bad SQL, error messag\n        return (\n            shared[\"natural_query\"],\n            shared[\"schema\"],\n            shared[\"generated_sql\"], # The one that failed\n            shared[\"execution_error\"]\n        )\n    def exec(self, inputs):\n        # Does: Asks LLM to fix the SQL based on the error\n        natural_query, schema, failed_sql, error_message = inputs\n        print(f\"喙 Asking LLM to fix SQL based on error: \n'{error_message}'\")\n        prompt = f\"\"\"\nOriginal Question: {natural_query}\nSchema: {schema}\nFailed SQL:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial14/19\n\nprep: Gathers all the context needed for debugging from the whiteboard: the\noriginal question, schema, the SQL that failed, and the error message it produ\nexec: Constructs a prompt telling the LLM about the failure and asks for a\ncorrection. Calls the LLM.\npost: Crucially, it overwrites the generated_sql on the whiteboard with the\nLLM's new attempt. It also clears the execution_error. It returns None,\nsignaling the default path, which (as we'll see next) leads back to the Execute\nnode to try this revised query.\nNow we wire these stations together using PocketFlow's Flow and the connection\noperators:\n{failed_sql}\nError: {error_message}\nProvide the corrected SQLite query:\nSQL:\"\"\"\n        corrected_sql = call_llm(prompt)\n        return corrected_sql.strip()\n    def post(self, shared, prep_res, corrected_sql):\n        # Stores: Overwrites the bad SQL with the new attempt\n        shared[\"generated_sql\"] = corrected_sql\n        shared.pop(\"execution_error\", None)\n        print(f\"✅ LLM suggested fix:\\n{corrected_sql}\")\nConnecting the Stations: Defining the Flow\nfrom pocketflow import Flow\n# Create instances of our stations\nget_schema_node = GetSchema()\ngenerate_sql_node = GenerateSQL()\nexecute_sql_node = ExecuteSQL()\ndebug_sql_node = DebugSQL()\n# --- Define the main path ---\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial15/19\n\nLook how cleanly we defined the process:\n1. Start with GetSchema, then GenerateSQL, then ExecuteSQL.\n2. If ExecuteSQL specifically returns \"error_retry\", then the flow jumps to\nDebugSQL.\n3. After DebugSQL completes (its default path), the flow goes back to ExecuteS\nAnd that's it! We've built the core logic of our Text-to-SQL assistant, complete with a\nautomated debugging loop, using simple, focused PocketFlow nodes.\nAnd there you have it! You've journeyed through the world of Text-to-SQL,\ntransforming simple English questions into powerful database queries. You now\nunderstand the elegant dance between:\n# Use '>>' for the default success path\nget_schema_node >> generate_sql_node >> execute_sql_node\n# --- Define the debug loop path ---\n# Use '- \"action\" >>' to specify a path for a specific action string\n# If ExecuteSQL returns \"error_retry\", go to DebugSQL\nexecute_sql_node - \"error_retry\" >> debug_sql_node\n# If DebugSQL finishes (returns None/default), go back to ExecuteSQL\ndebug_sql_node >> execute_sql_node\n# Create the Flow Manager, telling it where to start\ntext_to_sql_flow = Flow(start=get_schema_node)\n# --- Ready to Run! ---\n# Prepare the initial inputs\n# shared = { ... }\n# text_to_sql_flow.run(shared)\nConclusion: Unlock Your Data with Plain Englis\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial16/19\n\n1. Understanding the Map (Schema): Giving the AI the blueprint of your databa\n2. AI Translation (LLM Generation): Letting the LLM convert your request into\nSQL code.\n3. Running the Code (Execution): Actually talking to the database.\n4. Smart Error Fixing (Debugging Loop): Giving the AI a chance to correct its o\nmistakes!\nWhile the concept might seem complex initially, frameworks like PocketFlow reve\nthe underlying simplicity. The entire process, even the clever debugging loop, boil\ndown to a sequence of focused Nodes, orchestrated by a Flow, sharing information\na Shared Store. It's a pattern that makes building powerful, resilient data interacti\ntools surprisingly manageable.\nThe real magic of Text-to-SQL lies in breaking down the barrier between humans \ntheir data. No longer is database access solely the domain of SQL wizards. By\ngrounding AI translation with specific database schemas and adding intelligent er\nhandling, these systems make data insights accessible to everyone, faster and more\nintuitively than ever before.\nWith the concepts and PocketFlow structure you've learned here, you're now equip\nto build your own conversational interfaces for databases in any domain!\nReady to build this yourself? Dive into the code and experiment:\nGet the Code: Find the complete working example used in this tutorial at GitHub:\nPocketFlow Text-to-SQL Cookbook.\nExplore PocketFlow: Learn more about the simple framework powering this example \nthe main PocketFlow GitHub Repository.\nJoin the Community: Have questions or want to share what you're building? Connect\nother developers on the PocketFlow Discord.\nGo ahead, connect your databases, and start asking questions!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial17/19\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n20 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nWrite a comment...\nApr 26\nLiked by Zachary Huang\n4 replies by Zachary Huang and others\npatcap\nWhat else can you do to improve the accuracy from there? I'm curious what would it take to \nsome SOTA level system. Would it be something like this (https://arxiv.org/abs/2401.08500)\ngenerate 10s of samples and take majority vote + self reflection with errors + something else\nsure what that is).\nLIKE (1)REPLY\nApr 27Mark\nHi Zachary,\nI came across your repo from the incredible work - Pocketflow and keep tracing everything y\ncreated including this post. It's really informative and inspiring.\nOne thing hits me most is that I notice every post coming with a consistent theme for a robo\nmay I please know the secrete behind it, like what's the tool you use, and any guideline for t\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial18/19\n\n4 more comments...\nLIKEREPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMText-to-SQL from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/text-to-sql-from-scratch-tutorial19/19"
  },
  {
    "filename": "PocketBlog250506.pdf",
    "title": "Streaming LLM Responses — Tutorial For",
    "date": "2025-05-06",
    "content": "\n\nStreaming LLM Responses — Tutorial For\nDummies (Using PocketFlow!)\nMAY 06, 2025\n22Sh\nTired of staring at a loading spinner while the AI thinks? Wish you could just yell \"Stop\nwhen it goes off track? This guide shows you how to get AI answers *instantly by\nstreaming LLM responses word-by-word, and cut them off anytime, using a sim\nPocketFlow LLM Streaming Example.*\nWe've all been there. You ask an AI a question. You wait. Maybe it's brilliant, may\nit's... weird. What if you could see the answer appear as it's typed and hit an \"eject\"\nZACHARY HUANG\n15\nSee AI Answers Appear Live (And Slam the\nBrakes!)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial1/16\n\nbutton if it's not what you want?\nThat's LLM Streaming (seeing it live) and User Interruption (hitting stop). Instead\ngetting a whole essay dropped on you, text pops up piece by piece. It feels way fast\nPlus, the stop button puts you in charge, saving time and maybe even cash on API\ncalls.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nWhat you'll learn in this easy guide:\nWhy watching AI type is awesome.\nThe simple idea behind showing text live while listening for your \"STOP!\"\ncommand.\nHow to build this feature with just one simple PocketFlow Node.\nWe'll use the PocketFlow LLM Streaming example. PocketFlow helps organize the steps s\nsee exactly how the magic happens without getting lost in code spaghetti. Let's make AI \nless like waiting for dial-up and more like a chat!\nThink about ChatGPT typing out answers. That's streaming. Being able to stop it\nInterruption. Here's why they rock:\nFeels Faster (Better UX): Remember waiting for a webpage to load everything?\nUgh. Streaming is like seeing the text appear as it's written. It just feels quicke\nand keeps you engaged. Example: An AI coding helper starts spitting out cod\nYou see the function you need in the first few lines! No need to wait for the re\nWhy Stream? Why Interrupt? The Benefits\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial2/16\n\nGet the Point Faster: Sometimes you just need one quick thing. Example: \"W\nthe weather in London?\" Stream starts: \"In London, it's currently 15°C...\" Perfec\nMaybe you don't care about the humidity forecast for next Tuesday. Streaming\ngets you the core info ASAP.\nStop the Nonsense (Control & Savings): AI can ramble or get stuck. Interrupt\nis your \"Okay, buddy, that's enough\" button. Example: Ask for 10 marketing\nslogans. The third one is GOLD! Hit stop. Why wait (and pay) for 7 more medi\nones? Grab the winner and go!\nChange Your Mind Mid-Stream: Ideas change! Example: You ask for \"things \ndo in Paris.\" It starts listing museums. You see \"Louvre\" and think, \"Actually, \nwant outdoor stuff!\" Interrupt, ask about parks instead, and get relevant info fa\nStreaming + Interruption = AI that feels like a conversation, not a lecture you can't\nescape.\nGetting this live text + stop button involves two main tricks: how the AI sends dat\ndifferently, and how our code juggles showing text while listening for your \"STOP\ncommand.\nThink about asking an AI for help. The key is one little switch in the code:\nstream=True.\nHow It Works: Live Feeds & Listening Skills\n1. From Snail Mail to Live TV: stream=False vs.\nstream=True\n# Simplified concept of calling the AI\nfrom openai import OpenAI\n# The magic switch: stream=True or stream=False\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\", # Or another model\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    stream=True # <--- THIS IS THE KEY!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial3/16\n\nLet's imagine you ask: \"Give me tips for dealing with bugs.\" You mean software bu\nWhat Happens: You ask, you wait. The AI misunderstands, writes a whole an\nabout insects, then sends it all back. You waited 10 seconds for useless advice.\nAnnoying!\nData: You get one big chunk of text after the delay.\nExperience: Wait... wait... BAM! \"Seal cracks in your home...\" Ugh, wrong bug\nTotal waste of time.\n)\n# Now 'response' isn't the final answer... it's a live feed!\n(A) The Old Way: stream=False (Like Sending a Letter)\n(B) The Live Way: stream=True (Like a Phone Call)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial4/16\n\nWhat Happens: You ask. The AI sends back a live feed (an \"iterator\" or\n\"generator\" in code terms). Your code starts getting tiny pieces immediately.\nData: It's like a conveyor belt delivering small packages (chunks) one after ano\nExperience: Text appears right away: \"To deal with insect...\" You see \"insect\" \nthink, \"Nope!\" Because it's arriving piece by piece, you have the chance to\ninterrupt it.\nOkay, stream=True gives us text chunks. How do we show them and watch for y\nhitting Enter (because you saw \"insect\")? Our program needs to multitask.\n# Conceptual idea: Looping through the live feed\nfor chunk in response:\n   content = chunk.choices[0].delta.content or \"\"\n   print(content, end=\"\", flush=True)\n   # (Add a check here to see if user wants to stop)\n   if user_interrupts: break\n2. The Juggling Act: Showing Text While Listening\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial5/16\n\nThe Simple Steps:\n1. You Ask: Give the program your question.\n2. Program Starts Two Jobs:\nAsks the AI for the live feed.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial6/16\n\nAt the same time, starts listening for you to press ENTER.\n3. The Loop (Show & Check):\nAI sends a tiny text piece.\nProgram instantly checks: \"Did they hit ENTER?\"\nYES? --> Tell AI to stop, show \"Stopped!\", end of story.\nNO? --> Show the text piece, wait for the next one. Repeat fast!\n4. Finish Line: If the AI sends everything without you hitting ENTER, show \"Don\nEither way, stop listening for ENTER.\nThis sounds tricky to code, right? Juggling two things at once? This is where a simple tool\nPocketFlow makes life much easier by giving us a structure.\nWe want the live text + stop button. PocketFlow helps organize this.\nImagine PocketFlow gives you recipe cards, called Nodes. Each Node has 3 simple\nsteps:\n1. prep: Get your ingredients ready.\n2. exec: Do the main cooking steps.\n3. post: Clean up the kitchen.\nThis keeps complex tasks tidy.\nMaking It Happen with PocketFlow\nPocketFlow: Simple Recipe Cards (Nodes)\n# Super simplified idea of a PocketFlow Node\nclass MyTaskNode:\n    # 1. Get ready\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial7/16\n\nShared Store: Think of shared as a shared pantry to grab things from (prep)\nput things back into (post).\nHow does the part showing text know the other part listening for Enter wants to st\nThey need a signal. threading.Event is perfect.\nThink of it like raising your hand in class:\nThe listener (when you press Enter) raises the hand: signal.set()\nThe text-shower loop quickly checks if any hand is raised: if\nsignal.is_set():\n    def prep(self, shared):\n        # ... setup code goes here ...\n        return ingredients_for_exec\n    # 2. Do the main work\n    def exec(self, ingredients_from_prep):\n        # ... main logic goes here ...\n        return results_for_post\n    # 3. Tidy up\n    def post(self, shared, ingredients, results):\n        # ... cleanup code goes here ...\n        pass\n    def run(self, shared):\n        p = self.prep(shared) \n        e = self.exec(p)      \n        return self.post(shared, p, e)\nThe Secret Signal: threading.Event (Like Raising You\nHand)\n# --- Conceptual Hand-Raising ---\nimport threading\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial8/16\n\nRun this! You'll see the \"Teacher\" teaching parts, but after the \"Student\" signals\n(raises hand), the class will end early. The Event is our simple stop signal.\nExpected Output (timing might vary slightly):\nimport time\n# The shared signal (hand is initially down)\nstop_signal = threading.Event()\n# Background job: Student waits, then raises hand\ndef student_action():\n    print(\"Student: Waiting 3 secs...\")\n    time.sleep(3)\n    print(\"Student: Raising hand! (Signaling stop)\")\n    stop_signal.set() # <--- Hand goes UP!\n# Start the student job\nstudent_thread = threading.Thread(target=student_action)\nstudent_thread.start()\nprint(\"Teacher: Starting class (checking for hand)...\")\n# Teacher keeps checking the signal while teaching\nfor i in range(10): # Let's pretend class has 10 parts\n    # ---> Check the signal BEFORE teaching next part <---\n    if stop_signal.is_set(): # <--- Is hand raised?\n        print(\"Teacher: Hand raised! Stopping class.\")\n        break # Stop teaching\n    # ---> If no hand raised, teach the next part <---\n    print(f\"Teacher: Teaching part {i+1}...\")\n    time.sleep(0.8) # Simulate teaching\nprint(\"Teacher: Class ended.\")\nstudent_thread.join() # Wait for student thread to fully stop\nprint(\"Everyone dismissed.\")\n# --- End Example ---\nTeacher: Starting class (checking for hand)...\nStudent: Waiting 3 secs...\nTeacher: Teaching part 1...\nTeacher: Teaching part 2...\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial9/16\n\nLet's write the PocketFlow Node for our streaming task.\nWe need:\n1. The AI's live feed (the stream from stream_llm).\n2. The hand-raise signal (threading.Event).\n3. Someone listening for Enter in the background.\nTeacher: Teaching part 3...\nStudent: Raising hand! (Signaling stop)\nTeacher: Teaching part 4...\nTeacher: Hand raised! Stopping class.\nTeacher: Class ended.\nEveryone dismissed.\nBuilding the StreamNode: Our Recipe Card\nStep 1: prep - Get Ingredients\n# --- StreamNode: prep ---\nimport threading\nfrom pocketflow import Node\n# from utils import stream_llm # Assume this gets the AI stream\nclass StreamNode(Node):\n    def prep(self, shared):\n        prompt = shared[\"prompt\"] # Get the question\n        print(\"Requesting stream...\")\n        # Start the AI stream (this returns the live feed/iterator)\n        chunks_iterator = stream_llm(prompt)\n        # Create our signal flag (hand is down initially)\n        interrupt_event = threading.Event()\n        # Define the background job: wait for Enter, then raise the ha\n        def listen_for_enter():\n            input(\"Press ENTER anytime to stop...\")\n            print(\"--- Enter pressed! Sending stop signal ---\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial10/16\n\nprep is like getting set up. It grabs the user's prompt, calls the AI with\nstream=True to get the chunks_iterator (our live feed), creates the\ninterrupt_event signal (like an empty flag pole), and starts a background helpe\n(listener_thread) whose only job is to wait for you to press Enter, then raise th\nflag (interrupt_event.set()). It hands off the feed, the flag, and the helper to\nnext step (exec).\nHere's where we show the text, piece by piece, but always check the signal flag firs\n            interrupt_event.set() # Raise the hand!\n        # Start the listener job in the background\n        print(\"Listener started...\")\n        listener_thread = threading.Thread(target=listen_for_enter, \ndaemon=True)\n        listener_thread.start()\n        # Pass the live feed, signal, and listener thread to the 'exec\nstep\n        return chunks_iterator, interrupt_event, listener_thread\nStep 2: exec - The Main Cooking Loop\n# --- StreamNode: exec ---\n# (Continuing the StreamNode class)\n    def exec(self, prep_res):\n        # Get the ingredients from prep\n        chunks, interrupt_event, listener_thread = prep_res\n        print(\"Streaming response:\")\n        stream_finished_normally = True # Assume it will finish ok\n        # Loop through the live feed from the AI\n        for chunk in chunks:\n            # ----> CHECK THE FLAG FIRST! <----\n            if interrupt_event.is_set(): # Is the hand raised?\n                print(\"--- Interrupted by user ---\")\n                stream_finished_normally = False # Mark as interrupted\n                break # STOP THE LOOP!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial11/16\n\nexec takes the live feed (chunks), signal (interrupt_event), and listener helpe\n(listener_thread) from prep. It loops through each chunk arriving from the A\nCrucially, the very first thing inside the loop is checking if\ninterrupt_event.is_set(). If the flag is up (you hit Enter), it prints an interr\nmessage, notes that it didn't finish normally, and breaks out of the loop immediat\nIf the flag isn't up, it pulls the text out of the chunk and prints it (using end=\"\" \nflush=True makes it appear right away on the same line). If the loop finishes\nwithout being interrupted, it prints a \"finished\" message. Finally, it passes the sign\nand listener to post for cleanup.\nWhether the stream finished or was interrupted, make sure the background listene\nstops cleanly.\n            # ----> If flag not raised, show the text <----\n            # Get the text bit from the chunk and print it\n            # (Real APIs might need slightly different code here)\n            content = chunk.choices[0].delta.content or \"\"\n            print(content, end=\"\", flush=True) # Show text immediately\n        if stream_finished_normally:\n            print(\"--- Stream finished ---\")\n        # Pass the signal flag and listener thread to cleanup\n        return interrupt_event, listener_thread\nStep 3: post - Clean Up the Kitchen\n# --- StreamNode: post ---\n# (Continuing the StreamNode class)\n    def post(self, shared, prep_res, exec_res):\n        # Get the signal and listener from exec's results\n        interrupt_event, listener_thread = exec_res\n        # Ensure the listener thread stops cleanly\n        # Signal it to stop (if it wasn't already signaled)\n        interrupt_event.set()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial12/16\n\npost is cleanup time. It gets the signal flag (interrupt_event) and the listener\nhelper (listener_thread). It makes sure the signal flag is raised\n(interrupt_event.set()), just to be absolutely sure the listener (which is wait\nfor input()) gets the message to stop. Then, listener_thread.join() tells t\nmain program to wait politely (up to 1 second) for the listener thread to pack up an\nhome. This prevents leftover processes hanging around.\nAnd that's our StreamNode! PocketFlow's prep/exec/post structure helps keep th\npotentially tricky logic neat and tidy.\nOkay, theory's done, let's see it run!\n1. Get the Code: Grab the complete example from GitHub: PocketFlow LLM\nStreaming Example.\n2. Install Stuff: Open your terminal, go into the example folder, and run:\n3. Run It!\nWhat You'll See:\n        # Wait briefly for the listener thread to finish\n        listener_thread.join(timeout=1.0)\n        print(\"Listener stopped.\")\nRunning the Example Yourself\npip install -r requirements.txt\npython main.py\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial13/16\n\nFirst, the setup messages:\nThen, text will start appearing on one line:\nTry Interrupting: Hit ENTER while it's typing. Boom! The text stops instantly!\nLet it Finish: Run it again, but don't press anything. It will type out the full\nmessage, then:\nSo there you have it! No more staring at loading screens. By using:\nListener started...\nPress ENTER anytime to stop...\nRequesting stream...\nStreaming response:\nThis is a streaming response from LLM. Today is a sunny day. The sun i\nshining...\n--- Enter pressed! Sending stop signal ---\n--- Interrupted by user ---\nWaiting for listener to stop...\nListener stopped.\n--- Stream finished ---\nWaiting for listener to stop...\nListener stopped.\nConclusion: You've Got the Power!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial14/16\n\n1. LLM Streaming (stream=True): Get text piece by piece.\n2. Background Listening (threading): Watch for the Enter key.\n3. Simple Signal (threading.Event): A basic flag to say \"STOP!\".\n4. Organized Code (PocketFlow Node): Keep the setup, work, and cleanup tidy.\n...you can make AI interactions feel way faster and put yourself back in the driver's\nseat. Stop the AI when you want to!\nUsing PocketFlow just makes managing the tricky bits (like background tasks) mu\ncleaner with its simple prep/exec/post recipe.\nGo grab the code, play around, and build AI tools that feel snappy and responsive!\nWant more? Check out The Code at the GitHub: PocketFlow LLM Streaming Cookboo\nexplore the PocketFlow Framework on the PocketFlow GitHub Repo, or Chat with Us on\nPocketFlow Discord. Happy streaming (and interrupting)!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n15 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial15/16\n\n1 more comment...\nWrite a comment...\nMay 10\nLiked by Zachary Huang\n1 reply by Zachary Huang\nTRAN QUANG THIEN\nThanks for the wonderful post. Just one question. What will happen if we donʼt raise\ninterrupt_event.set() in the post processing part?\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:41 PMStreaming LLM Responses — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/streaming-llm-responses-tutorial16/16"
  },
  {
    "filename": "PocketBlog250510.pdf",
    "title": "The Ultimate AI Experiment: When LLMs Play t",
    "date": "2025-05-10",
    "content": "\n\nThe Ultimate AI Experiment: When LLMs Play t\nDanganronpa Killing Game (Part 1)\nMAY 10, 2025\nSh\nEver wondered what happens when super-smart AI isn't just a tool, but a player in a cr\ngame of lies, strategy, and survival? What if AI could truly act out complex characters,\nscheme against each other, and fight for their lives in a twisted social deduction game?\ntwo-part series shows you how we built exactly that: an AI-powered Danganronpa simu\nwhere the characters are anything but predictable. Play the game yourself! or check out\nopen-source code on GitHub!\nZACHARY HUANG\n4\n1. The LLM Game Paradox: Powerful Tech,\nUnfulfilled Potential\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms1/13\n\nLet's be real: Large Language Models (LLMs) are doing some mind-blowing stuff l\n– things that felt like pure sci-fi just a few years back! We've seen them crush supe\ncomplex games like Go, write surprisingly human-like text and code, and even run\nsimulations. AI agents can now explore and conquer virtual worlds like Minecraft\n(from NVIDIA's Voyager) and some can even beat entire RPGs like Pokémon. The\npower is definitely there.\nSo, here's the big question: If LLMs are so smart, why aren't we seeing tons of\nawesome games where the AI characters (NPCs) actually feel alive? Why do many \ninteractions in games still feel a bit... meh?\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThe Problem: NPCs Can Be Super Boring\nWe've all been there, right? You walk up to an NPC, and sure, they say their lines, \nthey often lack that spark. They feel like slightly fancier versions of those stiff\ncharacters from older games – they're there, they work, but they rarely surprise you\nmake you feel truly connected. They just follow their scripts and don't really seem\nhave their own secret plans or motivations.\nThe result? Talking to them feels like a chore, and the game world, even with all it\ncool tech, can feel a bit lifeless. It feels like we're this close to LLMs creating truly\nawesome social experiences in games, but we're not quite there yet.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms2/13\n\nWe think the secret sauce isn't just about more computer power. It's about giving AIs m\npersonality and putting them in a game that forces them to show it. What if, instead of tr\nto build the perfect all-around NPC, we threw AIs into a crazy, high-stakes situation wh\nthey had to be more than just talking heads?\nSo, what did we do? We built The Agentic Danganronpa Simulator. Instead of ma\na new game from scratch, we used a game series famous for its wild characters and\nsuper-tense social gameplay: Danganronpa.\nIf you haven't heard of it, Danganronpa is a popular Japanese game. Think of it lik\ntwisted reality show meets murder mystery. A bunch of super-talented high schoo\nstudents (each an \"Ultimate\" something, like \"Ultimate Detective\" or \"Ultimate Po\nStar\") get trapped by a creepy, remote-controlled bear named Monokuma. His dea\nescape, a student has to murder a classmate and then get away with it in a \"Class Tr\n2. The Solution: Unleash AI into the\nDanganronpa Killing Game!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms3/13\n\nIn these trials, everyone debates and votes on who they think the killer (the\n\"Blackened\") is. Guess right? Only the killer is punished. Guess wrong? Everyone e\ngets punished, and the killer goes free. Yikes!\nWhy Danganronpa? Because it's the perfect pressure cooker for AI!\nThis game is amazing for testing AI because it naturally has two things most AI ga\nexperiences are missing:\nWild, Built-in Characters: Danganronpa gives us a whole cast of \"Ultimate\"\nstudents with big personalities, unique ways of talking, and clashing goals.\nImagine an AI trying to be Kokichi Oma, the \"Ultimate Supreme Leader,\" wh\nloves to lie and cause trouble. Or Miu Iruma, the \"Ultimate Inventor,\" a super\nsmart but foul-mouthed genius. These aren't just boring roles; they're like dee\ncharacter studies waiting for an AI to jump in. The potential for crazy, charac\ndriven moments is huge!\nGameplay That Creates Drama and Deception: The whole \"Killing Game\" se\nis designed to make things intense. An AI can't just say it's a character; it has \nact like them when things get real. Will the AI playing the nice guy Gonta\nGokuhara freak out if he's falsely accused? How will the AI playing the smart\nKyoko Kirigiri figure out the truth while keeping her own secrets? The consta\ndanger, the need to lie, and the public accusations of the Class Trial force the \nto think strategically, team up, betray each other, and fight for their (virtual) li\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms4/13\n\nBasically, we're not just asking LLMs to play Danganronpa. We're asking them to becom\ncharacters. We want to see if their smarts and language skills can create the same kind \nexciting, unpredictable, and very human (or inhuman!) drama that makes the original gam\nawesome.\nAlright, picture this: 12 players are thrown into this high-stakes game of survival a\ndeception. But here's the kicker – not everyone is who they seem!\nEach player gets a secret role. This is where the fun (and paranoia) begins:\nThe Blackened (3 of them): These are your undercover killers. Their mission? \neliminate other players without getting caught. The cool part? They know wh\n3. So, How Does This Twisted Game Actually\nWork?\nMeet the Players (Shhh, Roles are Secret!):\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms5/13\n\ntheir fellow Blackened are and secretly team up each night to choose one vict\nDiabolical!\nThe Truth-Seeker (Just 1!): This player is like a secret detective. Each night, th\ncan privately investigate one player to find out if they're a Blackened or an\ninnocent Student. Crucial intel!\nThe Guardian (Also just 1!): The protector! Each night, the Guardian can choo\none player to shield from harm. But there's a catch: they can't pick the same\nplayer two nights in a row. Adds a bit of strategy, right?\nThe Students (The Innocent 7): These are the regular folks just trying to surv\nTheir goal? To figure out who the Blackened are and vote them out during the\nClass Trials before it's too late.\nThe game unfolds in a few key phases:\n1. Night Phase (When the Scheming Happens):\nFirst, the Blackened secretly chat amongst themselves and then vote on w\nto... eliminate. (Dun dun dun!)\nThe Truth-Seeker picks one player to investigate, hoping to uncover a\nBlackened.\nThe Guardian chooses someone to protect for the night.\n2. Morning Phase (The Big Reveal):\nMonokuma pops up to announce what happened. Either a player has been\neliminated (and their role is revealed – gasp!), or the Guardian successfully\nprotected their target. Sometimes, the Blackened might even choose to\nabstain from killing, just to mess with everyone's heads!\n3. Class Trial Phase (Let the Accusations Fly!):\nThis only happens if someone was eliminated. Now, things get intense.\nDiscussion Time: All surviving players get to speak their minds, one by on\na set order. This is where they present evidence, make accusations, or\nThe Daily Grind: Night, Morning, and... Trial!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms6/13\n\ndesperately try to look innocent.\nThe Vote: After the discussion, everyone publicly votes for who they think\nBlackened culprit is.\nExecution (or not): The player with the most votes gets kicked out, and th\nrole is revealed. If there's a tie, nobody gets expelled, and the tension\ncontinues!\nThere are two main teams, each with a different way to win:\nTeam Hope (Students, Truth-Seeker, Guardian): They win if they successfully\nkick out all three Blackened. Justice prevails!\nTeam Despair (The Blackened): They win if the number of Blackened become\nequal to or greater than the number of other living players. Basically, when\ndespair takes over!\nThis setup is what makes the game a thrilling mix of deduction, bluffing, and socia\nstrategy. Seeing our AIs navigate this complex web of rules, roles, and relationship\nwhat the Agentic Danganronpa Simulator is all about!\nHow Do You Win This Crazy Game?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms7/13\n\nAnd guess what? You can experience this chaos firsthand:\nPlay the Game NOW: https://danganronpa.app/\nCheck Out the Code (It's Open Source!): https://github.com/The-\nPocket/PocketFlow-Tutorial-Danganronpa-Simulator\nWatch Recorded Games (Seriously, It's Nuts!): https://www.youtube.com/play\nlist=PLRYer4Da-4mJUSxS5oyn6GbXg4YWHe5Cr\nNow that you know how the game works, let's talk about what happened when we\nunleashed our AIs into it...\nWhat really kicks the Agentic Danganronpa Simulator up a notch is seeing real so\nstrategy and deception emerge. The AIs aren't just trying to figure out \"whodunn\n4. The AI Mind Game: More Than Just Finding\nthe Killer\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms8/13\n\nthey're deep in a cutthroat social game where persuading, manipulating, and even\nbackstabbing are as crucial as actual clues.\nIt's fascinating to see these AI agents, powered by advanced language models,\ngenuinely grapple with their assigned personalities and the game's pressures. They\ndon't just recite lines; they reason, they suspect, they panic, and sometimes, they eve\ntroll, each approaching the challenges with its own information and biases.\nThe Persuasion Game (and the Lying Game!): Knowing the truth is only half \nbattle. An AI Student who's fingered the Blackened still needs to convince othe\nAIs. This involves crafting arguments, playing to others' personalities (or\nexploiting their weaknesses!), and navigating a minefield of deliberate\nmisinformation spread by a cunning AI Blackened.\nLobbying and Alliance Building: You'll see AIs trying to rally support, somet\nforming shaky voting blocs. A Blackened AI might subtly try to pin the blame\nan innocent but unpopular character. A proactive Student AI might try to lead\ncharge, only to become a target for being too outspoken.\nThe Art of the Bluff: When is it smart for an AI Truth-Seeker to reveal their r\nand findings? Doing so provides valuable information but also makes them a\nprime target. Some AIs might even fake being the Truth-Seeker – either to pro\nthe real one or just to stir the pot (a classic Kokichi move!).\nCalculated Betrayal: What happens when an AI Blackened sees their teamma\nabout to be exposed? Do they sink with them, or make the cold-blooded choic\n\"bus\" their ally (throw them under to save themselves and look more trustwor\nOur AIs have surprised us with their capacity for such ruthless (and strategica\nsound!) moves.\nBecause the interactions are primarily text-based, the AIs have a vast canvas for\nstrategic maneuvering. They aren't limited to predefined dialogue trees or action\nIt's a Social Battlefield, Not Just an Investigation:\nFreedom to Scheme: The Unpredictability of Text-Base\nStrategy\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms9/13\n\nmenus. They can:\nFilibuster or Misdirect: An AI trying to buy time or protect an ally might laun\ninto lengthy, irrelevant arguments.\nSow Seeds of Doubt: Subtle insinuations or pointed questions can shift the\ngroup's focus, often based on flimsy (or entirely fabricated) \"evidence.\"\nExploit Emotional States: If an AI character is known to be gullible or prone \npanic, other AIs (especially a Blackened) might target them with manipulative\ntactics.\nWhat kind of strategy would you devise if you were one of these AIs? Would you p\nsafe, lay low, and observe? Or would you take bold risks, make daring accusations,\ntry to control the flow of the Class Trial? The simulator allows these AI agents to\nexplore a wide range of such tactics, often leading to emergent gameplay that feels\nremarkably organic.\nOne of the coolest parts is peeking into the AI's \"thinking\" process (which we log)\na unique look at their reasoning and how they strategize:\n\"Okay, [Character X] is accusing me, but their logic is flawed because [recap Y]. Best\nmove: counter-accuse based on [detail Z], try to make them look flustered.\"\n\"As a Blackened, my teammate [Character A] is drawing too much heat. If I don't vot\nthem, we both go down. Sacrificing them makes me look like I'm helping the Students\nRisky, but necessary.\"\n\"I'm the Truth-Seeker; I know [Character B] is Blackened. But if I reveal myself now, \nother Blackened will target me tonight. Need to subtly guide discussion to [Character \nwithout exposing my role.\"\nThese internal monologues show AIs aren't just randomly generating text; they're\nstrategizing, reacting, and pursuing objectives based on their role and personalit\nWitnessing the \"Inner Sanctum\": The AI's Hidden\nThoughts\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms10/13\n\nThis depth turns the game from a simple simulation into a compelling psychologi\ndrama.\nReady to see some of this in action? Don't forget to check out the Recorded Game Playli\nwitness these AI machinations firsthand!\nWe've seen how our Agentic Danganronpa Simulator can turn code and AI promp\ninto a surprisingly gripping show of personality, strategy, and betrayal. The AIs pl\naccuse, defend, and despair, often acting shockingly like their famous Danganronp\ncharacters.\nBut how does this all actually work? Like, what's going on under the hood?\n5. The Code Behind the Chaos: Coming Up in\nPart 2!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms11/13\n\nHow do we keep a wild Danganronpa game flowing smoothly, from secret nig\nactions to chaotic class trials, making sure every AI gets its turn and the right\ninfo?\nWhat does the tech setup look like to manage all these different AI agents?\nHow do we make sure an AI playing a super-secretive character like Kokichi O\ndoesn't accidentally see the Truth-Seeker's private notes? (Spoiler: It involves\nsome clever tricks with information control!)\nWhat kind of digital notebooks do we need to keep track of everyone's roles, t\nmoves, their \"secret thoughts,\" and the constantly changing game state?\nAnd what about those little \"game design\" tweaks, like giving the main charac\na bit of \"plot armor\" so you (if you play as Shuichi) don't just get knocked out \nthe first round every time by super-strategic AIs?\nThese are the juicy questions we'll dig into in Part 2: Architecting Despair - Insid\nthe Danganronpa Simulator. We'll pull back the curtain and get into the techy det\nexploring how the system is built, the game's digital flowchart, the key ways we ha\nsecret information, how we log every whisper and accusation, and the tricks that k\nthe despair running smoothly.\nIf you're curious about building your own complex, AI-driven games, or just want \nknow the engineering secrets behind making AIs convincingly scheme and strateg\nyou won't want to miss it!\nFor now, why not try to survive the Killing Game yourself, or explore the open-source cod\nGitHub and see if you can spot the beginnings of the chaos we've talked about? The desp\njust getting started!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms12/13\n\n4 Likes\nDiscussion about this post\nPreviousNext\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 1)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms13/13"
  },
  {
    "filename": "PocketBlog250515.pdf",
    "title": "Build Your Own Voice Chatbot From Scratch —",
    "date": "2025-05-15",
    "content": "\n\nBuild Your Own Voice Chatbot From Scratch —\nPocketFlow Tutorial!\nMAY 15, 2025\n1Sh\nEver chatted with your smart speaker and wondered, \"How'd it DO that?\" Or maybe y\ndreamed of building your own voice assistant, like the cool one in our PocketFlow Voic\nChat Cookbook? This guide is your ticket! We'll build an AI Voice Chatbot from zero, u\nthe super-duper simple PocketFlow framework.\nEver talked to your phone to set a reminder, or asked your smart speaker about the\nweather? Yep, that's voice control! It's simply how we chat with our gadgets using\nour voice. And guess what? It's popping up everywhere: in our phones (think Siri o\nZACHARY HUANG\n16\n1. Hello, Voice Control!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from1/28\n\nGoogle Assistant), smart speakers (like Alexa), cars, and even when you call custom\nservice.\nWhy's everyone gabbing with their tech?\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nIt Just Feels Right: Talking is human! It's often easier than typing or clicking.\nHands-Free, Eyes-Free! Awesome for when you're busy, like cooking or drivin\nPlus, it helps more people use tech easily.\nSuper Speedy: Saying what you want is often quicker than navigating menus.\nReady to build one? Sweet! In this tutorial, you're going to create your very own v\nchatbot. We're talking an app that listens, gets what you're saying, thinks, and cha\nright back. We'll snag some cool tricks and code snippets from our PocketFlow Vo\nChat Cookbook to make it easier.\nOur main tool for this quest? PocketFlow! Think of PocketFlow as your easy-peas\ntoolkit for building tricky apps (like voice ones!) without the usual headaches. No\nconfusing code jungles here! PocketFlow chops the big job into small, clear steps, \nlike a recipe. It's your simple map from \"you talking\" to \"app talking back smartly\nLet's give your apps a voice!\nEver wonder what's happening when your voice app \"understands\" you? It's not q\nsorcery, but more like a well-rehearsed play with a few key actors. Your voice app\nneeds to:\n1. Listen to you.\n2. The Magic of Voice: How's It Actually Work?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from2/28\n\n2. Understand what you said.\n3. Talk back helpfully.\nLet's imagine you ask your app:\nYou: \"Hey Computer, what's the weather like today?\"\nHere's the behind-the-scenes journey:\nLet's walk through that journey step-by-step:\n1. You Speak & The App Listens (The \"Listening\" Part):\nYou kick things off: \"Hey Computer, what's the weather like today?\"\nThe Voice App is all ears! It grabs your voice and turns it into digital soun\ndata. Think of it like hitting \"record\" on a tape recorder.\n2. Sound to Words (Speech-to-Text – First part of \"Understanding\"):\nOur app is smart, but it doesn't understand raw sound. So, it sends your\nrecorded voice data to a Speech-to-Text (STT) Engine.\nThis STT engine is like a super-fast transcriptionist. It listens to the audio\ntypes out the words: \"Hey Computer, what's the weather like\ntoday?\".\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from3/28\n\n3. Figuring Out Your Request (The \"App Brain\" – Second part of\n\"Understanding\"):\nNow that your question is in text form, the Voice App passes it to its App\nBrain. This brain could be simple logic for basic commands, or for more\ncomplex chats (like ours!), it's often a Large Language Model (LLM).\nThe App Brain deciphers your request (you want the weather forecast!) an\nprepares a text answer, something like: \"It's sunny with a high o\n75 degrees.\".\n4. Words Back to Sound (Text-to-Speech – First part of \"Responding\"):\nYou asked with your voice, so you probably want to hear the answer, not re\nit. The app sends the text response to a Text-to-Speech (TTS) Engine.\nThe TTS engine does the reverse of STT. It takes the written words and\ngenerates spoken audio, complete with a voice.\n5. The App Talks Back! (Playing Audio – Second part of \"Responding\"):\nFinally, the Voice App plays this newly created audio. You hear: \"It's sunn\nwith a high of 75 degrees.\"\nAnd voilà! The conversation cycle is complete.\nSo, it's not quite magic, but a well-orchestrated flow: your app listens to your audio, chang\nto text, figures out what you mean, drafts a text reply, turns that reply into audio, and th\nplays it for you. Each step is a crucial piece of the puzzle for a smooth, human-like voi\ninteraction. In the next sections, we'll explore the specific components that handle each\nthese important jobs.\nAlright, let's pop the hood and see what individual parts (or \"components\") work\ntogether to make our voice chatbot tick. Think of these as the specialized crew\nmembers, each with a critical job to do in our voice interaction assembly line.\n3. Core Components of a Voice Application\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from4/28\n\nEver notice how your smart speaker only perks up when you actually say somethin\nand not when the TV is blaring or you're just quietly sipping your coffee? That's V\nActivity Detection (VAD) in action! It's like a smart bouncer for your app's\nmicrophone, deciding when to hit \"record\" because it hears real speech, and when\nchill because it's just background noise or silence. It does this by checking the ene\nof the sound it picks up.\nHere's how we can build a basic VAD to record speech. We'll break the code down\nsmall, easy-to-digest pieces.\nPiece 1: Setting up the Recorder\n1. Voice Activity Detection (VAD) – The Smart Listener\nimport sounddevice as sd\nimport numpy as np \n# Our VAD recorder function\ndef record_with_vad(\n    sample_rate=44100,      # How many sound snapshots per second\n    chunk_size_ms=50,       # How big is each audio piece we check (in\nmilliseconds)\n    silence_threshold_rms=0.01, # How quiet is \"silence\"?\n    min_silence_duration_ms=1000 # How long silence means \"user stoppe\ntalking\"\n):\n    recorded_frames = []    # This will store our recorded audio\n    is_recording = False    # Are we currently recording?\n    silence_counter = 0     # Counts how long it's been silent\n    # Convert ms to frames/chunks for sounddevice\n    chunk_size_frames = int(sample_rate * chunk_size_ms / 1000)\n    min_silence_chunks = int(min_silence_duration_ms / chunk_size_ms)\n    print(\"  Shhh... I'm listening for your voice...\")\n    # Open the microphone stream\n    # 'with' ensures the mic closes automatically\n    with sd.InputStream(samplerate=sample_rate, \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from5/28\n\nFirst, we set up our record_with_vad function. It has a few important settings, \nknobs on an old radio, that tell it how to listen:\nsample_rate (e.g., 44100 Hz): This is like the number of \"snapshots\" your m\ntakes of the sound every second. More snapshots mean clearer, higher-quality a\n– think a high-res photo vs. a blurry one! 44,100 is a common standard.\nchunk_size_ms (e.g., 50 milliseconds): Our app doesn't listen to everything \nonce; it listens in tiny \"chunks.\" This setting decides how big each chunk is.\nsilence_threshold_rms (e.g., 0.01): This is our \"shhh!\" level. If a sound\nchunk's energy is below this, we consider it silence.\nmin_silence_duration_ms (e.g., 1000 milliseconds): This is the \"are you \nyet?\" timer. If it stays quiet for this long, the app assumes you've stopped talki\nInside the function, we prepare to store recorded_frames (that's your voice!) an\nuse is_recording and silence_counter to keep track. We also do a quick\ncalculation to turn our millisecond settings into something sounddevice\nunderstands (frames/chunks). Finally, sd.InputStream opens up the microphon\nThe with keyword is neat because it makes sure the mic is properly closed when w\ndone.\nPiece 2: The Listening Loop and Energy Check\n(Continuing from inside the with sd.InputStream... block from the previou\nsnippet)\nblocksize=chunk_size_frames) as stream:\n        # ... more code inside the loop coming next!\n        # ... (previous setup code from Piece 1 ended with 'with \nsd.InputStream...')\n        # This loop keeps running, listening in small chunks\n        while True: \n            # Read a small chunk of audio from the microphone\n            # audio_chunk_np is an array of numbers representing the \nsound\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from6/28\n\nNow for the main action! The while True: loop means our app is constantly\nlistening. In each round of the loop:\n1. stream.read(...) grabs a tiny piece of sound from your microphone. This\nsound data comes in as a list of numbers (a NumPy array, which we call\naudio_chunk_np).\n2. Then, rms = np.sqrt(np.mean(audio_chunk_np**2)) is like our VAD\near. It calculates the \"Root Mean Square\" (RMS) of the audio chunk. Fancy nam\nsimple idea: it tells us the average energy or loudness of that tiny sound piece.\nhigher RMS means more energy (likely speech!), and a lower RMS means less\nenergy (likely silence!).\nPiece 3: Deciding When to Record (The VAD Logic)\n(Continuing from inside the while True: loop from the previous snippet)\n            audio_chunk_np = stream.read(frames=chunk_size_frames)[0] \n            # Calculate the 'energy' (RMS) of this audio chunk\n            # Big RMS = loud sound (maybe speech!), Small RMS = quiet \n(maybe silence!)\n            rms = np.sqrt(np.mean(audio_chunk_np**2))\n            # ... logic for starting/stopping recording based on RMS \ncomes next!\n            # ... (RMS calculation from Piece 2) ...\n            if is_recording:\n                # If we are already recording...\n                recorded_frames.append(audio_chunk_np) # Add the curre\nsound to our collection\n                if rms < silence_threshold_rms: # Is it quiet now?\n                    silence_counter += 1 # Count this quiet chunk\n                    if silence_counter >= min_silence_chunks: # Has it\nbeen quiet long enough?\n                        print(\"狼 Silence detected, stopping \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from7/28\n\nThis is where the VAD magic happens, based on that RMS energy we just calculat\nIf is_recording is True (we're already capturing your voice):\nWe keep adding the incoming audio_chunk_np to our recorded_fram\nIf the rms drops below our silence_threshold_rms (it got quiet), we s\ncounting (silence_counter).\nIf it stays quiet for long enough (silence_counter >=\nmin_silence_chunks), we print a message and break out of the while\nTrue loop, meaning recording is done for this segment.\nIf it gets loud again while we were counting silence, we reset\nsilence_counter because you're still talking!\nElse if is_recording is False (we're waiting for you to speak) AND rms is\nhigh enough:\nWoohoo! Speech detected! We set is_recording = True, save this firs\nchunk of speech, and reset any silence count.\nOnce the loop breaks (because enough silence was detected), the function returns \nthe recorded_frames it collected. That's your voice, ready for the next step!\nrecording.\")\n                        break # Stop the loop (and thus recording)\n                else:\n                    silence_counter = 0 # Oh, you're talking again! \nReset silence count.\n            elif rms > silence_threshold_rms: # If NOT recording, and \nit's loud enough...\n                print(\" Speech detected, starting recording!\")\n                is_recording = True       # Start recording!\n                recorded_frames = [audio_chunk_np] # Begin with this \nfirst speech chunk\n                silence_counter = 0       # Reset silence counter\n    # After the loop finishes (because of 'break')...\n    return recorded_frames # Send back all the recorded voice!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from8/28\n\nVisualizing the VAD Logic (Walking through the code):\nThat's how our VAD code figures out when you're talking! To see the overall flow \nthese decisions, let's look at a quick diagram:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from9/28\n\nIn summary, the record_with_vad function continuously listens to the microph\nin small chunks. It calculates the RMS energy of each chunk. If speech is detected\n(energy goes above silence_threshold_rms), it starts recording. If it's already\nrecording and detects a period of silence (energy stays below the threshold for\nmin_silence_duration_ms), it stops that recording segment and returns the\ncaptured audio frames.\nAlright, our app has \"heard\" you, thanks to VAD. But computers are way better at\nunderstanding written words than raw sound waves. That's where the Speech-to-T\n(STT) engine swoops in – it's like a super-fast, accurate typist for audio!\nHere's how we can get text from our recorded audio using OpenAI:\n2. Speech-to-Text (STT) – The Transcriber\nimport io # We'll use this small helper\n# And 'audio_bytes' contains the sound data from VAD (e.g., in WAV \nformat)\ndef speech_to_text_api(audio_bytes):\n    if not audio_bytes:\n        print(\"路 No audio to transcribe!\")\n        return None\n    print(\"➡ Sending audio to OpenAI for transcription...\")\n    # We need to send the audio as if it's a file\n    # io.BytesIO helps us treat our 'audio_bytes' like a file in memor\n    audio_file_like = io.BytesIO(audio_bytes)\n    audio_file_like.name = \"input.wav\" # Giving it a filename helps th\nAPI\n    response = client.audio.transcriptions.create(\n        model=\"gpt-4o-transcribe\", # OpenAI's model for turning speech\nto text\n        file=audio_file_like\n    )\n    print(f\" OpenAI STT says: {response.text}\")\n    return response.text\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from10/28\n\nLet's break that down:\n1. Our function speech_to_text_api needs the client (our connection to\nOpenAI) and the audio_bytes (your recorded voice).\n2. We use io.BytesIO(audio_bytes) to wrap our audio data. Think of it lik\nputting your audio into a digital envelope. Giving it a .name like \"input.wa\nlike labeling the envelope – it helps the OpenAI service understand what kind\naudio it is.\n3. Then, client.audio.transcriptions.create(...) is the magic call. \ntell it which AI model to use (\"gpt-4o-transcribe\" is a powerful one) and\ngive it our \"audio envelope.\"\n4. OpenAI listens to the audio, types out what it hears, and sends back the\nresponse. We just grab the response.text.\nAnd just like that, your spoken words are now text, ready for the app's brain!\nNow that we have text, it's time for our app to think and figure out what to say bac\nThis is where the \"brain\" of our chatbot comes in – usually a Large Language Mod\n(LLM). Imagine it as a super-smart, quick-witted assistant who has read tons of bo\nand conversations, ready to chat about almost anything.\nFirst, we need to prepare the full conversation history, including the user's latest\nmessage, in a format the LLM understands. This is typically a list of messages, eac\nmarked with who said it (\"user\" or \"assistant\"):\n3. Command Processing / LLM Interaction – The Brain\n# 'user_query' is the text from STT (e.g., \"What's the weather like?\")\n# 'chat_history' is a list of past messages, like:\n# [{\"role\": \"user\", \"content\": \"Tell me a joke.\"}, \n#  {\"role\": \"assistant\", \"content\": \"Why did the chicken cross the \nplayground? ...\"}]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from11/28\n\nWith our messages_for_llm ready, here's how we get a response using OpenAI\nWhat's happening here?\n1. Our call_llm function now needs the client and the complete\nmessages_for_llm list.\n2. It sends this entire conversation to a chat model like \"gpt-4o\" using\nclient.chat.completions.create(...).\n3. The LLM thinks and generates a reply based on the whole conversation. We g\nthis reply from response.choices[0].message.content.\nCool! The app now has a smart text response from its AI brain.\nmessages_for_llm = chat_history + [{\"role\": \"user\", \"content\": \nuser_query}]\ndef call_llm(messages_for_llm):\n    if not messages_for_llm:\n        print(\"樂 No messages for the LLM.\")\n        return None\n    print(f\"易 Sending to LLM: latest query '{messages_for_llm[-1]\n['content']}'\")\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",      # A powerful chat model from OpenAI\n        messages=messages_for_llm\n    )\n    llm_reply = response.choices[0].message.content\n    print(f\" LLM replied: {llm_reply}\")\n    return llm_reply\n4. Text-to-Speech (TTS) – The Expressive Voice &\nSpeaker\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from12/28\n\nThe app has figured out what to say (thanks, LLM!), but that reply is still just text. W\nwant our chatbot to talk back! This is the job of the Text-to-Speech (TTS) engine.\nThink of it as a talented voice actor who can read any script you give them, in vari\nvoices.\nLet's make OpenAI say our LLM's response out loud:\nHere's the play-by-play:\n1. Our text_to_speech_api function needs the client, the text_to_spea\nand optionally a voice_choice (OpenAI offers several voices like \"alloy\",\n\"echo\", \"nova\", etc.).\n2. We call client.audio.speech.create(...), giving it:\nThe model for TTS (e.g., \"gpt-4o-mini-tts\").\nThe voice we want.\nThe input text it needs to say.\ndef text_to_speech_api(text_to_speak, voice_choice=\"alloy\"):\n    if not text_to_speak:\n        print(\" Nothing to say for TTS.\")\n        return None\n    print(f\"➡ Sending to OpenAI TTS: '{text_to_speak[:30]}...'\")\n    response = client.audio.speech.create(\n        model=\"gpt-4o-mini-tts\", # A good TTS model\n        voice=voice_choice,   # You can pick different voices!\n        input=text_to_speak,\n        response_format=\"mp3\" # We want the audio back as an MP3\n    )\n    # The audio comes back as raw bytes (a sequence of 0s and 1s)\n    audio_bytes = response.content \n    print(f\" TTS created {len(audio_bytes)} bytes of MP3 audio.\")\n    return audio_bytes\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from13/28\n\nThe response_format – we're asking for an \"mp3\" file, which is a com\naudio format.\n3. OpenAI works its magic and sends back the spoken audio as\nresponse.content. This audio_bytes is the digital sound of the voice.\nAwesome! Now we have actual audio bytes – the app is ready to make some noise.\nWe've got the voice, recorded as a bunch of digital audio_bytes (likely in MP3\nformat from TTS). The very last step? Decoding those bytes and playing the sound\nthrough your computer's speakers so you can hear it! This is like hitting the \"play\"\nbutton on your favorite music app.\nHere's how we can decode and play those TTS audio bytes using sounddevice an\nsoundfile:\n5. Audio Playback – The Speaker\nimport sounddevice as sd\nimport soundfile as sf \nimport io # For BytesIO\ndef decode_and_play_tts_bytes(audio_bytes_from_tts):\n    if not audio_bytes_from_tts:\n        print(\" No audio bytes to play.\")\n        return\n    print(\" Playing audio...\")\n    # soundfile needs to read the bytes as if it's a file\n    # so we wrap audio_bytes_from_tts in io.BytesIO\n    # It decodes the MP3 data and gives us raw sound (sound_data) and \nits speed (samplerate)\n    sound_data, samplerate = sf.read(io.BytesIO(audio_bytes_from_tts),\ndtype='float32')\n    sd.play(sound_data, samplerate) # Play the sound\n    sd.wait() # Wait until playback is completely finished\n    print(\" Playback finished.\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from14/28\n\nLet's tune into what this code does:\n1. The decode_and_play_tts_bytes function gets the\naudio_bytes_from_tts (the MP3 data we got from OpenAI).\n2. To play an MP3, we first need to decode it into raw sound waves that the\ncomputer understands. The soundfile library (we call it sf) is great for this\nsf.read(io.BytesIO(audio_bytes_from_tts), ...) does the trick.\nuse io.BytesIO again to make our bytes look like a file to soundfile. It giv\nus back the sound_data and the samplerate (how fast the sound should be\nplayed).\n3. Then, our old friend sounddevice (called sd) steps up. sd.play(sound_da\nsamplerate) sends the sound to your speakers.\n4. sd.wait() is pretty important: it tells our program to pause and patiently wa\nuntil the sound has completely finished playing before doing anything else.\nAnd boom! Your chatbot speaks! The whole cycle – listening, understanding, think\nand responding with voice – is complete.\nPhew! That was a quick tour of all the main parts. Each one is a specialist, and wh\nthey work together, you get a smooth, chatty app!\nOkay, we've got all these cool parts for our voice chatbot: a listener (VAD), a\ntranscriber (STT), a brain (LLM), a voice (TTS), and a speaker. But how do we get th\nto work together like a well-rehearsed orchestra? That's where PocketFlow steps i\nThink of PocketFlow as a super-simple conductor. It doesn't write the music (that\nwhat our component functions from Section 3 do), but it tells each musician (or\n\"Node\" in PocketFlow terms) when to play its part and makes sure the music flow\nsmoothly from one to the next. PocketFlow is tiny and straightforward, built on a\ncouple of easy ideas: LEGOs® and a Shared Notepad!\n4. Orchestrating Voice Interactions with\nPocketFlow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from15/28\n\nEach main job in our voice chat (like \"listen to audio\" or \"get LLM reply\") become\nNode. A Node is just a Python class representing one step. Here's a simplified pee\nwhat PocketFlow's basic Node looks like internally:\nSo, each Node generally knows how to:\nprep(shared): Get ready! It grabs any info it needs from the common shar\nnotepad.\nexec(prep_res): Do the main work! This is where it would call our functio\nlike record_with_vad or call_llm.\npost(shared, ...): Clean up! It puts its results back on the shared note\nand returns an action_signal (like a string, e.g., \"default\" or \"error\") \nthe Flow, telling it what to do next.\nWhen a Node finishes and returns the \"default\" signal from its post method,\nPocketFlow automatically sends the shared_notepad to the next Node in this ch\nThis is just a regular Python dictionary (e.g., shared_data = {}). All our Nodes\nread from and write to this \"notepad.\" It's how they pass information along the\nassembly line – like the recorded audio, the transcribed text, API keys, and\nconversation history.\n1. Nodes (The LEGO® Bricks)\nclass Node:\n    def __init__(self): self.successors = {}\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass\n    def post(self, shared, prep_res, exec_res): return \"default\"\n    def run(self, shared): p=self.prep(shared); e=self.exec(p); return\nself.post(shared, p, e)\n2. Shared Store (The Central Notepad)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from16/28\n\nA Flow object is in charge of the overall process. You tell it which Node to start w\nHere's a simplified look at PocketFlow's Flow:\nThe Flow's orch (orchestration) method is the core loop. It takes the shared not\nand:\n1. Starts with the self.start node.\n2. Runs the current node (curr.run(shared)), which executes that node's pre\n> exec -> post cycle and returns an action signal.\n3. Looks up that action in the current node's successors dictionary to find t\nnext node.\n4. Continues until no next node is found for a given signal (which ends the flow)\nHow does the Flow know which Node is next for a given action signal? You defi\nthese connections! PocketFlow makes it easy to define the default order of your No\nusing the >> operator:\nWhen a Node finishes and its post method returns the \"default\" signal (or\nwhatever signal >> is configured for), the Flow (using the successors populated\n3. Flow & Connecting Nodes (The Conductor & The Pat\nclass Flow(Node): # A Flow manages a sequence of Nodes\n    def __init__(self, start): \n        self.start = start # The first Node in this Flow\n    def orch(self, shared, params=None): # orch for internal \norchestration\n        curr = self.start\n        while curr: action=curr.run(shared); \ncurr=curr.successors.get(action)\n# This sets up a \"default\" path between them.\nnode1 >> node2 >> node3\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from17/28\n\n>>) sends the shared_notepad to the next Node in this chain.\nLet's make this super clear with a tiny game, now with code: take a number, add 1,\nthen multiply the result by 2.\nFirst, our LEGO® bricks (Nodes):\nTiny Example: Number Game!\n# Assuming our minimal 'Node' class is defined as shown before\nclass AddOneNode(Node):\n    def prep(self, shared_notepad):\n        return shared_notepad.get(\"number\", 0) # Get number, default t\n0\n    def exec(self, number_from_prep):\n        result = number_from_prep + 1\n        print(f\"AddOneNode: {number_from_prep} + 1 = {result}\")\n        return result\n    def post(self, shared_notepad, _, exec_result):\n        shared_notepad[\"number\"] = exec_result # Update number in \nnotepad\n        return \"default\" # Signal to go to next default node\nclass MultiplyByTwoNode(Node):\n    def prep(self, shared_notepad):\n        return shared_notepad.get(\"number\", 0)\n    def exec(self, number_from_prep):\n        result = number_from_prep * 2\n        print(f\"MultiplyByTwoNode: {number_from_prep} * 2 = {result}\")\n        return result\n    def post(self, shared_notepad, _, exec_result):\n        shared_notepad[\"final_result\"] = exec_result # Store final \nresult\n        print(f\"MultiplyByTwoNode: Final result is {exec_result}\")\n        return \"default\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from18/28\n\nNow, let's set up and run this game with PocketFlow:\nSee? PocketFlow just helps us snap our LEGO bricks together and run the process\nThe shared_notepad carries the data between them.\nNow, let's see how our voice chatbot looks as a PocketFlow assembly line. It's desi\nto loop for a continuous conversation:\n# 1. Create instances of our node bricks\nadd_node = AddOneNode()\nmultiply_node = MultiplyByTwoNode()\n# 2. Connect them! This says \"add_node is followed by multiply_node\" f\nthe \"default\" signal.\nadd_node >> multiply_node\n# 3. Create the Flow, telling it to start with add_node\n# (Assuming our minimal 'Flow' class is defined as shown before)\nnumber_game_flow = Flow(start_node=add_node)\n# 4. Let's prepare our shared notepad and run the game!\nshared_notepad = {\"number\": 5} # Start with 5\nprint(f\"Starting Number Game with: {shared_notepad}\")\nnumber_game_flow.run(shared_notepad)\nprint(f\"Number Game finished. Notepad: {shared_notepad}\")\n# Expected console output:\n# Starting Number Game with: {'number': 5}\n# AddOneNode: 5 + 1 = 6\n# MultiplyByTwoNode: 6 * 2 = 12\n# MultiplyByTwoNode: Final result is 12\n# Number Game finished. Notepad: {'number': 6, 'final_result': 12}\n5. The Voice Conversation Loop in Action: A\nPocketFlow Walkthrough\nOur Voice Chatbot as a PocketFlow Assembly Line\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from19/28\n\nEach box in the diagram is a custom Node we'll build (inheriting from PocketFlow\nNode from Section 4). CaptureAudioNode, SpeechToTextNode, and\nQueryLLMNode handle their specific tasks. The TextToSpeechNode will both\nconvert the LLM's text to audio and play it, then decide whether to loop back. The\nshared dictionary (our shared notepad) will carry information like API keys, capt\naudio, transcribed text, and conversation history between them.\nWe learned that PocketFlow Nodes use a common shared dictionary to exchange\ninformation. For our voice chatbot, this shared dictionary is lean and focused,\ntypically holding the following key pieces of data as the conversation progresses:\nThe Voice Chat's shared Dictionary Structure\nshared = {\n    \"user_audio_data\": None,      # NumPy array of user's voice\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from20/28\n\nEach Node can access and update the relevant keys in this dictionary. For example\nCaptureAudioNode would populate \"user_audio_data\" and\n\"user_audio_sample_rate\", while QueryLLMNode would use and update\n\"chat_history\". This keeps our Nodes focused and the data flow clear.\nRemember the Node structure from Section 4, with its prep -> exec -> post\ncycle? The Nodes we're about to explore are built just like that. They all inherit fro\nPocketFlow's base Node class and use the shared dictionary we just discussed to\nnecessary data and to store their results or pass information along.\nThis Node is our chatbot's ears. Its main job is to listen, use Voice Activity Detect\n(VAD) to know when you're talking, and capture your speech.\n    \"user_audio_sample_rate\": None, # int: Sample rate of user's voice\n    \"chat_history\": [],           # list: Full conversation history\n    \"continue_conversation\": True # boolean: Controls conversation loo\n}\nMeet the Node Workers: The prep -> exec -> post Cycl\n1. CaptureAudioNode – The Attentive Listener\nclass CaptureAudioNode(Node):\n    def prep(self, shared):\n        print(\" CaptureAudioNode: Ready to listen...\")\n        return None \n    def exec(self, _):\n        audio_np_array, sample_rate = record_with_vad() \n        if audio_np_array is None:\n             print(\" CaptureAudioNode: No speech detected.\")\n             return None, None # Return tuple\n        return audio_np_array, sample_rate\n    def post(self, shared, _, exec_result):\n        audio_np_array, sample_rate = exec_result if exec_result else \n(None, None)\n        if audio_np_array is not None:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from21/28\n\nHow it works:\nprep: Gets ready to listen.\nexec: Calls our record_with_vad() function (from Section 3), which retur\nNumPy array of the audio and its sample rate.\npost: If voice was captured, it puts the NumPy audio data onto\nshared[\"user_audio_data\"], its sample rate onto\nshared[\"user_audio_sample_rate\"], and signals \"default\". If not, i\nsignals \"next_turn\" to loop back and listen again.\nGot audio? This Node sends it to a Speech-to-Text (STT) service.\n            shared[\"user_audio_data\"] = audio_np_array\n            shared[\"user_audio_sample_rate\"] = sample_rate\n            return \"default\"\n        else:\n            print(\" CaptureAudioNode: No speech detected. Trying \nagain...\")\n            return \"next_turn\"\n2. SpeechToTextNode – The Accurate Transcriber\nclass SpeechToTextNode(Node):\n    def prep(self, shared):\n        audio_np_array = shared.get(\"user_audio_data\")\n        sample_rate = shared.get(\"user_audio_sample_rate\")\n        if audio_np_array is None or sample_rate is None:\n            print(\" SpeechToTextNode: No audio data from shared.\")\n            return None\n        return audio_np_array, sample_rate\n    def exec(self, audio_input_from_prep):\n        if not audio_input_from_prep: return None\n        audio_np_array, sample_rate = audio_input_from_prep\n        # Convert NumPy array to WAV bytes for the API\n        byte_io = io.BytesIO()\n        scipy.io.wavfile.write(byte_io, sample_rate, audio_np_array)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from22/28\n\nHow it works:\nprep: Grabs shared[\"user_audio_data\"] (the NumPy array) and\nshared[\"user_audio_sample_rate\"].\nexec: Converts the NumPy audio array and its sample rate into WAV bytes (u\nio.BytesIO and scipy.io.wavfile.write), then calls\nspeech_to_text_api() which returns the transcribed text.\npost: If text was transcribed, it updates shared[\"chat_history\"] by add\na new entry for the user's query. It then clears the audio data from shared.\nThis Node chats with the LLM, using conversation history for context.\n        wav_bytes = byte_io.getvalue()\n        transcribed_text = speech_to_text_api(audio_data=wav_bytes) \n        return transcribed_text\n    def post(self, shared, _, transcribed_text_from_exec):\n        if transcribed_text_from_exec:\n            history = shared.get(\"chat_history\", [])\n            history.append({\"role\": \"user\", \"content\": \ntranscribed_text_from_exec})\n            shared[\"chat_history\"] = history\n            print(f\" STT adds to history: User said \n'{transcribed_text_from_exec}'\")\n        else:\n            print(\" SpeechToTextNode: No text transcribed.\")\n        shared[\"user_audio_data\"] = None\n        shared[\"user_audio_sample_rate\"] = None\n        return \"default\"\n3. QueryLLMNode – The Intelligent Brain\nclass QueryLLMNode(Node):\n    def prep(self, shared):\n        chat_history_for_llm = shared.get(\"chat_history\", [])\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from23/28\n\nHow it works:\nprep: Gets the full shared[\"chat_history\"] (which should include the la\nuser query from SpeechToTextNode).\nexec: Sends this history to call_llm() which returns the LLM's textual\nresponse.\npost: If the LLM responded, it updates shared[\"chat_history\"] by add\nnew entry for the assistant's reply.\nTurns the LLM's text reply back into audio and plays it for you.\n        if not chat_history_for_llm or \nchat_history_for_llm[-1].get(\"role\") != \"user\":\n            print(\"易 QueryLLMNode: Chat history empty or doesn't end \nwith user query.\")\n            return None \n        return chat_history_for_llm\n    def exec(self, messages_for_llm):\n        if not messages_for_llm: return None\n        llm_response_text = call_llm(messages=messages_for_llm)\n        return llm_response_text\n    def post(self, shared, _, llm_response_from_exec):\n        if llm_response_from_exec:\n            history = shared.get(\"chat_history\", [])\n            history.append({\"role\": \"assistant\", \"content\": \nllm_response_from_exec})\n            shared[\"chat_history\"] = history\n            print(f\" LLM adds to history: Assistant said \n'{llm_response_from_exec}'\")\n        else:\n            print(\"易 QueryLLMNode: No response from LLM.\")\n        return \"default\"\n4. TextToSpeechNode – The Expressive Voice & Speak\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from24/28\n\nHow it works:\nprep: Grabs the latest message from shared[\"chat_history\"], expecting\nto be the LLM assistant's reply.\nexec: Calls text_to_speech_api() (from Section 3.4) which returns the\nsynthesized audio bytes.\npost: If audio bytes were generated, it calls decode_and_play_tts_bytes\n(from Section 3.5) to play the audio. It then checks\nclass TextToSpeechNode(Node):\n    def prep(self, shared):\n        chat_history = shared.get(\"chat_history\", [])\n        if not chat_history or chat_history[-1].get(\"role\") != \n\"assistant\":\n            print(\"烙 TextToSpeechNode: No assistant reply in history \nfor TTS.\")\n            return None\n        text_to_speak = chat_history[-1].get(\"content\")\n        return text_to_speak\n    def exec(self, text_to_speak):\n        if not text_to_speak: return None \n        audio_bytes = text_to_speech_api(text_to_speak) # from Sec 3.4\n        return audio_bytes \n    def post(self, shared, _, audio_bytes_from_exec):\n        if audio_bytes_from_exec:\n            print(f\" TTS generated audio data (approx. \n{len(audio_bytes_from_exec)} bytes). Playing...\")\n            decode_and_play_tts_bytes(audio_bytes_from_exec)\n            print(\" Playback finished.\")\n        else:\n            print(\"烙 TextToSpeechNode: TTS failed or no input\")\n        if shared.get(\"continue_conversation\", True):\n            return \"next_turn\"\n        else:\n            print(\"Conversation ended by user flag.\")\n            return \"end_conversation\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from25/28\n\nshared[\"continue_conversation\"] and signals \"next_turn\" to loop \nto listening or \"end_conversation\".\nNow we snap our LEGO® Node bricks together using PocketFlow to create the ful\nconversation loop.\n5. Connecting the Nodes: The Voice Chat Flow\n# 1. Create instances of all Node workers\ncapture_node    = CaptureAudioNode()\nstt_node        = SpeechToTextNode()\nllm_node        = QueryLLMNode()\ntts_node        = TextToSpeechNode() # This node now also handles \nplayback\n# 2. Connect them to define flow paths based on signals\ncapture_node.add_successor(stt_node, action=\"default\")\ncapture_node.add_successor(capture_node, action=\"next_turn\") # If no \naudio, loop back\nstt_node >> llm_node >> tts_node # Default path for successful \nprocessing\ntts_node.add_successor(capture_node, action=\"next_turn\") # After TTS &\nplayback, loop to listen\n# 3. Create the main flow, starting with capture_node\nvoice_chat_flow = Flow(start_node=capture_node)\n# 4. Running the Conversation Loop\nshared = {\n    \"user_audio_data\": None,\n    \"user_audio_sample_rate\": None,\n    \"chat_history\": [],\n    \"continue_conversation\": True\n}\nvoice_chat_flow.run(shared)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from26/28\n\nAnd that's how PocketFlow helps us build a sophisticated voice chatbot by connec\nsimple, focused Nodes in a clear, manageable loop! This modular design makes it e\nto understand, test, and even swap out parts later.\nAnd there you have it! You've journeyed from a simple \"hello\" with voice comman\nseeing how all the pieces click together to make a voice chatbot that really chats. W\npeeked under the hood to see how your voice gets heard (VAD & Audio Capture),\nturned into words (STT), understood by a smart brain (LLM), and then spoken back\nyou (TTS & Playback), all in a smooth, looping conversation.\nHopefully, this tutorial has shown you that building cool voice-controlled apps do\nhave to feel like rocket science. With a friendly toolkit like PocketFlow, complex t\nbecome way more manageable. PocketFlow is like your helpful conductor, letting y\nfocus on the fun part – what each piece of your voice app should do – instead of ge\ntangled in the tricky wiring. It's all about breaking big ideas into small,\nunderstandable Nodes and letting the Flow make sure they all play nicely togethe\nNow, it's your turn to grab the mic and get creative! We really encourage you to\nexplore the PocketFlow Voice Chat Cookbook we've mentioned. Play around with\nmaybe even try to break it (that's often the best way to learn!), and then build it bac\nup. What if you tried a different voice for the TTS, or made the VAD more or less\nsensitive? What other awesome voice-powered tools can you dream up?\nThe world of voice interaction is getting bigger and more exciting every day, and w\ntools like PocketFlow, you're all set to jump in and be a part of it. Go on, give your\nproject a voice – we can't wait to see what you build!\nReady to explore more or need some help? You can dive deeper by checking out the ma\nPocketFlow repository on GitHub for the core framework, other neat examples, and all \nlatest updates. The complete code for the voice chatbot we discussed is right in the pocketfl\nvoice-chat directory within the PocketFlow cookbook.\n6. Conclusion: Your Voice Adventure Awaits!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from27/28\n\nHappy building, and happy chatting with your new AI creations!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n16 Likes∙1 Restack\nDiscussion about this post\nPreviousNext\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:44 PMBuild Your Own Voice Chatbot From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-voice-chatbot-from28/28"
  },
  {
    "filename": "PocketBlog250524.pdf",
    "title": "Build Your Own AI Code Generator From Scratc",
    "date": "2025-05-24",
    "content": "\n\nBuild Your Own AI Code Generator From Scratc\n— A PocketFlow Tutorial!\nMAY 24, 2025\n53Sh\nEver wished you could just describe a coding problem and have an AI automatically\ngenerate comprehensive test cases, implement the solution, and iteratively improve it u\neverything works perfectly? This guide shows you how to build exactly that using the\nPocketFlow AI Code Generator Cookbook!\nPicture this: You're staring at a LeetCode-like coding problem, and instead of goin\nthrough the usual grind of writing test cases, coding a solution, debugging failures\nZACHARY HUANG\n14\n1. From Problem to Perfect Code: Why AI Code\nGeneration Matters\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator1/15\n\nand repeating the cycle until everything works, you just paste the problem descrip\nand watch an AI system automatically:\n1. Generate comprehensive test cases including all the edge cases you'd probabl\nforget\n2. Implement a clean solution based on the problem requirements\n3. Test everything automatically with detailed pass/fail analysis\n4. Intelligently debug by deciding whether the tests are wrong or the code needs\nfixing\n5. Iterate until perfect - all tests passing with a working solution\nThis isn't science fiction - it's exactly what we're going to build together!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nWhat you'll learn: By the end of this tutorial, you'll have built a complete AI developme\nassistant that can take any coding problem and automatically work through the entir\ndevelopment cycle. We'll use PocketFlow to orchestrate the workflow, making the comp\nprocess surprisingly manageable and easy to understand.\nWait, why not just ask ChatGPT? You might think: \"Why build all this? Can't I ju\npaste the problem into ChatGPT and get the answer?\"\nSure, you could! But here's what typically happens:\nChatGPT gives you one solution (no test cases!)\nIf there's a bug, you have to spot it manually\n2. How AI Code Generation Works: Step-by-St\nwith Two Sum\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator2/15\n\nEdge cases? You better hope you thought of them\nWhat we need instead is a smart workflow. An AI system that can write code, test\ncatch its own mistakes, and fix them. Just like how human developers work: code →\ntest → debug → improve → repeat.\nIn this tutorial, we'll learn hands-on how to build exactly this kind of intelligent\nworkflow using the classic Two Sum problem as our example.\nFirst, let's look at the problem we'll be solving:\nSo how does our intelligent system actually work? Here's the high-level flow we're\ngoing to build:\nNotice the key insight: when tests fail, we don't just give up. We analyze what wen\nwrong and intelligently fix it, then test again. This creates a feedback loop that kee\nimproving until everything works.\nNow let's see this workflow handle our Two Sum problem step by step!\nGiven an array of integers nums and an integer target, return indices \nthe two numbers such that they add up to target.\nExample: nums = [2,7,11,15], target = 9 → Output: [0,1]\nOur Smart Workflow in Action\nStep 1: Generate Test Cases\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator3/15\n\nThe first thing our system does is create comprehensive test cases (way more than\nthe given examples):\nWhy this rocks: It automatically thinks of edge cases like duplicates, negatives, an\nlarger arrays. No more forgetting to test the tricky scenarios!\nWith test cases ready, our system writes clean, efficient code:\nCool detail: It chose the smart O(n) hash map approach instead of the obvious (but\nslow) nested loop. The AI actually thinks about efficiency!\nTime for the moment of truth - our system tests all cases in parallel:\n=== Generated 7 Test Cases ===\n1. Basic case: [2, 7, 11, 15], target=9 → [0, 1]\n2. Duplicates: [3, 3], target=6 → [0, 1]  \n3. Negatives: [-1, -2, -3, -4, -5], target=-8 → [2, 4]\n4. Zero case: [0, 4, 3, 0], target=0 → [0, 3]\n5. End solution: [1, 2, 3, 4, 5, 6], target=11 → [4, 5]\n6. Larger array: [5, 75, 25, 45, 42, 2, 11, 9, 55, 12], target=14 → [2\n6]\nStep 2: Implement Function\ndef run_code(nums, target):\n    num_to_index = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in num_to_index:\n            return [num_to_index[complement], i]\n        num_to_index[num] = i\n    return []\nStep 3: Run Tests\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator4/15\n\nUh oh! One test failed. But here's where the magic happens...\nInstead of panicking, our system analyzes what went wrong:\nArray: [5, 75, 25, 45, 42, 2, 11, 9, 55, 12], target: 14\nPosition 0: 5 + Position 7: 9 = 14 ✅ (what our code found)\nPosition 2: 25 + Position 6: 11 = 36 ❌ (what the test expected)\nPlot twist: The test case was wrong, not the code! Our system figures this out and \nit:\nAfter the fix, our system runs the tests again:\nThe key insight: Instead of blindly \"fixing\" perfectly good code, our system correc\nidentified that the test case had a math error. This is what separates intelligent\nsystems from basic automation.\nThis feedback loop is the secret sauce. The AI writes, tests, analyzes failures, and\nintelligently decides what to fix. Way better than crossing your fingers with a one-\n=== Test Results: 6/7 Passed ===\nFailed: Larger array case\nExpected: [2, 6], Got: [0, 7]\nStep 4: Intelligent Debugging\n=== Smart Fix ===\nTest 6: Expected [2, 6] → [0, 7]\nStep 5: Victory!\n=== Test Results: 7/7 Passed ===\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator5/15\n\nChatGPT answer!\nReady to build this? Let's dive into the tools that make it possible.\nNow that we understand the conceptual process, how do we actually build a system\nthat can orchestrate these steps, handle the decision-making, and manage the itera\nimprovements? This is where PocketFlow becomes our secret weapon!\nThink of PocketFlow as your development workshop manager. Just like a well-\norganized workshop has different workstations for different tasks, PocketFlow hel\nyou create specialized \"workers\" for each job and coordinate them smoothly.\nIn PocketFlow, each major task becomes a Node - think of it as a specialist worker\nwho's really good at one specific job:\nThis is like a simple recipe: prep (gather ingredients), exec (cook), post (serve and\ndecide what's next). Each Node knows its job and signals what should happen next\n3. Building Intelligent Workflows with\nPocketFlow: The Perfect Toolkit\nThe Workshop Approach: Nodes as Specialist Workers\nclass Node:\n    def __init__(self): self.successors = {}\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass  \n    def post(self, shared, prep_res, exec_res): pass\n    def run(self, shared): p=self.prep(shared); e=self.exec(p); return\nself.post(shared,p,e)\nThe Shared Workspace: Information Hub\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator6/15\n\nThink of this as a shared whiteboard where all workers can read and write:\nEach worker grabs what they need from this shared space and leaves their results \nothers.\nLet's build a tiny workflow that takes a number, adds 5, then multiplies by 2:\nshared = {\n    \"number\": 10,\n    \"result\": None\n}\nQuick Example: Simple Math Pipeline\nclass AddFive(Node):\n    def prep(self, shared):\n        return shared[\"number\"]\n    def exec(self, number):\n        return number + 5\n    def post(self, shared, prep_res, result):\n        shared[\"number\"] = result\n        print(f\"Added 5: {result}\")\n        return \"default\"\nclass MultiplyByTwo(Node):\n    def prep(self, shared):\n        return shared[\"number\"]\n    def exec(self, number):\n        return number * 2\n    def post(self, shared, prep_res, result):\n        shared[\"result\"] = result\n        print(f\"Final result: {result}\")\n        return \"default\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator7/15\n\nEach worker does one simple job and passes the result along.\nIt's like saying: \"First add 5, then multiply by 2.\"\nThe Beauty: Each worker is simple and focused. Need to change the math? Just sw\nout a worker. Want to add more steps? Connect more workers. The smart behavior\ncomes from how they work together, like musicians in an orchestra!\nFor our AI code generator, we'll have workers like:\nTestCaseGenerator: Creates comprehensive test suites\nCodeImplementer: Writes clean implementations\nTestRunner: Executes tests efficiently\nSmartReviewer: Analyzes failures and decides fixes\nSame simple pattern, just with more sophisticated jobs.\nConnecting Workers: The Assembly Line\n# Connect workers in sequence (the >> means \"then go to\")\nadd_worker = AddFive()\nmultiply_worker = MultiplyByTwo()\nadd_worker >> multiply_worker\n# Create the manager and run it\nmath_flow = Flow(start=add_worker)\nshared = {\"number\": 10}\nmath_flow.run(shared)\n# Output:\n# Added 5: 15\n# Final result: 3\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator8/15\n\nNow let's build the actual workers! Each one handles a specific job in our developm\nworkflow.\nOur workers communicate through a simple dictionary that holds everything need\nfor the code generation workflow:\nThink of this as a desk where each worker leaves notes for the next person. We ne\nthe original problem description, test cases to validate our solution, the actual cod\nimplementation, test results to know what passed or failed, and an iteration count\nprevent infinite loops.\n4. Building the Code Generator with PocketFlo\nNodes\nThe Shared Memory Structure\nshared = {\n    \"problem\": \"Problem description...\",\n    \"test_cases\": [{\"name\": \"Basic case\", \"input\": {...}, \"expected\": \n\"result\"}],\n    \"function_code\": \"def run_code(...): ...\",\n    \"test_results\": [{\"passed\": True, \"error\": None}],\n    \"iteration_count\": 0\n}\nWorker 1: The Test Case Generator\nclass GenerateTestCases(Node):\n    def prep(self, shared):\n        return shared[\"problem\"]\n    def exec(self, problem):\n        prompt = f\"Generate test cases for: {problem}\\nOutput as \nYAML...\"\n        response = call_llm(prompt)\n        return yaml.safe_load(response)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator9/15\n\nThis worker reads the problem, asks an AI to create test cases in YAML format, pa\nthe response, and stores the test cases. Simple as that!\nThis worker takes the problem and test cases, asks the AI to write code, and stores\nresult. The AI sees both the problem AND the tests, so it writes better code.\n    def post(self, shared, prep_res, result):\n        shared[\"test_cases\"] = result[\"test_cases\"]\n        print(f\"Generated {len(result['test_cases'])} test cases\")\nWorker 2: The Code Implementer\nclass ImplementFunction(Node):\n    def prep(self, shared):\n        return shared[\"problem\"], shared[\"test_cases\"]\n    def exec(self, inputs):\n        problem, test_cases = inputs\n        prompt = f\"Implement: {problem}\\nTests: {test_cases}\\nFunction\nmust be named 'run_code'\"\n        response = call_llm(prompt)\n        return yaml.safe_load(response)\n    def post(self, shared, prep_res, code):\n        shared[\"function_code\"] = code\n        print(\"Function implemented\")\nWorker 3: The Test Runner (Batch Processing)\nclass RunTests(BatchNode):\n    def prep(self, shared):\n        code = shared[\"function_code\"]\n        tests = shared[\"test_cases\"]\n        return [(code, test) for test in tests]\n    def exec(self, test_data):\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator10/15\n\nThis uses BatchNode to test all cases one-by-one. Each test gets the code and one\ncase, runs it safely, and returns the result.\nThe post method handles the results:\nThis counts passes/fails, prints results, and signals what to do next: celebrate succ\ngive up after too many tries, or fix the problems.\n        code, test_case = test_data\n        output, error = execute_python(code, test_case[\"input\"])\n        return {\n            \"test_case\": test_case,\n            \"passed\": output == test_case[\"expected\"] and not error,\n            \"actual\": output,\n            \"error\": error\n        }\n    def post(self, shared, prep_res, results):\n        shared[\"test_results\"] = results\n        passed = sum(1 for r in results if r[\"passed\"])\n        print(f\"Tests: {passed}/{len(results)} passed\")\n        if all(r[\"passed\"] for r in results):\n            return \"success\"\n        elif shared.get(\"iteration_count\", 0) >= 5:\n            return \"max_iterations\"\n        else:\n            return \"failure\"\nWorker 4: The Smart Reviewer\nclass Revise(Node):\n    def prep(self, shared):\n        failures = [r for r in shared[\"test_results\"] if not \nr[\"passed\"]]\n        return {\n            \"problem\": shared[\"problem\"],\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator11/15\n\nThis worker gathers all the context about what failed, asks the AI to analyze and\ndecide what to fix, then returns structured fixes.\nThis applies the AI's suggested fixes to either test cases, code, or both. The AI mig\nsay \"test case 3 has wrong expected output\" or \"the algorithm needs a different\napproach.\"\n            \"code\": shared[\"function_code\"], \n            \"failures\": failures\n        }\n    def exec(self, data):\n        prompt = f\"Problem: {data['problem']}\\nCode: \n{data['code']}\\nFailures: {data['failures']}\\nWhat should I fix?\"\n        response = call_llm(prompt)\n        return yaml.safe_load(response)\n    def post(self, shared, prep_res, fixes):\n        if \"test_cases\" in fixes:\n            # Update specific test cases\n            for index, new_test in fixes[\"test_cases\"].items():\n                shared[\"test_cases\"][int(index)-1] = new_test\n        if \"function_code\" in fixes:\n            shared[\"function_code\"] = fixes[\"function_code\"]\n        shared[\"iteration_count\"] = shared.get(\"iteration_count\", 0) +\n        print(\"Applied fixes\")\nConnecting Everything Together\ndef create_code_generator_flow():\n    # Create workers\n    generate_tests = GenerateTestCases()\n    implement = ImplementFunction()\n    run_tests = RunTests()\n    revise = Revise()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator12/15\n\nThe magic happens in the connections: normal flow goes generate → implement →\ntest. But if tests fail, we go to the reviewer, who fixes things and sends us back to\ntesting.\nWhy This Works: Each worker is laser-focused on one job. The intelligence emerg\nfrom their coordination - like a jazz band where everyone knows their part but can\nimprovise together!\nAnd there you have it! You've journeyed from staring at a coding problem to build\nan AI that generates tests, writes code, and even debugs its own mistakes. We peek\nunder the hood to see how problems get understood (test generation), solved (smar\nimplementation), tested (batch execution), and improved (intelligent revision), all i\nsmooth, iterative loop.\nHopefully, this tutorial has shown you that building intelligent coding assistants\ndoesn't have to feel like rocket science. With a friendly toolkit like PocketFlow,\ncomplex AI workflows become way more manageable. PocketFlow is like your hel\nconductor, letting you focus on the fun part – what each piece of your AI system\nshould do – instead of getting tangled in the tricky coordination. It's all about brea\nbig ideas into small, focused Nodes and letting the Flow make sure they all work\ntogether intelligently.\nNow, it's your turn to grab the keyboard and get creative! We really encourage you\nexplore the PocketFlow AI Code Generator Cookbook we've built together. Play\naround with it, maybe try \"Reverse Linked List\" or \"Valid Parentheses\" and watch\n    # Connect the assembly line\n    generate_tests >> implement >> run_tests\n    run_tests - \"failure\" >> revise >> run_tests\n    return Flow(start=generate_tests)\n5. Conclusion: Code Smarter, Not Harder!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator13/15\n\nit tackles different problems. What if you made the test generator more creative, o\nadded performance benchmarking? What other coding challenges can you automa\nThe world of AI-assisted development is evolving rapidly, and with tools like\nPocketFlow, you're all set to jump in and be a part of it. Go on, give your next codi\nproject an AI brain – we can't wait to see what intelligent tools you build!\nReady to explore more or need some help? You can dive deeper by checking out the ma\nPocketFlow repository on GitHub for the core framework, other neat examples, and all \nlatest updates. The complete code for the AI code generator we discussed is right in th\npocketflow-code-generator directory within the PocketFlow cookbook.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n14 Likes∙3 Restacks\nDiscussion about this post\nPreviousNext\nWrite a comment...\nMay 29\nLiked by Zachary Huang\nFranco\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator14/15\n\n3 more comments...\n1 reply by Zachary Huang\nWhat a great tutorial! This is very interesting. But is it really useful in corporate and multidisc\nenvironments? As a programmer, I don't see any way to do something that first indexes an e\nmonstrous project, such as a real-life application for an international client, and then, knowin\ncontext of the entire project, identifies styles and patterns used by the team, as well as func\nand variables used in the project, such as utility functions created by the team. That is, the a\ncan create a function, but if a function has already been created for that case, use it; don't c\nnew one yourself. Also, refactoring legacy code or parts of the code without affecting or cor\nthe integration branch or Git workflow for your other colleagues is impossible. Testing every\nwell and generating quality, production-ready code without duplication and without creating\nconflicts between branches is something that is currently impossible.\nLIKE (1)REPLY\nMay 27\nLiked by Zachary Huang\n1 reply by Zachary Huang\nThank you for sharing this amazing PocketFlow tutorial! The intelligent code generator desc\nthe article is truly impressive, especially its implementation and application in the Python\nenvironment. However, I'm currently working primarily with Java for my development project\ncurious to know: Are there any plans for a PocketFlow-Java tutorial in the future? If so, I'd be\nexcited to learn how to apply similar intelligent workflows to my Java projects, which would\nsignificantly boost my development efficiency!\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild Your Own AI Code Generator From Scratch — A PocketFlow Tutorial!\nhttps://pocketflow.substack.com/p/build-your-own-ai-code-generator15/15"
  },
  {
    "filename": "PocketBlog250602.pdf",
    "title": "Build an LLM Web App in Python from Scratch",
    "date": "2025-06-02",
    "content": "\n\nBuild an LLM Web App in Python from Scratch\nPart 1 (Local CLI)\nJUN 02, 2025\n1\nEver thought about sprinkling some AI magic into your web app? This is Part 1 of ou\njourney from a basic command-line tool to a full-blown AI web app. Today, we're bu\na \"Human-in-the-Loop\" (HITL) chatbot. Think of it as an AI that politely asks for yo\n\"OK\" before it says anything. We'll use a tiny, super-simple tool called PocketFlow – \njust 100 lines of code!\nAdding AI (especially those smart Large Language Models or LLMs) to web apps\nmake them super powerful. Imagine smart chatbots, instant content creation, or \ncoding help. But hold on, it's not just \"plug and play.\" You'll bump into question\nZACHARY HUANG\n20\nSo, You Want to Add AI to Your Web App?\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from1/19\n\nWhere does the AI brain actually live? In the user's browser? On your server\nHow do you handle AI tasks that need multiple steps?\nHow can users tell the AI what to do or give feedback?\nWhat's the deal with remembering conversation history?\nMost importantly: How do you stop the AI from saying something totally we\nwrong?\nThis tutorial series is your guide to building LLM web apps in Python, and we'll \nthese questions head-on! Here's our 4-part adventure:\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nPart 1 (That's Today!): We'll build a basic Human-in-the-Loop (HITL) chatbo\nruns in your computer's command line. We'll use PocketFlow to nail down th\ncore logic, no fancy UI to distract us.\nPart 2: Let's get this HITL bot on the web! We'll build a user interface using\nStreamlit (or maybe Flask), and learn how to manage user interactions smoo\nPart 3: Time for real-time action! We'll upgrade our web app with WebSocke\n(using FastAPI) for instant messages and a slicker chat feel.\nPart 4: What about AI tasks that take a while? We'll set up background\nprocessing and use Server-Sent Events (SSE) with FastAPI. This lets us show\nusers live progress updates, making our app feel truly pro.\nTo make this journey smooth, we'll use PocketFlow. It's not just for simple AI ca\nPocketFlow helps you build complex AI workflows that you can actually control.\nbecause it's so small (seriously, just 100 lines for the core framework), you'll alway\nknow what's going on. No black boxes!\nThe secret sauce to control and quality? A pattern called Human-in-the-Loop (H\nWith PocketFlow, HITL is easy. It means your AI is like a helpful assistant: it dra\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from2/19\n\nstuff, but you (the human co-pilot) get the final say. Approve, edit, or reject – you\ncontrol before anything goes live. Total quality control, phew!\nYou can try out the code for the command-line HITL bot discussed in this part at: Pock\nCommand-Line HITL Example.\nLet's build the most basic HITL app: a chatbot where you approve every single A\nresponse. Imagine it's an AI trying to tell jokes. AI can be funny, but sometimes \njokes might be... well, not funny, or maybe even a little weird or inappropriate. T\nwhere you come in!\nThink of a tiny script. The AI suggests a joke, and you, the human, give it a thum\nor thumbs-down before it's told. That's HITL in action! If the AI suggests, \"Why\nthe chicken cross the playground? To get to the other slide!\" and you think it's a\nwinner, you say \"yes!\" If it suggests something that makes no sense, or isn't right\nyour audience, you say \"nope!\"\nYour First HITL App: The \"Are You Sure?\" Bot\nThe Basic Idea (It's Super Simple!)\nuser_topic_request = \"Tell me a joke about cats.\"\nai_suggested_joke = call_llm_for_joke(user_topic_request)\n# You get to approve!\napproval = input(f\"AI suggests: '{ai_suggested_joke}'. Tell this joke\n(y/n): \")\nif approval.lower() == 'y':\n    print(f\"To Audience: {ai_suggested_joke}\")\nelse:\n    print(\"Human said: Nope! That joke isn't hitting the mark.\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from3/19\n\nThat's the core! AI suggests a joke, human (input()) approves, then it's (maybe)\nThis simple check is crucial for joke quality and appropriateness. Everything else\nbuild is about making this core idea robust for more complex apps. Visually, it's a\nloop, especially for our joke bot:\nLet's See It Go!\nYou: Tell me a programming joke.\nAI suggests: 'Why do programmers prefer dark mode? Because light \nattracts bugs!'\nApprove? (y/n): y\nTo Audience: Why do programmers prefer dark mode? Because light attra\nbugs!\nYou: Tell me a joke about vegetables.\nAI suggests: 'Why did the tomato turn red? Because it saw the salad \ndressing! But also, all vegetables are boring.'\nApprove? (y/n): n\nHuman said: Nope! That joke isn't hitting the mark. (And the comment \nabout vegetables is a bit much!)\nRegenerating... (Imagine we have logic for this)\nAI suggests: 'What do you call a sad strawberry? A blueberry!'\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from4/19\n\nSee? The human caught that slightly off-kilter joke and the unnecessary commen\nThat's HITL making sure the AI comedian doesn't bomb too hard!\nWhen you try to build something more than a quick demo with plain Python whi\nloops and if statements, things can turn into a bowl of spaghetti code REAL qui\nThe main headaches are:\n1.  Spaghetti Code: Add features like conversation history, letting users edit\ntrying different AI prompts, and your simple loop becomes a monster of nest\nif/else blocks. It's tough to read and a nightmare to fix.\n2. 隣 Not Very Mix-and-Match: Your logic for getting input, calling the AI, ge\napproval, and sending the response all gets jumbled together. Want to test ju\npiece? Or reuse your \"AI calling\" bit in another app? Good luck untangling t\n3.  Hard to Change or Grow: Want to add a new step, like checking for bad w\nbefore the human sees it? Or offer three ways to react instead of just \"yes/no\"\nplain Python, these changes mean carefully rewiring everything, and you'll\nprobably break something.\nThese problems make it super hard to build AI workflows that are robust and rea\nreal users.\nEnter PocketFlow - Think of it as LEGO blocks for your AI workflows.\nApprove? (y/n): y\nTo Audience: What do you call a sad strawberry? A blueberry!\nWhy Just Plain Python Gets Tangled Fast\nPocketFlow: HITL Workflows, Super Simple!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from5/19\n\nTrying to build complex AI steps with plain Python is like building a giant LEGO\ncastle without instructions – you'll end up with a wobbly mess. PocketFlow is yo\nfriendly instruction manual and a set of perfectly fitting LEGO bricks. It helps yo\nbuild AI workflows in just 100 lines of actual framework code!\nImagine PocketFlow as running a little workshop:\nYou have Nodes: These are your specialist workers, each good at one job.\nYou have a Shared Store: This is like a central whiteboard where everyone sh\nnotes.\nYou have a Flow: This is the manager who tells the workers what to do and i\nwhat order.\nIn PocketFlow, each main task is a Node. A Node is like a specialist worker who'\npro at one specific thing.\nHere's what a Node looks like in PocketFlow:\nDon't worry if __init__ or self look weird; they're just Python things! The\nimportant bit is the prep -> exec -> post cycle:\n1. prep(shared): \"Hey, I'm about to start. What info do I need from the sha\nwhiteboard?\"\n2. exec(data_from_prep): \"Okay, I have my info. Now I'll do my main job!\ncalling an AI).\nThe Node Pattern: Your Specialist Workers\nclass Node:\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass\n    def post(self, shared, prep_res, exec_res): pass\n    def run(self,shared): p=self.prep(shared); e=self.exec(p); retur\nself.post(shared,p,e)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from6/19\n\n3. post(shared, prep_res, exec_res): \"Job's done! I'll write my results\nto the shared whiteboard and tell the manager (the Flow) what happened by\nreturning a simple signal (like a keyword, e.g., \"done\" or \"needs_approva\nThis is just a plain old Python dictionary (let's call it shared_store). All our No\nworkers can read from it and write to it. It's how they pass info—like the user's\nquestion, the AI's draft answer, or conversation history—to each other.\nFor a math problem, it might start like this:\nAs Nodes do their work, they'll update this shared_store.\nA Flow object is like the manager of your workshop. You tell it which Node kick\nthings off. When you run a Flow:\n1. It runs that first Node.\n2. The Node finishes and returns a signal (just a text string, like \"user_appro\nor \"try_again\").\n3. The Flow checks a little map on that Node (called successors) that says: \"I\nsignal is \"user_approves\", go to the SendResponseNode next. If it's\n\"try_again\", go back to the GenerateAINode.\"\nThe Shared Store: The Central Whiteboard (Just a\nPython Dictionary!)\nshared_store = {\n    \"number_to_process\": 0,\n    \"intermediate_result\": None,\n    \"final_answer\": None\n}\nThe Flow: The Workshop Manager\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from7/19\n\nYou build this map with simple connections:\nnode_a >> node_b: This is a shortcut. If node_a finishes and gives the u\n\"all good\" signal (PocketFlow calls this \"default\"), then node_b runs next\nnode_a - \"custom_signal\" >> node_c: This means if node_a finish\nand shouts \"custom_signal\", then node_c is up.\nThe Flow keeps this going: run a Node, get its signal, find the next Node. If it get\nsignal and can't find a next step, the flow for that path just ends. Easy!\nThis lets you make workflows that branch off in different directions based on wh\nhappens. Like a choose-your-own-adventure for your AI!\nHere's how tiny the Flow manager class actually is in PocketFlow:\nThat's it! It just needs a start_node and then it keeps running nodes and follow\ntheir signals until there's no next step defined for a signal.\nLet's build a super-tiny workflow: take a number, add 5, then multiply by 2.\nWorker 1: The Adder Node\nThis Node's job is to add 5.\nclass Flow:\n    def __init__(self, start_node): self.start_node = start_node\n    def run(self, shared_store):\n        current_node = self.start_node\n        while current_node:\n            signal = current_node.run(shared_store)\n            current_node = current_node.successors.get(signal)\nTiny Math Example: PocketFlow in Action!\nclass AddFive(Node):\n    def prep(self, shared):\n        return shared.get(\"number_to_process\", 0)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from8/19\n\n1. prep: Grabs \"number_to_process\" from shared_store.\n2. exec: Adds 5.\n3. post: Saves the new number as \"intermediate_result\" and says\n\"default\" (meaning \"continue to the next step in line\").\nWorker 2: The Multiplier Node\nThis Node's job is to multiply by 2.\n1. prep: Grabs \"intermediate_result\".\n2. exec: Multiplies by 2.\n3. post: Saves it as \"final_answer\" and says \"done\".\n    def exec(self, current_number):\n        return current_number + 5\n    def post(self, shared, prep_res, addition_result):\n        shared[\"intermediate_result\"] = addition_result\n        print(f\"AddFive Node: Added 5, result is {addition_result}\")\n        return \"default\" # Signal \"all good, continue\"\nclass MultiplyByTwo(Node):\n    def prep(self, shared):\n        return shared[\"intermediate_result\"]\n    def exec(self, current_number):\n        return current_number * 2\n    def post(self, shared, prep_res, multiplication_result):\n        shared[\"final_answer\"] = multiplication_result\n        print(f\"MultiplyByTwo Node: Multiplied, final answer is \n{multiplication_result}\")\n        return \"done\" # Signal \"all finished with this path\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from9/19\n\nConnecting the Workers (The Assembly Line):\nNow, let's tell PocketFlow how these Nodes connect.\nAnd if you run this, you'd see:\nSee? Each Node (worker) is simple. The shared_store (whiteboard) carries the\nnumber through. The Flow (manager) made sure AddFive ran, then\nMultiplyByTwo, because of the \"default\" signal. If MultiplyByTwo had ot\nsignals for different outcomes, the flow could branch off!\n# First, make our specialist worker Nodes\nadder_node = AddFive()\nmultiplier_node = MultiplyByTwo()\nadder_node >> multiplier_node\n# Create the Flow manager\nmath_flow = Flow(start_node=adder_node)\n# Let's get some data for them to work on\nshared_store_for_math = {\"number_to_process\": 10}\nprint(f\"\\nStarting math game with: {shared_store_for_math}\")\n# Run the flow!\nmath_flow.run(shared_store_for_math)\nprint(f\"Math game finished. Whiteboard looks like: \n{shared_store_for_math}\")\nStarting math game with: {'number_to_process': 10}\nAddFive Node: Added 5, result is 15\nMultiplyByTwo Node: Multiplied, final answer is 30\nMath game finished. Whiteboard looks like: {'number_to_process': 10, \n'intermediate_result': 15, 'final_answer': 30}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from10/19\n\nNow we know how PocketFlow uses Nodes, a Shared Store, and a Flow to handle steps\npass data. Let's use these exact same ideas for our HITL approval chatbot!\nAlright, enough theory! Let's get our hands dirty and build that HITL workflow w\nPocketFlow for our joke bot. This time, we'll start by thinking about what inform\nour Nodes will need to share.\nFor our interactive joke generator, the shared_store dictionary (our central\nwhiteboard) needs to keep track of a few key things as the conversation flows:\ntopic: What kind_of_joke the user wants (e.g., \"cats\", \"programming\"). Thi\nbe filled in by our first Node.\ncurrent_joke: The latest joke the AI cooked up. This will be updated by t\njoke generation Node.\ndisliked_jokes: A list of jokes about the current topic that the user alre\nsaid \"no\" to. This helps the AI avoid telling the same bad joke twice. It will b\nupdated by our feedback Node.\nuser_feedback: The user's latest decision (e.g., \"approve\" or\n\"disapprove\"). Also updated by the feedback Node.\nHere's a peek at what it might look like while the bot is running:\nBuilding Your HITL \"Approval Bot\" Workflow\nFirst, Design the Shared Store (Our Whiteboard)\nshared_store = {\n    \"topic\": \"dogs\",\n    \"current_joke\": \"What do you call a dog magician? A \nlabracadabrador!\",\n    \"disliked_jokes\": [\"Why did the dog cross the road? To get to the\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from11/19\n\nEach Node we design will read the information it needs from this shared_stor\nwrite its results back here for other Nodes to use. This way, everyone's on the sam\npage!\nWe'll use three main Nodes for our joke-making machine:\n1. GetTopicNode: Asks the user what they want a joke about.\n2. GenerateJokeNode: Cooks up a joke using the AI.\n3. GetFeedbackNode: Asks the user if the joke was a hit or a miss.\nLet's build them one by one!\nThis Node's only job is to ask the user for a joke topic.\nFirst, the prep method. Think of this as setting the table before a meal. It just cl\nup any old information from a previous joke in our shared whiteboard so we sta\nfresh for the new topic.\nbarking lot!\"],\n    \"user_feedback\": None\n}\nThe Three Core Nodes: Our Specialist Joke Crafters\n1. GetTopicNode - The Idea Catcher \nclass GetTopicNode(Node):\n    def prep(self, shared):\n        shared[\"topic\"] = None\n        shared[\"current_joke\"] = None\n        shared[\"disliked_jokes\"] = [] \n        shared[\"user_feedback\"] = None\n        return None\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from12/19\n\nNext, exec does the main work: it simply asks the user for a topic using input(\nreturns whatever they type.\nFinally, post takes the topic_input from exec, saves it to our shared whiteb\nunder the key \"topic\", prints a little message, and then returns the signal\n\"generate_joke\". This signal tells the Flow manager, \"Okay, we have a topic, \ngo to the node that generates jokes!\"\nThis Node grabs the topic (and any jokes the user didn't like about it) and tells th\nto whip up a new joke.\n    def exec(self, _prep_res): \n        return input(\"What topic shall I jest about today? \")\n    def post(self, shared, _prep_res, topic_input):\n        shared[\"topic\"] = topic_input\n        print(f\"Alright, a joke about '{topic_input}'! Coming right \nup...\")\n        return \"generate_joke\"\n2. GenerateJokeNode - The AI Comedy Chef 烙\nclass GenerateJokeNode(Node):\n    def prep(self, shared):\n        topic = shared.get(\"topic\", \"something random\")\n        disliked = shared.get(\"disliked_jokes\", [])\n        prompt = f\"Tell me a short, funny joke about: {topic}.\"\n        if disliked:\n            avoid_these = \"; \".join(disliked)\n            prompt += f\" Please try to make it different from these: \n[{avoid_these}].\"\n        return prompt\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from13/19\n\nIn prep, this Node looks at the shared whiteboard for the \"topic\" and any\n\"disliked_jokes\". It then crafts a prompt (a set of instructions) for our AI. I\nthere are disliked jokes, it cleverly tells the AI, \"Hey, avoid jokes like these ones t\nuser didn't like!\"\nThen, exec is where the AI magic would happen. We take the joke_prompt fro\nprep and send it to our call_llm function. This function would be responsible\ntalking to a real AI service (like OpenAI, Anthropic, etc.) and returning its respon\nAnd in post, we save the ai_joke to our shared whiteboard as \"current_jo\nprint it out for the user to see, and then return the signal \"get_feedback\". Th\nthe Flow manager, \"Joke's ready! Go to the node that gets the user's opinion.\"\nThis Node shows the joke and asks the user: thumbs up or thumbs down? Based \ntheir answer, it decides if we should try another joke on the same topic or if we'r\ndone.\n    def exec(self, joke_prompt):\n        return call_llm(joke_prompt)\n    def post(self, shared, _prep_res, ai_joke):\n        shared[\"current_joke\"] = ai_joke\n        print(f\"烙 AI Suggests: {ai_joke}\")\n        return \"get_feedback\"\n3. GetFeedbackNode - The Joke Judge 樂\nclass GetFeedbackNode(Node):\n    def prep(self, shared):\n        return None\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from14/19\n\nprep is super simple here. GenerateJokeNode already showed the joke, so the\nnothing to set up. We just pass None.\nexec asks the user if they liked the joke. It waits for a clear \"yes\" (or \"y\") or \"no\"\n\"n\") before moving on.\nFinally, post looks at the user_decision:\nIf it's a \"yes\", we celebrate, store \"approve\" in shared[\"user_feedbac\nand return the signal \"joke_approved\". This means we're done with this j\ntopic.\n    def exec(self, _prep_res):\n        while True: \n            decision = input(\"Did you like this joke? (yes/no): \n\").strip().lower()\n            if decision in [\"yes\", \"y\", \"no\", \"n\"]:\n                return decision \n            print(\"Hmm, I didn't catch that. Please type 'yes' or \n'no'.\")\n    def post(self, shared, _prep_res, user_decision):\n        if user_decision in [\"yes\", \"y\"]:\n            print(\" Hooray! Glad you liked it!\")\n            shared[\"user_feedback\"] = \"approve\"\n            return \"joke_approved\"\n        else: \n            print(\" Oops! My circuits must be crossed. Let me try \nagain...\")\n            shared[\"user_feedback\"] = \"disapprove\"\n            current_joke = shared.get(\"current_joke\")\n            if current_joke: \n                shared.setdefault(\"disliked_jokes\", \n[]).append(current_joke)\n            return \"regenerate_joke\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from15/19\n\nIf it's a \"no\", we apologize, store \"disapprove\", add the failed current_j\nto our shared[\"disliked_jokes\"] list (so GenerateJokeNode knows \nrepeat it), and return the signal \"regenerate_joke\". This tells the Flow\nmanager: \"Back to the joke drawing board (the GenerateJokeNode) for the\ntopic!\"\nNow we tell PocketFlow how to get from one Node to another using the signals w\njust defined, and then we'll run it.\nThis is like drawing a map for our Flow manager and then telling it to start the\njourney:\n1. We create our three Node workers.\nConnecting the Flow: Drawing the Joke Map & Runnin\nIt! \n# 1. Make our specialist Node workers\nget_topic_node = GetTopicNode()\ngenerate_joke_node = GenerateJokeNode()\nget_feedback_node = GetFeedbackNode()\n# 2. Draw the paths for the Flow manager\nget_topic_node - \"generate_joke\" >> generate_joke_node\ngenerate_joke_node - \"get_feedback\" >> get_feedback_node\nget_feedback_node - \"regenerate_joke\" >> generate_joke_node\n# 3. Let's Run Our HITL Joke Bot!\nshared = {\n    \"topic\": None, \"current_joke\": None,\n    \"disliked_jokes\": [], \"user_feedback\": None\n}\nhitl_joke_flow = Flow(start_node=get_topic_node)\nhitl_joke_flow.run(shared)\nprint(f\"\\n Joke session over! Here's what happened: {shared}\")\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from16/19\n\n2. We use the node - \"signal\" >> next_node pattern to define the path\n3. We set up our shared whiteboard.\n4. We create our Flow manager (using the Flow class we saw earlier), telling it\nkick things off with get_topic_node.\n5. We call hitl_joke_flow.run(shared). The Flow manager now takes ov\nruns the Nodes, listens for their signals, and follows the map. The shared\ndictionary gets updated live.\n6. When the flow naturally ends (because \"joke_approved\" has no next step\nrun method finishes, and we print out the final state of our whiteboard.\nAnd that's it! You've built a Human-in-the-Loop chatbot using PocketFlow. Each\nis small, understandable, and they all work together to create a flexible workflow\nwhere the human is always in control.\nYou've built a cool command-line bot where you're the boss! But most people do\nhang out in command prompts, right? They use web apps! The great news is that\nHITL logic you've built with PocketFlow is the engine that can power a web UI to\nThe Journey Ahead:\nPart 2 (Web UI): We'd take this exact HITL flow and hook it up to somethin\nStreamlit or Flask. Instead of input(), users would click buttons\n(st.button(\" Approve\")). The underlying PocketFlow logic remains\nlargely the same!\nPart 3 (Real-Time): Time for real-time action! We'll upgrade our web app wi\nWebSockets (using FastAPI) for instant messages and a slicker chat feel. Th\nHITL decision points (AI drafts, human approves) are still there.\nFrom CLI to Web App: What's Next & Key\nTakeaways\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from17/19\n\nPart 4 (Background Tasks & Progress Updates): What about AI tasks that ta\nwhile? We'll set up background processing and use Server-Sent Events (SSE\nFastAPI. This lets us show users live progress updates, making our app feel \npro. Your PocketFlow Flow is a key part of each user's session.\nIn Part 2, we'll take our HITL bot to the web using Streamlit! This means buildin\nproper user interface where users can interact with buttons and see responses. W\neven explore how such a UI could handle more than just text, like displaying ima\nmaking our AI interactions richer.\nWant to try out this exact command-line HITL bot yourself? You can find the compl\nrunnable code in the PocketFlow cookbook here: PocketFlow Command-Line HITL Ex\nGo ahead, build your own HITL apps!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n20 Likes∙1 Restack\nDiscussion about this post\nPreviousNex\nWrite a comment...\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from18/19\n\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:45 PMBuild an LLM Web App in Python from Scratch: Part 1 (Local CLI)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from19/19"
  },
  {
    "filename": "PocketBlog250605.pdf",
    "title": "Build an LLM Web App in Python from Scratch",
    "date": "2025-06-05",
    "content": "\n\nBuild an LLM Web App in Python from Scratch\nPart 2 (Streamlit & FSM)\nJUN 05, 2025\n41\nEver wanted to create your own AI-powered image generator, where you call the shot\nthe final masterpiece? That's exactly what we're building today! We'll craft an interac\nweb application that lets users generate images from text prompts and then approve o\nregenerate them – all within a user-friendly interface. We'll use PocketFlow for workfl\nmanagement, and you can check out the complete example we're building.\nZACHARY HUANG\n5\n1. Want to Build Your Own AI Art Director? Let\nDo It! \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b111/16\n\nImagine you're an artist, and you have a super-smart assistant (an AI) who can pa\nanything you describe. You tell it, \"Paint a cat and an otter on a sofa!\" The AI qu\npaints a picture. But maybe the cat looks a bit grumpy, or the otter is on the floor\ninstead of the sofa. Wouldn't it be great if you could tell the assistant, \"Make the \nlook friendlier,\" or \"Put the otter on the sofa next to the cat,\" and it would repain\nThat's where you come in as the director. You get to say \"Nope, try again!\" or\n\"Perfect, I love it!\" This back-and-forth between you and the AI is called Human\nthe-Loop (HITL), and it's exactly what we're building today.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nWe're creating a web app where you can: (1) Type what you want (like \"a robot ea\npizza on Mars\"), (2) See what the AI creates, (3) Approve it or ask for a do-over, an\nKeep the final masterpiece.\nDon't worry – we're keeping it simple with just a few Python tools:\n Streamlit – Turns your Python code into a web app. No HTML/CSS need\n PocketFlow – Organizes our AI tasks like a recipe (we used this in Part 1)\n Finite State Machine (FSM) – Keeps track of where we are in the process\n(typing → generating → reviewing → done)\nThis is part 2 of our 4-part journey of LLM web app tutorial:\nPart 1: Built the basic HITL system in the command line ✅\nPart 2 (You are here!): Making it a real web app with Streamlit \nPart 3: Adding real-time chat features\nPart 4: Handling long AI tasks in the background\nReady to turn your Python skills into a real web app? Let's dive in!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b112/16\n\nWant to see the final result? Check out the complete code example we're building\nSo we've picked Streamlit to build our AI Image Generator. Why is this perfect f\nPython folks who don't want to mess with HTML and CSS? Streamlit gives you a\npackage of UI components (buttons, text boxes, sliders, charts) right out of the bo\nno web design skills required! Plus, it has this brilliantly simple approach called \n\"rerun\" model.\nHere's the wild part – and it's dumb simple: Every time a user does something (c\na button, types text), Streamlit runs your entire Python script from top to bottom. A\nEvery single time.\n\"Wait, the whole script? Isn't that... slow?\" you might think. Nope! Streamlit is c\nfast at this, and it actually makes everything simpler. Think of it like a chef who m\nyour entire meal fresh every time you ask for extra salt – except this chef works a\nlightning speed.\nWhy this \"rerun everything\" approach rocks:\nFeels natural: You write normal Python code, step by step\nNo complicated UI updates: Streamlit automatically redraws everything bas\nyour latest script run\nEasy to understand: Your code flows from top to bottom, just like you'd expe\n2. Streamlit 101: A Web App in a Single Python\nFile!\nStreamlit's Big Idea: Just Rerun It! \nYour First Streamlit App: \"Hello, Clicks!\" \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b113/16\n\nLet's see this in action with a simple click counter. Create a file called\nhello_clicks.py:\nRun it with: streamlit run hello_clicks.py\nLet's follow what happens when you click the button for the first time, like steps\ndance:\nimport streamlit as st\nst.title(\"Hello, Clicks!\")\n# Think of st.session_state as Streamlit's memory notebook\nif 'click_count' not in st.session_state:\n    st.session_state.click_count = 0\nif st.button(\"Click Me!\"):\n    st.session_state.click_count += 1\nst.write(f\"Button has been clicked: {st.session_state.click_count} \ntimes\")\nWhat Happens When You Click? (The Rerun Dance!)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b114/16\n\nFirst Time: Setting the Stage (Grey Box):\n1. You open the app in your Web Page (Browser)\n2. The Python Script (hello_clicks.py – our play) runs for the very first tim\n3. It looks at the SessionState (our whiteboard) and sees 'click_count' isn't\n4. So, it writes st.session_state.click_count = 0 on the whiteboard\n5. The script then tells the Web Page to show the button and the text \"Count: 0\nUser Clicks Button:\n1. The User clicks the \"Click Me!\" button on the web page\nButton Click: Perform the Play Again! (Blue Box):\n1. Streamlit sees the click and tells the Script (the play) to run all over again, fro\nthe first line to the last\n2. This time, when the script checks the SessionState (whiteboard), it finds\n'click_count' (its value is 0)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b115/16\n\n3. The line if st.button(\"Click Me!\"): is true (because this specific butt\nclick is what caused the rerun). So, the script updates\nst.session_state.click_count to 1 (0 + 1)\n4. The script finishes, and the Web Page shows the updated UI with \"Count: 1\nEvery time you click again, the steps in the \"Button Click Rerun\" (blue box) repea\nThe st.session_state.click_count keeps going up because SessionState\nwhiteboard) remembers its value between each rerun of the play.\nSince your script reruns from scratch each time, regular Python variables would \neverything. That's where st.session_state comes in – it's like a personal not\nthat Streamlit gives each user to remember important stuff.\nWhat goes in this memory bank? Anything your app needs to remember: user inp\ncalculation results, which screen you're on, and for our image generator – the use\nprompt, the generated image, and where we are in the process.\nConnecting to Part 1: Remember the shared_data dictionary from our comma\nline app? st.session_state is exactly that, but for web apps. Instead of passi\ndata between PocketFlow nodes in an in-mem dictionary, we'll store it in\nst.session_state.\nNow that you get how Streamlit works, let's plan out our image generation workflow\nTime to plan our masterpiece! Before we start clicking buttons and typing promp\nlet's map out what our AI Image Generator actually needs to do. Think of this lik\nst.session_state: Your App's Memory Bank 易\n3. Planning Our AI Image Generator (The\nPocketFlow Blueprint)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b116/16\n\nsketching before you paint – we want to get the big picture right first.\nWe'll use PocketFlow to organize our workflow. Remember from Part 1? It's our \ntool for connecting different steps together in a logical sequence.\nOur app has a simple but powerful flow: (1) User types what they want, (2) AI gen\nan image, (3) User reviews it and decides if it's good, and (4) Either keep it or try a\nThat's it! Here's how it looks:\nIn PocketFlow, each step is a \"Node\" – think of them as LEGO blocks that do spe\njobs. Every Node has three parts:\n prep – Grabs what it needs from st.session_state (our memory bank)\n⚡ exec – Does the actual work (like calling the AI or showing a button)\n post – Saves results back to st.session_state and signals what's next\nThe Basic Journey: From Idea to Image\nPocketFlow Nodes: The Building Blocks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b117/16\n\nLet's see these in action:\nNode 1: Getting the User's Idea\nclass GetPromptNode(Node):\n    def exec(self, prep_res):\n        prompt = input(\"What do you want to see?\")\n        return prompt\n    def post(self, shared, prep_res, exec_res_prompt):\n        shared[\"task_input\"] = exec_res_prompt  # Save to memory\n        return \"prompt_ready\"  # Signal: we're ready for the next ste\nNode 2: AI Creates the Magic\nclass GenerateImageNode(Node):\n    def prep(self, shared):\n        return shared.get(\"task_input\")  # Get the prompt from memory\n    def exec(self, prep_res_prompt):\n        image_data = generate_image(prep_res_prompt)\n        return image_data\n    def post(self, shared, prep_res_prompt, exec_res_image_data):\n        shared[\"generated_image\"] = exec_res_image_data  # Save image\n        return \"image_generated\"  # Signal: image is ready!\nNode 3: User Reviews the Result\nclass ReviewImageNode(Node):\n    def prep(self, shared):\n        display(shared[\"generated_image\"])\n    def exec(self, prep_res):\n        choice = input(\"Approve (a) or Regenerate (r)?\")\n        return choice\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b118/16\n\nPocketFlow makes connecting these steps super clean:\n    def post(self, shared, prep_res, exec_res_choice):\n        if exec_res_choice == 'a':\n            shared[\"final_result\"] = shared[\"generated_image\"]\n            return \"approved\"\n        else:\n            return \"regenerate\"  # Try again!\nNode 4: Celebrating the Final Result\nclass ShowFinalNode(Node):\n    def prep(self, shared):\n        display(shared[\"generated_image\"])\n    def exec(self, prep_res):\n        choice = input(\"Start Over (s)?\")\n        return choice\n    def post(self, shared, prep_res, exec_res_choice):\n        if exec_res_choice == 's':\n            # Clear memory for fresh start\n            for key in [\"task_input\", \"generated_image\", \n\"final_result\"]:\n                shared.pop(key, None)\n            return \"start_over\"\nConnecting the Dots\ndef create_image_generator_flow():\n    # Create our building blocks\n    get_prompt = GetPromptNode()\n    generate_image = GenerateImageNode()\n    review_image = ReviewImageNode()\n    show_final = ShowFinalNode()\n    # Connect them with signals\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b119/16\n\nHere's the thing: command-line apps can pause and wait with input(\"What's\nnext?\"). Web apps can't do that! A web server needs to stay responsive for all u\nnot freeze while waiting for one person to click a button.\nThat's where we need a different approach – and that's exactly what we'll solve with F\nState Machines in the next section!\nRemember the challenge we just hit? Command-line apps can pause and wait wi\ninput(), but web apps need to stay responsive. That's where Finite State Mach\n(FSMs) come to the rescue!\nThink of an FSM like a roadmap for your app. Instead of getting lost wondering\n\"where am I in the process?\", your app always knows exactly which \"room\" it's in\nwhat should happen next.\nYou can see the complete working example at: PocketFlow Streamlit FSM Example.\nAn FSM is just a fancy way to organize your app into different \"modes\" or \"scree\n    get_prompt     - \"prompt_ready\"    >> generate_image\n    generate_image - \"image_generated\" >> review_image\n    review_image   - \"approved\"        >> show_final\n    review_image   - \"regenerate\"      >> generate_image  # Loop bac\n    show_final     - \"start_over\"      >> get_prompt      # Start fre\n    return Flow(start_node=get_prompt)\nThe Web App Challenge: No More input()\n4. FSM to the Rescue: Managing Interactive W\nStates\nWhat's a Finite State Machine? 樂\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1110/16\n\n States – Different rooms your app can be in:\ninitial_input: \"Hey, tell me what you want to see!\"\nuser_feedback: \"Here's your image. Like it or want me to try again?\"\nfinal: \"Awesome! Here's your approved masterpiece!\"\n Transitions – How you move between rooms:\nUser clicks \"Generate\" → move from initial_input to user_feedback\nUser clicks \"Approve\" → move from user_feedback to final\nUser clicks \"Start Over\" → move from final back to initial_input\nHere's how our image generator flows between states:\nVisualizing Our App's States\nHow FSM + Streamlit + PocketFlow Work Together\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1111/16\n\nHere's the beautiful part: st.session_state becomes our master control cent\ntracks both which state we're in AND all our PocketFlow data.\nThen we use simple if/elif blocks to show different screens based on the curr\nstate:\n# Initialize our app's memory\nif 'state' not in st.session_state:\n    st.session_state.state = \"initial_input\"  # Start here\n    st.session_state.task_input = \"\"\n    st.session_state.generated_image = \"\"\n    st.session_state.final_result = \"\"\nThe Magic: State-Based UI\n# State 1: Getting user input\nif st.session_state.state == \"initial_input\":\n    st.header(\" What do you want to see?\")\n    prompt = st.text_area(\"Describe your image:\")\n    if st.button(\"Generate Image\"):\n        st.session_state.task_input = prompt\n        # Run PocketFlow node\n        image_node = GenerateImageNode()\n        image_node.run(st.session_state)\n        # Move to next state\n        st.session_state.state = \"user_feedback\"\n        st.rerun()\n# State 2: User reviews the image\nelif st.session_state.state == \"user_feedback\":\n    st.header(\" Here's your image!\")\n    st.image(st.session_state.generated_image)\n    col1, col2 = st.columns(2)\n    with col1:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1112/16\n\n No More Confusion: Your app always knows exactly where it is and what\nshould happen next.\n Clean Code: Each state handles its own UI and logic – no messy spaghett\ncode!\n Streamlit Friendly: Works perfectly with Streamlit's rerun model.\n PocketFlow Integration: Nodes run smoothly within state transitions.\n User-Friendly: Each state shows exactly what the user needs to see and d\n        if st.button(\" Approve\"):\n            st.session_state.final_result = \nst.session_state.generated_image\n            st.session_state.state = \"final\"\n            st.rerun()\n    with col2:\n        if st.button(\" Try Again\"):\n            # Run PocketFlow node again\n            image_node = GenerateImageNode()\n            image_node.run(st.session_state)\n            # Stay in same state, just refresh\n            st.rerun()\n# State 3: Show final approved image\nelif st.session_state.state == \"final\":\n    st.header(\" Your Masterpiece!\")\n    st.success(\"Image approved!\")\n    st.image(st.session_state.final_result)\n    if st.button(\" Start Over\"):\n        # Reset everything\n        st.session_state.task_input = \"\"\n        st.session_state.generated_image = \"\"\n        st.session_state.final_result = \"\"\n        st.session_state.state = \"initial_input\"\n        st.rerun()\nThe Power of This Approach\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1113/16\n\nThis FSM approach transforms our PocketFlow workflow from a linear comman\nscript into an interactive web experience. Users can bounce between states natur\nand your code stays organized and predictable.\nBoom! We just built a fully interactive AI Image Generator web app. Look what w\nachieved: (1) Streamlit handles the UI magic, (2) FSM keeps our app states organi\n(3) PocketFlow manages our AI workflow, and (4) Users get a smooth, intuitive\nexperience.\nWhat we learned:\nFSMs make interactive web apps way easier to manage\nst.session_state is perfect for both FSM states and PocketFlow data\nStreamlit + FSM + PocketFlow = a powerful combo for AI apps\nOur journey so far:\nPart 1: Built HITL logic with PocketFlow (command line) ✅\nPart 2 (This part!): Created an interactive web app with Streamlit + FSM ✅\nPart 3 (Coming up!): Real-time features with FastAPI & WebSockets\nPart 4: Background processing and progress updates\nReady to add real-time superpowers to your AI apps? Part 3 will show you how\nFastAPI and WebSockets can create instant, live interactions – think real-time ch\nwith AI or live image generation updates!\nWant to try this out yourself? You can find the complete, runnable code in the PocketF\ncookbook here: PocketFlow Streamlit FSM Example\n5. Mission Accomplished! What's Next? \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1114/16\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n5 Likes∙1 Restack\nDiscussion about this post\n2 more comments...\nPreviousNex\nWrite a comment...\nJun 8\nLiked by Zachary Huang\nSanchit\nReally great series happy to have found this substack thank you!\nLIKE (1)REPLY\nJun 6\nLiked by Zachary Huang\n1 reply by Zachary Huang\nramon betancourt\nOk nice and will this work for interactive video generation too?\nLIKE (1)REPLY\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1115/16\n\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 2 (Streamlit & FSM)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b1116/16"
  },
  {
    "filename": "PocketBlog250608.pdf",
    "title": "Build an LLM Web App in Python from Scratch:",
    "date": "2025-06-08",
    "content": "\n\nBuild an LLM Web App in Python from Scratch:\nPart 3 (FastAPI & WebSockets)\nJUN 08, 2025\n1S\nEver watched ChatGPT type back to you word by word, like it's actually thinking out l\nThat's streaming AI in action, and it makes web apps feel incredibly alive! Today, we'r\nbuilding exactly that: a real-time AI chatbot web app where responses flow in instantly\nmore staring at loading spinners! We'll use FastAPI for lightning-fast backends,\nWebSockets for live chat magic, and PocketFlow to keep things organized. Ready to ma\nyour web app feel like a real conversation? You can find the complete code for this par\nthe FastAPI WebSocket Chat Cookbook.\nZACHARY HUANG\n5\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b331/12\n\nPicture this: You ask an AI a question, then... you wait. And wait. Finally, BOOM \nwall of text appears all at once. Feels clunky, right?\nNow imagine this instead: You ask your question, and the AI starts \"typing\" back\nimmediately – word by word, just like texting with a friend. That's the magic of\nstreaming for AI web apps.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nWhy streaming rocks: It feels lightning fast, keeps users engaged, and creates nat\nconversation flow. No more \"is this thing broken?\" moments!\nWe're creating a live AI chatbot web app that streams responses in real-time. You\ntype a message, and watch the AI respond word by word, just like the pros do it.\nOur toolkit:\n FastAPI – Blazing fast Python web framework\n WebSockets – The secret sauce for live, two-way chat\n PocketFlow – Our LLM framework in 100 lines\nQuick catch-up on our series:\nPart 1: Built command-line AI tools ✅\nPart 2: Created interactive web apps with Streamlit ✅\nPart 3 (You are here!): Real-time streaming web apps \nPart 4 (Coming next!): Background tasks for heavy AI work\nWant to see streaming in action without the web complexity first? Check out our\nsimpler guide: \"Streaming LLM Responses — Tutorial For Dummies\".\n1. Why Your AI Web App Should Stream (It's a\nGame Changer!) \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b332/12\n\nReady to make your AI web app feel like magic? Let's dive in!\nTo build our streaming chatbot, we need two key pieces: FastAPI for a blazing-fas\nbackend and WebSockets for live, two-way chat.\nFastAPI is like the sports car of Python web frameworks – fast, modern, and asyn\nready. Perfect for AI apps that need to handle multiple conversations at once.\nMost web apps work like old-school mail: Browser sends request → Server process\nSends back response → Done. Here's a basic FastAPI example:\nWhat's happening here?\napp = FastAPI() – Creates your web server\n@app.get(\"/hello\") – Says \"when someone visits /hello, run the functi\nbelow\"\nasync def say_hello() – The function that handles the request\nreturn {\"greeting\": \"Hi there!\"} – Sends back JSON data to the\nbrowser\n2. FastAPI + WebSockets = Real-Time Magic ⚡\nFastAPI: Your Speed Demon Backend\nfrom fastapi import FastAPI\napp = FastAPI()\n@app.get(\"/hello\")\nasync def say_hello():\n    return {\"greeting\": \"Hi there!\"}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b333/12\n\nWhen you visit http://localhost:8000/hello, you'll see {\"greeting\": \"\nthere!\"} in your browser!\nYour First FastAPI App Flow:\nSimple enough, but for chatbots we need something more interactive...\nWebSockets turn your web app into a live phone conversation. Instead of sending\nmessages back and forth, you open a connection that stays live for instant back-an\nforth chat.\nHere's a simple echo server that repeats whatever you say:\nWebSockets: Live Chat Superpowers\nfrom fastapi import FastAPI, WebSocket\napp = FastAPI()\n@app.websocket(\"/chat\")\nasync def chat_endpoint(websocket: WebSocket):\n    await websocket.accept() # Pick up the call!\n    while True:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b334/12\n\nThe browser side is just as simple:\nWebSocket Chat Flow:\n        message = await websocket.receive_text() # Listen\n        await websocket.send_text(f\"You said: {message}\") # Reply\n<input id=\"messageInput\" placeholder=\"Say something...\"/>\n<button onclick=\"sendMessage()\">Send</button>\n<div id=\"chatLog\"></div>\n<script>\n    const ws = new WebSocket(\"ws://localhost:8000/chat\");\n    const chatLog = document.getElementById('chatLog');\n    ws.onmessage = (event) => {\n        chatLog.innerHTML += `<p>Server: ${event.data}</p>`;\n    };\n    function sendMessage() {\n        const message = document.getElementById('messageInput').value\n        ws.send(message);\n        chatLog.innerHTML += `<p>You: ${message}</p>`;\n        document.getElementById('messageInput').value = '';\n    }\n</script>\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b335/12\n\nThat's it! You now have live, real-time communication between browser and serve\nPerfect foundation for our streaming AI chatbot!\nGreat! We have live chat working. But here's the thing: calling an AI like ChatGPT\ntakes time (sometimes 3-5 seconds). If our server just sits there waiting, our whole\napp freezes. Not good!\nThe problem: Normal code is like a single-lane road. When the AI is thinking,\neverything else stops.\nThe solution: Async code is like a highway with multiple lanes. While AI is thinki\nin one lane, other users can chat in other lanes!\nRemember PocketFlow from our earlier tutorials? It helps break down complex ta\ninto simple steps. For web apps, we need the async version:\n3. Adding AI to the Mix: Why Async Matters 烙\nPocketFlow Goes Async\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b336/12\n\nAsyncNode – Each step can wait for AI without blocking others\nAsyncFlow – Manages the whole conversation workflow\nHere's the magic difference:\nOur StreamingChatNode does three things:\n1. Prep: Add user message to chat history\n2. Execute: Call AI and stream response word-by-word via WebSocket\n3. Post: Save AI's complete response to history\n# ❌ This blocks everything\ndef call_ai(message):\n    response = openai.chat.completions.create(...)  # Everyone waits!\n    return response\n# ✅ This lets others keep chatting\nasync def call_ai_async(message):\n    response = await openai.chat.completions.create(...)  # Just this \ntask waits\n    return response\nStreaming Chat Node: The Star of the Show\nclass StreamingChatNode(AsyncNode):\n    async def prep_async(self, shared):\n        # Add user message to history\n        history = shared.get(\"conversation_history\", [])\n        history.append({\"role\": \"user\", \"content\": \nshared[\"user_message\"]})\n        return history, shared[\"websocket\"]\n    async def exec_async(self, prep_result):\n        messages, websocket = prep_result\n        # Stream AI response word by word\n        full_response = \"\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b337/12\n\nThat's it! The node streams AI responses live while keeping chat history. Next, let\nsee how this all connects together!\nTime to connect all the pieces! Here's how a user message flows through our\nstreaming chatbot:\nThe Journey of a Message:\nUser sends message → FastAPI receives it → PocketFlow handles AI logic → Strea\nresponse back live!\nHere's the main FastAPI code that ties everything together:\n        async for chunk in stream_llm(messages):\n            full_response += chunk\n            await websocket.send_text(json.dumps({\"content\": chunk}))\n        return full_response\n    async def post_async(self, shared, prep_res, exec_res):\n        # Save complete AI response\n        shared[\"conversation_history\"].append({\n            \"role\": \"assistant\", \n            \"content\": exec_res\n        })\n4. Putting It All Together: The Complete\nStreaming Flow \nThe FastAPI WebSocket Handler\n@app.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket):\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b338/12\n\nWhat happens:\n1. Accept WebSocket connection\n2. Wait for user messages in a loop\n3. For each message, run our StreamingChatNode\n4. The node handles AI calling + streaming automatically!\nNote: Each WebSocket connection gets its own chat_memory dictionary with th\nconnection, latest message, and full conversation history. This lets each user have\nindependent conversations while the AI remembers context.\nOn the browser side, we need just a few lines to make streaming work:\n    await websocket.accept()\n    chat_memory = {\n        \"websocket\": websocket, \n        \"conversation_history\": []\n    }\n    try:\n        while True:\n            # Get user message\n            user_data = await websocket.receive_text()\n            message = json.loads(user_data)  # {\"content\": \"Hello!\"}\n            chat_memory[\"user_message\"] = message[\"content\"]\n            # Run our PocketFlow\n            chat_flow = create_streaming_chat_flow()\n            await chat_flow.run_async(chat_memory)\n    except WebSocketDisconnect:\n        print(\"User left the chat\")\ndef create_streaming_chat_flow():\n    return AsyncFlow(start_node=StreamingChatNode())\nFrontend: The Streaming Magic in JavaScript\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b339/12\n\nThe streaming happens in ws.onmessage – each time the server sends a text ch\nwe append it to the display. That's how you get the \"typing\" effect!\nPretty neat, right? You now have all the pieces for a real-time streaming AI chatbo\nBoom! You just built a streaming AI chatbot web app that feels like magic. No mo\nwaiting around – your AI responds word by word, just like the pros!\nWhat you crushed today:\n⚡ FastAPI + WebSockets – Live, two-way chat that never gets old\n<div id=\"aiResponse\"></div>\n<input id=\"userInput\" placeholder=\"Type your message...\"/>\n<button onclick=\"sendMessage()\">Send</button>\n<script>\nconst ws = new WebSocket(\"ws://localhost:8000/ws\");\nconst aiResponse = document.getElementById(\"aiResponse\");\n// The magic: append each chunk as it arrives\nws.onmessage = (event) => {\n    const data = JSON.parse(event.data);\n    if (data.content) {\n        aiResponse.textContent += data.content; // Stream word by word\n    }\n};\nfunction sendMessage() {\n    const input = document.getElementById(\"userInput\");\n    aiResponse.textContent = \"\"; // Clear for new response\n    ws.send(JSON.stringify({content: input.value}));\n    input.value = \"\";\n}\n</script>\n5. Mission Accomplished! You Built a Real-Tim\nAI Chatbot \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b3310/12\n\n Async PocketFlow – AI calls that don't freeze your app\n Streaming responses – Watch the AI \"type\" in real-time\nYou've officially joined the ranks of developers building modern, responsive AI we\napps. Pretty cool, right?\nWhat's next in our series:\nPart 1: Command-line AI tools ✅\nPart 2: Interactive web apps with Streamlit ✅\nPart 3 (You just finished!): Real-time streaming ✅\nPart 4 (Coming up!): Background tasks for heavy AI work\nReady for the big leagues? Part 4 will tackle those marathon AI tasks – think\ngenerating reports or complex analyses that take minutes, not seconds. We'll explo\nbackground processing and Server-Sent Events to keep users happy even during th\nheavy lifting.\nWant to try this yourself? Grab the complete code from the PocketFlow cookbook: FastA\nWebSocket Chat Example You're building some serious AI web development skills! See y\nPart 4! \nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n5 Likes∙1 Restack\nPreviousNext\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b3311/12\n\nDiscussion about this post\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:46 PMBuild an LLM Web App in Python from Scratch: Part 3 (FastAPI & WebSockets)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-b3312/12"
  },
  {
    "filename": "PocketBlog250612.pdf",
    "title": "Build an LLM Web App in Python from Scratch",
    "date": "2025-06-12",
    "content": "\n\nBuild an LLM Web App in Python from Scratch\nPart 4 (FastAPI, Background Tasks & SSE)\nJUN 12, 2025\n1\nEver asked an AI to write a whole blog post, only to stare at a loading spinner for five\nminutes, wondering if your browser crashed? We've all been there. Today, we're fixing\nWe'll build an AI web app that takes on heavy-duty tasks—like writing a full article—\nwithout freezing up. You'll see live progress updates in real-time, so you always know \nthe AI is up to. Ready to make long-running AI tasks feel fast and interactive? Let's g\nbuilding!\nImagine your new AI app is a genius content writer. You ask it to \"write an articl\nabout space exploration,\" hit enter, and... the dreaded loading spinner appears. T\nZACHARY HUANG\n8\n1. The Spinner of Doom: Why Long AI Tasks\nBreak Your App \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f1/15\n\nwhole page is frozen. You can't click anything. After a minute, your browser mig\neven give you a \"This page is unresponsive\" error. Yikes.\nThis is the classic problem with long-running tasks on the web. Standard web ap\nwork like this:\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n1. You ask for something. (e.g., \"Generate my article!\")\n2. The server works on it. (e.g., Calls the AI, which takes 2-3 minutes)\n3. You wait... and wait... (The connection is held open, your browser is stuck)\n4. Finally, you get the result. (Or a timeout error!)\nThis is a terrible user experience. Users need to know their request is being hand\nand see that progress is being made.\nOur Solution: The Smart Restaurant Analogy\nThink of it like ordering food at a restaurant:\nThe Bad Way (Standard Web Request): You order a steak. The waiter stands\nyour table, staring at you without moving, for the entire 15 minutes it takes t\ncook. Awkward, right? You can't even ask for more water.\nThe Good Way (Our Approach): You order a steak. The waiter says, \"Excelle\nchoice! I'll put that in with the chef,\" and walks away (Background Task). A \nminutes later, they bring you some bread (\"Making progress!\"). A bit later, yo\ndrink arrives (\"Almost ready!\"). You're happy and informed while the main c\nis being prepared in the background.\nThat's exactly what we're building today. Our app will:\n1. Instantly confirm the user's request.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f2/15\n\n2. Offload the heavy AI work to a background task.\n3. Stream live progress updates back to the user with Server-Sent Events (SSE)\nOur toolkit for this mission:\n FastAPI BackgroundTasks: For running the AI job without freezing th\n Server-Sent Events (SSE): A simple way to push live updates from the ser\nthe browser.\n PocketFlow: To organize our multi-step article writing process.\nLet's dive into the tools that make this magic possible.\nYou can find the complete code for the app we're building today in the PocketFlow cook\nFastAPI Background Jobs with Real-time Progress.\nTo build our responsive AI article writer, we need two key pieces of technology: o\nhandle the work behind the scenes and another to report on its progress.\nThink of BackgroundTasks as giving a job to a helper who works independent\nYou tell FastAPI, \"Hey, after you tell the user I got their request, please run this o\nfunction in the background.\"\nThe magic is that the user gets an immediate response. They don't have to wait\nthe background work to finish.\nIt's like ordering from Amazon. You get the \"Order Confirmed!\" email instantly. \nactual process of picking, packing, and shipping your item happens later, in the\n2. Our Tools for the Job: Background Tasks &\nServer-Sent Events (SSE) \nFastAPI BackgroundTasks: The \"Work in the Back\" C\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f3/15\n\nbackground.\nHere's a simple example: sending a welcome email after a user signs up.\nWhat's happening?\n1. When you send a request to /signup, FastAPI sees\nbackground_tasks.add_task(...).\n2. It immediately sends back the {\"message\": \"Thanks...\"} response. Yo\nbrowser is happy and responsive.\n3. After sending the response, FastAPI runs send_welcome_email() in the\nbackground.\nThis is perfect for our AI article generator! We'll use it to run the entire AI writin\nprocess.\nfrom fastapi import FastAPI, BackgroundTasks\napp = FastAPI()\n# This is our slow task (e.g., calling an email service)\ndef send_welcome_email(email: str):\n    import time\n    time.sleep(5) # Simulate a 5-second delay\n    print(f\"Email sent to {email}! (This prints in the server console\n@app.post(\"/signup\")\nasync def user_signup(email: str, background_tasks: BackgroundTasks)\n    # Add the slow email task to the background\n    background_tasks.add_task(send_welcome_email, email)\n    # Return a response to the user IMMEDIATELY\n    return {\"message\": f\"Thanks for signing up, {email}! Check your \ninbox soon.\"}\nServer-Sent Events (SSE): Your Live Progress Ticker\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f4/15\n\nOkay, so the work is happening in the background. But how do we tell the user w\ngoing on? That's where Server-Sent Events (SSE) come in.\nSSE is a super simple way for a server to push updates to a browser over a single,\nway connection. It's like a live news ticker: the server sends new headlines as the\nhappen, and your browser just listens.\nWhy not use WebSockets again?\nWebSockets (from Part 3) are awesome for two-way chat. But for just sending one\nprogress updates, they're a bit like using a walkie-talkie when all you need is a pa\nSSE is simpler, lighter, and designed for exactly this \"server-to-client\" push scen\nHere's how simple an SSE endpoint is in FastAPI:\nAnd on the browser side, the JavaScript is just as easy:\nimport asyncio, json\nfrom fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\napp = FastAPI()\nasync def progress_generator():\n    for i in range(1, 6):\n        # In a real app, this would be a progress update from our AI\n        yield f\"data: {json.dumps({'progress': i*20, 'step': f'Step \ndone'})}\\n\\n\"\n        await asyncio.sleep(1) # Wait 1 second\n@app.get(\"/stream-progress\")\nasync def stream_progress():\n    return StreamingResponse(progress_generator(), \nmedia_type=\"text/event-stream\")\n<div id=\"progressStatus\">Waiting for progress...</div>\n<script>\n    const progressStatus = document.getElementById('progressStatus')\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f5/15\n\nWhen you open this page, eventSource connects to our endpoint, and the\nprogressStatus div will update every second. Simple and effective!\nSo, how does our AI actually write an article? It doesn't happen in one go. We ne\ngive it a step-by-step plan, like a recipe. This is where PocketFlow helps us. It br\nthe big job of \"write an article\" into small, manageable Nodes (or steps).\nBefore we dive into the nodes, let's look at the brain of our operation: a simple Py\ndictionary. All our nodes will read from and write to this central shared data hu\nhow they pass information to each other.\nHere's what it looks like at the start of a job:\n    const eventSource = new EventSource(\"/stream-progress\"); // Conne\nto our stream!\n    eventSource.onmessage = (event) => {\n        const data = JSON.parse(event.data);\n        progressStatus.textContent = `Progress: ${data.progress}% - \n${data.step}`;\n    };\n</script>\n3. The AI's To-Do List: A PocketFlow Workflow\nThe Central Hub: Our shared Dictionary\nshared_data = {\n    \"topic\": \"The user's article topic\",\n    \"sse_queue\": None, # The \"mailbox\" for progress messages\n    \"sections\": [],    # Will be filled by the Outline node\n    \"draft\": \"\",       # Will be filled by the Content node\n    \"final_article\": \"\" # The final result!\n}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f6/15\n\nThe sse_queue is our \"mailbox.\" Each node will drop progress updates into it, \nour FastAPI server will read from it to update the user.\nThis node's only job is to create the article's structure. (We'll assume a call_ll\nfunction exists that talks to the AI).\nWhat's happening here:\nprep grabs the user's topic from the shared dictionary.\nexec takes that topic and asks the AI for an outline.\npost saves the outline for the next step and—most importantly—drops a pr\nmessage into the mailbox. This tells the frontend, \"Hey, I'm 33% done!\"\nThis node takes the outline and writes the content for each section.\nStep 1: GenerateOutline Node\nclass GenerateOutline(Node):\n    def prep(self, shared):\n        return shared[\"topic\"]\n    def exec(self, topic):\n        prompt = f\"Create 3 section titles for an article on '{topic\n        return call_llm(prompt) # e.g., \"Intro,Main Points,Conclusio\n    def post(self, shared, outline_str):\n        sections = outline_str.split(',')\n        shared[\"sections\"] = sections\n        progress = {\"step\": \"outline\", \"progress\": 33, \"data\": sectio\n        shared[\"sse_queue\"].put_nowait(progress)\nStep 2: WriteContent Node\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f7/15\n\nWhy this is cool:\nInside the exec loop, after each paragraph is written, we immediately send\nanother progress update.\nThis means the user will see the progress bar jump forward multiple times d\nthis step, making the app feel very responsive.\nThis is the final touch. It takes the combined draft and asks the AI to polish it.\nclass WriteContent(Node):\n    def prep(self, shared):\n        return shared[\"sections\"], shared[\"sse_queue\"]\n    def exec(self, prep_result):\n        sections, queue = prep_result\n        full_draft = \"\"\n        for i, section in enumerate(sections):\n            prompt = f\"Write a paragraph for the section: '{section}\n            paragraph = call_llm(prompt)\n            full_draft += f\"<h2>{section}</h2>\\n<p>{paragraph}</p>\\n\n            progress = {\"step\": \"writing\", \"progress\": 33 + ((i+1)*20\n            queue.put_nowait(progress)\n        return full_draft\n    def post(self, shared, full_draft):\n        shared[\"draft\"] = full_draft\nStep 3: ApplyStyle Node\nclass ApplyStyle(Node):\n    def prep(self, shared):\n        return shared[\"draft\"]\n    def exec(self, draft):\n        prompt = f\"Rewrite this draft in an engaging style: \n{draft[:500]}\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f8/15\n\nThe grand finale:\nThis node does the final rewrite.\nCrucially, it sends the complete message to the mailbox with progress: \nThis tells our frontend that the job is finished and the final article is ready!\nFinally, we just need to tell PocketFlow the order of our to-do list.\nThis is super readable: outline_node runs, then content_node, then\nstyle_node. This Flow object is what our FastAPI background task will ultima\nrun.\nHere is a visual summary of the entire process:\n        return call_llm(prompt)\n    def post(self, shared, final_article):\n        shared[\"final_article\"] = final_article\n        progress = {\"step\": \"complete\", \"progress\": 100, \"data\": \nfinal_article}\n        shared[\"sse_queue\"].put_nowait(progress)\nTying It All Together with a Flow\nfrom pocketflow import Flow\ndef create_article_flow():\n    outline_node = GenerateOutline()\n    content_node = WriteContent()\n    style_node = ApplyStyle()\n    # Define the sequence: outline -> write -> style\n    outline_node >> content_node >> style_node\n    return Flow(start_node=outline_node)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f9/15\n\nWith our AI's \"to-do list\" ready, let's connect it to our FastAPI backend.\nOkay, our AI has its \"to-do list\" from PocketFlow. Now, let's build the web serve\nacts as the project manager. It will take requests from users, give the work to our\nand report on the progress.\nWe'll walk through the main main.py file piece by piece.\nFirst, we need a place to keep track of all the article-writing jobs that are current\nrunning. A simple Python dictionary is perfect for this.\nThink of active_jobs as the front desk of an office. When a new job comes in,\ngive it a ticket number (job_id) and a dedicated mailbox (asyncio.Queue) for \ninternal memos.\nThis is the first thing a user interacts with. They send their article topic to our\n/start-job endpoint, which kicks off the whole process.\n4. Connecting the Dots: The FastAPI Backend\nPart 1: The Job Center\n# A dictionary to hold our active jobs\n# Key: A unique job_id (string)\n# Value: The \"mailbox\" (asyncio.Queue) for that job's messages\nactive_jobs = {}\nPart 2: Kicking Off the Job\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f10/15\n\nLet's break that down:\n1. Get a Ticket Number: job_id = str(uuid.uuid4()) creates a unique I\nthis request.\n2. Create the Mailbox: sse_queue = asyncio.Queue() creates the messa\nqueue. We then store it in our active_jobs dictionary using the job_id.\n3. Hand off the Work: background_tasks.add_task(...) is the magic. I\nFastAPI, \"Don't wait! After you send the response, start running the\nrun_article_workflow function.\"\n4. Instant Reply: The return {\"job_id\": job_id} is sent back to the use\nbrowser right away. The user's page doesn't freeze!\nThis is the function that runs behind the scenes. It's the project manager that act\nruns our PocketFlow to-do list.\n@app.post(\"/start-job\")\nasync def start_job(background_tasks: BackgroundTasks, topic: str = \nForm(...)):\n    job_id = str(uuid.uuid4())\n    # Create a new, empty mailbox for this specific job\n    sse_queue = asyncio.Queue()\n    active_jobs[job_id] = sse_queue\n    # Tell FastAPI: \"Run this function in the background\"\n    background_tasks.add_task(run_article_workflow, job_id, topic)\n    # IMMEDIATELY send a response back to the user\n    return {\"job_id\": job_id}\nPart 3: The Background Worker\ndef run_article_workflow(job_id: str, topic: str):\n    sse_queue = active_jobs[job_id]\n    shared = {\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f11/15\n\nHere's the crucial connection:\nIt gets the correct sse_queue (mailbox) for this job from our active_jobs\ndictionary.\nIt creates the shared data dictionary and puts the sse_queue inside it.\nWhen flow.run(shared) is called, our PocketFlow nodes now have acces\nthis queue and can drop their progress messages into it!\nWhile the background task is running, the user's browser connects to our\n/progress/{job_id} endpoint to listen for updates.\nThis function looks a bit complex, but it's just a loop that checks the mailbox.\n        \"topic\": topic,\n        \"sse_queue\": sse_queue, # Here's where we pass the mailbox i\n        \"sections\": [],\n        \"draft\": \"\",\n        \"final_article\": \"\"\n    }\n    flow = create_article_flow()\n    flow.run(shared) # Start the PocketFlow!\nPart 4: Streaming the Progress Updates\n@app.get(\"/progress/{job_id}\")\nasync def get_progress(job_id: str):\n    async def event_stream():\n        # First, find the right mailbox for this job\n        if job_id not in active_jobs:\n            yield 'data: {\"error\": \"Job not found\"}\\n\\n'\n            return\n        sse_queue = active_jobs[job_id]\n        while True:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f12/15\n\nThe logic is simple:\n1. event_stream is a special async generator that can send (yield) data ove\ntime.\n2. It finds the correct mailbox (sse_queue) for the job_id.\n3. The while True: loop starts.\n4. await sse_queue.get() pauses and waits until a message appears in th\nmailbox.\n5. As soon as a PocketFlow node drops a message in, this line wakes up, grabs t\nmessage, and sends it to the browser with yield.\n6. It keeps doing this until it sees the \"step\": \"complete\" message, at whi\npoint it cleans up and closes the connection.\nAnd that's the whole system! It's a clean loop: the user starts a job, a background\nworker runs it while dropping messages into a mailbox, and a streamer reads fro\nmailbox to keep the user updated.\nYou did it! You've successfully built a web app that can handle long, complex AI \nwithout breaking a sweat or frustrating your users. They get an instant response \n            # Wait for a new message to arrive in the mailbox\n            progress_msg = await sse_queue.get()\n            yield f\"data: {json.dumps(progress_msg)}\\n\\n\"\n            # If the message says \"complete\", we're done!\n            if progress_msg.get(\"step\") == \"complete\":\n                del active_jobs[job_id] # Clean up the job\n                break\n    return StreamingResponse(event_stream(), media_type=\"text/event-\nstream\")\n5. Mission Complete! Your App Now Handles t\nHeavy Lifting \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f13/15\n\nlive progress updates, making the whole experience feel smooth, interactive, and\nprofessional.\nNo more dreaded loading spinners or \"page unresponsive\" errors. Your app now \nlike a modern, intelligent assistant: it acknowledges your request, works on it\ndiligently in the background, and keeps you informed every step of the way.\nWhat you conquered today:\n✅ No More Freezing UIs: Used FastAPI's BackgroundTasks to offload h\nAI work so your app stays responsive.\n✅ Live Progress Updates: Mastered Server-Sent Events (SSE) to stream stat\nupdates from the server to the browser in real-time.\n✅ Clean, Organized Logic: Structured a complex, multi-step AI job with\nPocketFlow, keeping your AI logic separate from your web code.\n✅ Tied It All Together: Used an asyncio.Queue as a simple \"mailbox\" to\nyour background task communicate with your web server.\nThis architecture is a game-changer for building serious AI applications. You no\nhave the skills to create tools that can generate reports, analyze data, or perform \nother time-intensive task, all while keeping your users happy and engaged.\nOur \"Build an LLM Web App\" Journey is Complete!\nPart 1: Command-line AI tools ✅\nPart 2: Interactive web apps with Streamlit ✅\nPart 3: Real-time streaming chat with WebSockets ✅\nPart 4 (You just crushed it!): Background tasks for heavy AI work ✅\nReady to see it all in action? Grab the complete code, including the HTML and Pocket\nnodes, from our cookbook: FastAPI Background Jobs with Real-time Progress. You've le\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f14/15\n\nup your AI dev skills in a big way. Now go build something amazing! \nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n8 Likes∙1 Restack\nDiscussion about this post\nPreviousNex\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:47 PMBuild an LLM Web App in Python from Scratch: Part 4 (FastAPI, Background Tasks & SSE)\nhttps://pocketflow.substack.com/p/build-an-llm-web-app-in-python-from-d4f15/15"
  },
  {
    "filename": "PocketBlog250619.pdf",
    "title": "The Easiest Way to Build an AI Chatbot for You",
    "date": "2025-06-19",
    "content": "\n\nThe Easiest Way to Build an AI Chatbot for You\nWebsite (Full Dev Tutorial)\nJUN 19, 2025\n41Sh\nWant to build an AI chatbot for your website, but worried about the complexity? Are y\npicturing a maintenance nightmare of endless data updates and complex pipelines? Go\nnews. This tutorial shows you how to build a lightweight AI chatbot that learns directly\nfrom your live website. No vector databases, no manual updates—just a chatbot that w\nThe project is open-sourced on GitHub.\nSo, you want to build an AI chatbot for your website. It sounds easy enough. You c\nan API, write a clever prompt, and you're basically done, right?\nZACHARY HUANG\n12\n1. That \"Simple\" Chatbot Project... Isn't\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot1/19\n\nExcept for one tiny, soul-crushing detail: Your brand-new AI knows... nothing.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nIt has no idea what your company sells, what your return policy is, or who you are.\njust an empty brain in a box. To make it useful, you have to feed it knowledge. And\nthat's where the \"simple\" project becomes a total nightmare.\nHere’s the standard, painful process everyone seems to follow:\n1. The Scavenger Hunt. First, you go on a company-wide scavenger hunt, diggin\nthrough folders and old emails to find every PDF, FAQ, and policy document y\ncan.\n2. The Data Janitor Job. Then, you become a data janitor. You write a bunch of\ntedious scripts to chop all that messy information into clean little \"chunks\" th\ncan understand.\n3. The Expensive Brain Surgery. Finally, you perform some expensive brain surg\nYou set up a complicated (and often pricey) \"vector database\" and shove all th\ndata chunks into it.\nAfter all that, you finally have a chatbot that knows things. For about a day.\nThe moment your bot goes live, it starts to rot.\nThe marketing team updates the pricing page. The engineers release a new feature\nSuddenly, your chatbot is confidently telling customers the wrong price. It's a walk\ntalking liability. You didn't build a smart AI assistant. You built a manual-syncing\nhigh-maintenance chore that you have to babysit forever.\nThe Old, Broken Way to Build a Chatbot's Brain\nAnd Now... Your Chatbot Is a Liar\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot2/19\n\nBut what if this entire approach is wrong? What if the knowledge base wasn't som\nclunky database you have to constantly update? What if... the website itself was the\nbrain? That’s the chatbot we’re building today. A bot so simple, it feels like cheatin\nThis project is powered by PocketFlow, a tiny but mighty AI framework that makes build\nthis kind of intelligent, looping agent incredibly straightforward. Forget vector databases\nmanual updates. Let's build a chatbot that just works.\nLet's throw that entire, complicated process in the trash. We are not going to hunt\ndocuments, clean up data, or set up a single database.\nInstead, our chatbot will get its information directly from the source: your live web\nThink of it like this. The old way is like printing a map once a year and hoping the\nroads don't change. Our new way is like using Google Maps on your phone—it's\nalways live, always current.\nOur chatbot works like a very fast, very focused intern. When a user asks a questio\nthe bot doesn't look up the answer in some dusty old database. Instead, it visits yo\nwebsite and starts reading, right then and there.\nLet's imagine your website has a realistic structure. A user asks a question that\nrequires information from multiple places: \"How do I get a refund for Product A?\nThe bot needs to be smart. It has to navigate the site to find all the relevant pieces\nthe puzzle. In the diagram below, the lines show all the possible links. The dashed\nshows the exact path our bot takes to find the answer.\n2. Our Solution: A \"Dumb\" Crawler That's\nActually Smart\nThe Master Plan: Let the Bot Read\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot3/19\n\nHere's a play-by-play of the bot's clever thought process:\n1. It starts on the Homepage. It sees both \"refund\" and \"Product A\" in the ques\nIt decides to find the product page first to confirm the product's details.\n2. It navigates to the \"Product A\" page. It reads the content and finds key info, \na \"30-day warranty,\" but it doesn't find the process for actually getting a refund\n3. It intelligently changes course. It realizes the refund steps aren't on the produ\npage. So, it thinks like a human would: \"Okay, I need to find the general comp\npolicies.\" It navigates back to the site's main \"Support\" section to find the offi\ninformation. It doesn't need a direct link; it understands the site's structure.\n4. It finds the final piece of the puzzle. On the Support page, it sees a link to\n\"Shipping & Returns Policy,\" reads it, and learns the exact steps to submit a\nrefund request.\nNow, it combines the \"30-day warranty\" from the product page with the \"how-to\nsteps\" from the returns policy to give a perfect, comprehensive answer.\nThe beauty of this approach is its simplicity.\nWhy This is So Much Better\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot4/19\n\nYour Knowledge is Always Fresh: You change your pricing? The bot knows\ninstantly. You update your team bio? The bot knows that too. There is no sync\nstep. There is no \"stale data.\" Ever.\nThere is Zero Maintenance: You never have to tell the bot about updates. Just\nupdate your website like you normally would, and the chatbot takes care of th\nrest.\nBut what stops it from wandering off your site and crawling the entire internet?\nSimple. We give it a leash. We provide a list of approved website domains (like\nyourwebsite.com) and tell it: \"You are only allowed to visit links on these sites.\nDon't go anywhere else.\"\nThis all sounds great, but building an agent that can make decisions and get stuck\nloop sounds complicated, right? You'd think you need a massive, heavy framework\nmanage that kind of logic.\nActually, you don't. And that’s where PocketFlow comes in.\nYou wouldn't use a bulldozer to plant a single flower. In the same way, we don't ne\nmassive, heavyweight AI framework for our straightforward crawling task. We nee\nsomething small, fast, and built for exactly this kind of job.\nThat's why we're using PocketFlow. PocketFlow is a minimalist AI framework tha\njust 100 lines of code. It has zero dependencies and zero fluff. Let's look at its thre\ncore ideas.\n3. PocketFlow: The Tiny Engine That Powers O\nBot\nThe Node: A Specialist Worker\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot5/19\n\nIn PocketFlow, each task is a Node. A Node is like a specialist worker who is a pro\none specific thing. Here’s what a Node looks like in the actual PocketFlow code:\nDon't worry if __init__ or self look weird; they're just Python things! The\nimportant bit is the prep -> exec -> post cycle:\n1. prep(shared): \"Hey, I'm about to start. What info do I need from the share\nwhiteboard?\"\n2. exec(data_from_prep): \"Okay, I have my info. Now I'll do my main job!\" \ncalling an AI).\n3. post(shared, ..., ...): \"Job's done! I'll write my results to the shared\nwhiteboard and tell the manager what to do next by returning a signal (like a\nkeyword, e.g., \"explore\" or \"answer\").\"\nThis is just a plain old Python dictionary (we'll call it shared). All our Node work\ncan read from it and write to it. It's how they pass information—like the user's\nquestion or the list of URLs to visit—to each other.\nFor our chatbot, it might look like this initially:\nclass BaseNode:\n    def __init__(self):\n        self.params, self.successors = {}, {}\n    def prep(self, shared): pass\n    def exec(self, prep_res): pass\n    def post(self, shared, prep_res, exec_res): pass\n    def run(self, shared):\n        p = self.prep(shared)\n        e = self.exec(p)\n        return self.post(shared, p, e)\nThe Shared Store: The Central Whiteboard\nshared = {\n    \"user_question\": \"How do I get a refund?\",\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot6/19\n\nAs Nodes do their work, they'll update this shared dictionary.\nA Flow object is the manager of your workshop. You tell it which Node to start wi\nand it handles the rest. When you run a Flow, it just keeps doing one thing over an\nover:\n1. Run the current Node.\n2. The Node finishes and returns a signal (just a string, like \"explore\").\n3. The Flow looks at the Node's connections to see where that signal leads, and\nmoves to the next Node.\nHere's how tiny the Flow manager class actually is in PocketFlow:\nThat's it! It starts a while loop, runs a node, gets a signal, and finds the next node\nthere's no next node for that signal, the loop ends.\nLet's build a super-tiny workflow: take a number, add 5, then multiply by 2.\n    \"urls_to_process\": [\"https://example.com\"],\n    \"visited_urls\": set(),\n    \"final_answer\": None\n}\nThe Flow: The Workshop Manager\nclass Flow(BaseNode):\n    def __init__(self, start): \n        self.start = start\n    def orch(self, shared, params=None):\n        curr = self.start\n        while curr:\n            signal = curr.run(shared)\n            curr = curr.successors.get(signal or \"default\")\nTiny Math Example: PocketFlow in Action!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot7/19\n\nWorker 1: The Adder Node\nNotice post doesn't return anything? PocketFlow automatically treats that as the signal\n\"default\".\nWorker 2: The Multiplier Node\nConnecting the Workers and Running the Flow:\nclass AddFive(BaseNode):\n    def prep(self, shared):\n        return shared.get(\"number_to_process\", 0) # Read from whiteboa\n    def exec(self, current_number):\n        return current_number + 5 # Do the work\n    def post(self, shared, prep_res, addition_result):\n        shared[\"intermediate_result\"] = addition_result # Write to \nwhiteboard\n        print(f\"AddFive Node: Added 5, result is {addition_result}\")\nclass MultiplyByTwo(BaseNode):\n    def prep(self, shared):\n        return shared[\"intermediate_result\"] # Read from whiteboard\n    def exec(self, current_number):\n        return current_number * 2 # Do the work\n    def post(self, shared, prep_res, multiplication_result):\n        shared[\"final_answer\"] = multiplication_result # Write to \nwhiteboard\n        print(f\"MultiplyByTwo Node: Multiplied, final answer is \n{multiplication_result}\")\n# Create our specialist worker Nodes\nadder_node = AddFive()\nmultiplier_node = MultiplyByTwo()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot8/19\n\nIf you run this, you get exactly what you'd expect:\nSee? Each Node is simple. The shared dictionary carries the data. The Flow man\nmakes sure AddFive runs, then MultiplyByTwo.\nNow, just swap our math workers for chatbot workers:\nAddFive becomes CrawlAndExtract.\nMultiplyByTwo becomes AgentDecision.\nAnd instead of just a \"default\" signal, AgentDecision will return\n\"explore\" to loop back or \"answer\" to move forward.\nThe pattern is exactly the same. Now that we have our blueprint, let's build the thr\n\"workers\" that make our chatbot come to life.\n# Connect them: after adder_node is done, run multiplier_node\nadder_node.add_successor(multiplier_node) \n# Create the Flow manager\nmath_flow = Flow(start=adder_node)\n# Create the whiteboard with our starting number\nshared_math_data = {\"number_to_process\": 10}\nprint(f\"Starting math game with: {shared_math_data}\")\n# Run the flow!\nmath_flow.run(shared_math_data)\nprint(f\"Math game finished. Whiteboard looks like: {shared_math_data}\"\nStarting math game with: {'number_to_process': 10}\nAddFive Node: Added 5, result is 15\nMultiplyByTwo Node: Multiplied, final answer is 30\nMath game finished. Whiteboard looks like: {'number_to_process': 10, \n'intermediate_result': 15, 'final_answer': 30}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot9/19\n\nAlright, theory's over. Let's look at the actual code that makes our chatbot's brain \nBy the end of this section, you'll understand the entire backend, from the high-lev\nworkflow down to the individual \"workers.\"\n(Note: We've simplified the code below to focus on the core ideas. For the complete,\nunabridged version, you can view the full code in the project on GitHub.)\nFirst, let's look at our workflow diagram. This is the entire brain of our operation:\nsimple loop.\nBefore we build the individual workers, let's look at the instructions that tell them\nto work together. This is our flow.py file, and it's the \"manager\" that directs the\nassembly line.\n4. Building the Brain: A Look Under the Hood\nThe Game Plan\nThe Assembly Line Instructions (flow.py)\n# From flow.py\nfrom pocketflow import Flow\nfrom nodes import CrawlAndExtract, AgentDecision, DraftAnswer\n# 1. Create an instance of each \"worker\" node\ncrawl_node = CrawlAndExtract()\nagent_node = AgentDecision()\ndraft_answer_node = DraftAnswer()\n# 2. Define the connections and signals\ncrawl_node >> agent_node                 # After crawling, always go t\nthe agent to decide.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot10/19\n\nThat's the entire orchestration logic. It's a simple, readable blueprint for our agen\nbehavior.\nNext, our workers need a central place to read and write information. This is just a\nsimple Python dictionary that holds the state of our operation.\nNow let's look at the simplified code for our three specialist nodes.\nThis BatchNode efficiently processes a list of URLs. Its job is to read a page and\nreturn its text and any new links it finds.\nagent_node - \"explore\" >> crawl_node     # If the agent says \"explore\"\nloop back to the crawler.\nagent_node - \"answer\" >> draft_answer_node # If the agent says \"answer\nmove to the writer.\n# 3. Create the final flow, telling it where to start\nsupport_bot_flow = Flow(start=crawl_node)\nThe Shared Whiteboard (shared dictionary)\nshared = {\n    \"user_question\": \"How do I get a refund?\",\n    \"urls_to_process\": [0], # A \"to-do\" list of URL indices to crawl\n    \"visited_urls\": set(),  # A set of URL indices it has already \ncrawled\n    \"url_content\": {},      # Where it stores the text from each URL\n    \"all_discovered_urls\": [\"https://example.com\"], # Master list of \nevery URL\n    \"final_answer\": None\n}\nThe Workers (nodes.py)\n1. CrawlAndExtract: The Librarian\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot11/19\n\nIn English: It crawls each page on its to-do list, stores the content, and adds any n\nunique links to the master URL list.\nThis node looks at what we've learned and decides what to do next, returning a sig\nto the Flow.\nclass CrawlAndExtract(BatchNode):\n    def prep(self, shared):\n        return shared.get(\"urls_to_process\", [])\n    def exec(self, url_index):\n        url = shared[\"all_discovered_urls\"][url_index]\n        content, new_links = crawl_webpage(url)\n        return {\"url_index\": url_index, \"content\": content, \"new_links\nnew_links}\n    def post(self, shared, prep_res, all_results):\n        for result in all_results:\n            idx = result[\"url_index\"]\n            shared[\"url_content\"][idx] = result[\"content\"]\n            shared[\"visited_urls\"].add(idx)\n            for link_url in result[\"new_links\"]:\n                if link_url not in shared[\"all_discovered_urls\"]:\n                    shared[\"all_discovered_urls\"].append(link_url)\n        shared[\"urls_to_process\"] = []\n2. AgentDecision: The Brain\nclass AgentDecision(Node):\n    def prep(self, shared):\n        knowledge = \"\\n\".join(shared[\"url_content\"].values())\n        unvisited_urls = [url for i, url in \nenumerate(shared[\"all_discovered_urls\"]) \n                          if i not in shared[\"visited_urls\"]]\n        return {\n            \"question\": shared[\"user_question\"],\n            \"knowledge\": knowledge,\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot12/19\n\nIn English: It asks the AI for a strategy (answer or explore) and returns that exa\nsignal to the Flow, which knows what to do next.\nOnce the Brain says \"answer\", this node crafts the final response.\n            \"unvisited_urls\": unvisited_urls\n        }\n    def exec(self, prepared_data):\n        prompt = f\"\"\"\n        User Question: {prepared_data['question']}\n        Knowledge I have: {prepared_data['knowledge']}\n        URLs to explore next: {prepared_data['unvisited_urls']}\n        Should I 'answer' or 'explore'? If exploring, which URLs are \nbest?\n        Respond in YAML:\n        decision: [answer/explore]\n        selected_urls: [...]\n        \"\"\"\n        response_yaml = call_llm(prompt)\n        return parse_yaml(response_yaml)\n    def post(self, shared, prep_res, decision):\n        if decision[\"decision\"] == \"explore\":\n            selected_indices = [shared[\"all_discovered_urls\"].index(ur\n                                for url in decision[\"selected_urls\"]]\n            shared[\"urls_to_process\"] = selected_indices\n            return \"explore\" # This signal matches our flow.py \ninstruction\n        else:\n            return \"answer\" # This signal also matches flow.py\n3. DraftAnswer: The Writer\nclass DraftAnswer(Node):\n    def prep(self, shared):\n        knowledge = \"\\n\".join(shared[\"url_content\"].values())\n        return { \"question\": shared[\"user_question\"], \"knowledge\": \nknowledge }\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot13/19\n\nIn English: It gathers all the text we found, gives it to the AI, and asks it to write a\nbeautiful, helpful response.\nAnd that's the core of the system. Three simple nodes, each with a clear job, passin\ndata through a simple dictionary.\nNow that the magic is revealed (and you see it's not so magical after all), let's give our cha\na pretty face so you can put it on your website.\nOkay, we have a functional AI brain that runs in the terminal. That's a great start, \nit's not very useful for your website visitors.\nLet's connect that brain to a user-friendly chat bubble. This is a classic web\ndevelopment pattern with two simple parts: a backend (our Python script) and a\nfrontend (the chat bubble on a website).\nThink of it like this:\n    def exec(self, prepared_data):\n        prompt = f\"\"\"\n        Answer this question: {prepared_data['question']}\n        Using ONLY this information:\n        {prepared_data['knowledge']}\n        \"\"\"\n        return call_llm(prompt)\n    def post(self, shared, prep_res, final_answer_from_ai):\n        shared[\"final_answer\"] = final_answer_from_ai\n5. Giving Our Bot a Face: From Terminal to\nWebsite\nThe Architecture: A Brain and a Face\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot14/19\n\n1. The Backend (The Brain): This is our Python script, server.py. Its only job\nwait for a question, run our PocketFlow logic to find the answer, and send the\nanswer back. It's the powerhouse that does all the heavy lifting.\n2. The Frontend (The Face): This is a small piece of JavaScript, chatbot.js, th\nyou add to your website. It creates the chat icon and the chat window. When a\nuser types a question, the JavaScript simply sends it to our backend for proces\nThey communicate over the network. The frontend asks a question, and the backe\nprovides the answer.\nLet's look at the minimal code that makes each part work.\nWe use a lightweight Python framework called FastAPI to create a simple web ser\nIts job is to expose a single \"endpoint\" (like a URL) that the frontend can send\nquestions to.\nHere’s the core logic in server.py:\nThe Backend: server.py\nfrom fastapi import FastAPI\nfrom flow import support_bot_flow # Our PocketFlow brain\napp = FastAPI()\n@app.post(\"/get-answer\") # An endpoint to receive questions\ndef get_answer(data: dict):\n    # 1. Get the question and URL from the frontend\n    question = data.get(\"question\")\n    start_urls = data.get(\"urls\")\n    # 2. Set up the shared dictionary for our flow\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot15/19\n\nIn English: The server waits for a POST request at /get-answer. When it gets o\nruns the same PocketFlow we built before and sends the result back.\nThis is the JavaScript that lives on your website. It listens for the user to click \"sen\nthen makes a simple web request to our Python backend.\nHere's the simplified logic from chatbot.js:\n    shared_state = {\"user_question\": question, \"all_discovered_urls\": \nstart_urls, ...}\n    # 3. Run the PocketFlow brain to find the answer\n    support_bot_flow.run(shared_state)\n    # 4. Return the final answer as a response\n    return {\"answer\": shared_state.get(\"final_answer\")}\nThe Frontend: chatbot.js\nasync function handleSendClick() {\n    const userInput = document.getElementById(\"chat-input\").value;\n    const siteUrls = [\"https://your-site.com\"]; // The URLs for the bo\nto crawl\n    // 1. Send the user's question to our Python backend\n    const response = await fetch(\"/get-answer\", {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ question: userInput, urls: siteUrls })\n    });\n    // 2. Get the answer back from the server\n    const data = await response.json();\n    const botAnswer = data.answer;\n    // 3. Display the bot's answer in the chat window\n    displayMessage(botAnswer);\n}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot16/19\n\nIn English: When the user sends a message, it packages up the question and sends\nto the /get-answer endpoint on our server. When the server responds, it display\nanswer.\nNow the process is clear:\n1. Start the Backend: First, you need to run the brain. In your terminal, run pyt\nserver.py. This starts the web server and gets it ready to answer questions.\n2. Add the Frontend to a Page: Next, you add the <script src=\"chatbot.j\n</script> tag to your website's HTML. This makes the chat bubble appear.\nTo make testing easy, the project includes a sample static/chatbot.html file \nalready has the script included. Once your server is running, just open that file in y\nbrowser to see your live, interactive chatbot in action\nLet's take a step back. We just built a fully-functional AI chatbot that can intellige\nanswer questions about any website.\nAnd we did it without touching a single vector database, writing a complex data-\nsyncing script, or worrying about our information ever going stale. Its brain is you\nlive website, which means its knowledge is always up-to-date.\nThis isn't just another chatbot. This is a better, simpler way to build one. Here’s w\nthis approach wins:\nAlways Up-to-Date. Your bot’s knowledge is never stale. When you update yo\nwebsite, you've instantly updated your chatbot. There is no sync step, ever.\nPractically Zero-Maintenance. You can finally \"set it and forget it.\" Your only\nis to keep your website current—something you were already doing anyway.\nRunning It Live\n6. Conclusion: Simple, Maintainable, and Live\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot17/19\n\nIncredibly Simple Code. Because the entire system is built on PocketFlow and\nfew straightforward Python scripts, the logic is easy to read and modify. There\nno black boxes to fight with.\nThe days of babysitting your AI are over. You now have the blueprint for a system\nthat’s not only intelligent but also practical and sustainable.\nReady to add a real-time brain to your own website?\nThe complete, open-source code for this chatbot is waiting for you on GitHub. It's powere\nthe 100-line PocketFlow framework. Dive in, experiment, and see for yourself how eas\nbuilding a truly smart chatbot can be! Get the AI Website Chatbot Code on GitHub\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n12 Likes∙1 Restack\nDiscussion about this post\nPreviousNext\nWrite a comment...\nJul 20\nGopinathan K. Munappy\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot18/19\n\n3 more comments...\nLiked by Zachary Huang\n3 replies by Zachary Huang and others\nIs it possible to use LLM other than Gemini, specifically open source LLMs?\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:48 PMThe Easiest Way to Build an AI Chatbot for Your Website (Full Dev Tutorial)\nhttps://pocketflow.substack.com/p/the-easiest-way-to-build-an-ai-chatbot19/19"
  },
  {
    "filename": "PocketBlog250701.pdf",
    "title": "LLM Agent's Arsenal: A Beginner's Guide to the",
    "date": "2025-07-01",
    "content": "\n\nLLM Agent's Arsenal: A Beginner's Guide to the\nAction Space\nJUL 01, 2025\n42Sh\nEver sent your AI agent into the \"battle\" of a complex task, only to watch it fumble wit\nblunt sword or use the wrong weapon for the fight? When an agent fails, our first instin\nto blame its \"brain\" (the LLM). But the real culprit is often the arsenal we equipped it w\n—the collection of weapons was dull, confusing, or simply not right for the job.\nIn our previous tutorial, LLM Agents are simply Graph — Tutorial For Dummies, \nrevealed that every agent is like a warrior following a simple battle plan: Assess \nStrike -> Repeat. We showed how the 'assessing' happens in a decision node\nplans the next move. Now, it's time to forge the weapons used for the Strike.\nThat 'Strike' is powered by the agent's Arsenal—the official set of weapons, tools,\nspells it can draw upon. In technical terms, this is its Action Space. This isn't just \nZACHARY HUANG\n10\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide1/13\n\nlist of functions; it is the very soul of your agent's power. A well-forged arsenal, wh\nevery blade is sharp and serves a unique purpose, is the difference between an age\nthat is defeated by the first obstacle and one that conquers any challenge.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nIn this guide, you are the master blacksmith. Using the transparent and powerful\nPocketFlow framework as your forge, we will teach you how to craft an arsenal of\nactions that will turn your agent from a clumsy squire into a legendary warrior.\nSo, we have an arsenal. But how does the agent, our digital warrior, know when to\ndraw a longsword for a close-quarters fight versus firing a bow from a distance?\nThis critical decision happens in the DecideAction node—the agent's battle\ntactician. At its core, every agent is just a simple loop that consults its tactician, w\nthen chooses an action from the arsenal. The chosen action is performed, and the\nresults are reported back to the tactician to plan the next move.\nVisually, the battle plan looks like this:\nThe Battle Tactician: How an Agent Chooses It\nWeapon\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide2/13\n\nIn this diagram:\n1. DecideAction (The Tactician): This is the brain. It analyzes the battlefield (\nuser's request and current data).\n2. The Arrows (The Commands): Based on its analysis, the tactician issues a\ncommand: search_web, write_file, or answer_question. This is the\nbranch in the graph.\n3. The Action Nodes (The Specialists): Each command goes to a specialist soldie\nwho executes that one task.\n4. The Loop Back (The Report): After the specialist completes their task, they re\nback to the tactician with new information, and the cycle begins again.\n\"But what magic happens inside that DecideAction node?\" you ask. \"How does \nactually think?\"\nThis is the most misunderstood part of agent design, and the secret is shockingly\nsimple. It's just a prompt. There's no complex algorithm, just a carefully written s\ninstructions for the LLM.\nThe tactician's \"brain\" is a prompt that looks something like this:\n### CONTEXT\nYou are a research assistant. Here is the current situation:\nQuestion: {the user's original question}\nPrevious Actions: {a log of what has been done so far}\nCurrent Information: {any data gathered from previous actions}\n### ARSENAL (Available Actions)\nHere are the weapons you can use. Choose one.\n[1] search_web\n  Description: Search the internet for up-to-date information.\n  Parameters:\n    - query (str): The specific topic to search for.\n[2] write_file\n  Description: Save text into a local file.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide3/13\n\nThat's it! The agent's entire decision-making process boils down to this: the LLM\nreads the description of the situation and the \"user manual\" for every weapon in it\narsenal, and then it picks the one that makes the most sense.\nThe quality of its choice is 100% dependent on how clearly you describe its weapo\nA sharp, well-defined arsenal in your prompt leads to a smart, effective agent. A va\nconfusing one leads to a warrior who brings a knife to a dragon fight.\nNow, let's learn how to forge these weapons, from simple daggers to god-tier mag\nspells.\nAs a master blacksmith, you wouldn't forge just one type of weapon. You need a fu\nrange, from simple daggers for quick jabs to powerful, enchanted swords for epic\nbattles. The same is true for your agent's arsenal. Actions can be designed with va\nlevels of power and complexity. Let's explore the three tiers.\nA simple dagger is a no-frills weapon. You draw it, you use it. It does one thing, an\ndoes it reliably. These are actions that require no parameters.\n  Parameters:\n    - filename (str): The name of the file to create.\n    - content (str): The text content to write into the file.\n[3] answer_question\n  Description: Provide the final answer to the user.\n  Parameters:\n    - answer (str): The complete, final answer.\n## YOUR NEXT COMMAND\nReview the CONTEXT and choose the single best ACTION from your ARSENAL\nto proceed.\nFormat your response as a YAML block.\nLevel Up Your Arsenal: The Three Tiers of\nWeapon Complexity\nLevel 1: The Simple Dagger (The \"Button\" Action)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide4/13\n\nThink of them as on/off switches or simple commands.\nIn the Forge (Code):\nAn action like request_human_help or finish_task.\nIn the Arsenal (Prompt Description):\nWhen to Use It:\nFor clear, binary decisions. When the agent needs to signal a state change, like \"I'm\nfinished,\" \"I'm stuck,\" or \"I've failed.\" They are perfect for controlling the overall \nof the battle plan.\nA bow is useless without an arrow and a target. This weapon requires input to be\neffective. These are the most common and versatile actions in an agent's arsenal—\nactions that require specific parameters to function.\nTo use these weapons, the agent must not only choose the bow but also aim it by\nproviding the correct inputs.\nIn the Forge (Code):\nAn action like search_web(query) or send_email(to, subject, body).\nIn the Arsenal (Prompt Description):\n[1] request_human_help\n  Description: If you are stuck or need clarification, use this action\nto pause and ask the human user for guidance.\nLevel 2: The Sharpshooter's Bow (The Parameterized\nTool)\n[2] search_web\n  Description: Searches the public internet for a given text string.\n  Parameters:\n    - query (str): The precise search term to look up. Must be a focus\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide5/13\n\nThe Crucial Link to Your Blacksmithing Skills:\nHow does the agent provide these parameters? This is where your skill in structur\noutput becomes critical. As we covered in our guide, Structured Output for Beginn\nyou must instruct the LLM to format its response in a structured way (like YAML \nJSON) so your program can easily parse the action and its parameters.\nWithout this skill, you've given your agent a powerful bow but no way to nock an\narrow.\nThis is the ultimate weapon: a spellbook that doesn't contain a list of spells but\nteaches the agent how to write its own. These are programmable actions where the\nagent generates code or complex instructions on the fly.\nThis gives the agent god-like flexibility to solve novel problems you never explicitl\ntrained it for.\nIn the Forge (Code):\nAn action like execute_sql(query) or run_python_code(code).\nIn the Arsenal (Prompt Description):\nstring.\n[3] send_email\n  Description: Composes and sends an email to a recipient.\n  Parameters:\n    - to (str): The email address of the recipient.\n    - subject (str): The subject line of the email.\n    - body (str): The main content of the email.\nLevel 3: The Spellbook of Creation (The Programmable\nAction)\n[4] execute_sql\n  Description: Write and run a SQL query against the company's sales \ndatabase. The database contains tables named 'customers', 'orders', an\n'products'.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide6/13\n\nThe Power and the Peril:\nA spellbook is the most powerful weapon in your arsenal, but it's also the most\ndangerous.\nPower: Your agent can solve almost any problem that can be expressed in code\nIt's no longer limited to pre-defined tools.\nPeril: It's much more likely to make a mistake (e.g., writing buggy code). More\nimportantly, it opens up massive security risks if not handled carefully (e.g.,\nexecuting malicious code like os.remove(\"important_file.txt\")). Alw\nrun such code in a secure, sandboxed environment.\nMastering these three tiers allows you to build a balanced and effective arsenal,\nequipping your agent for any challenge it might face.\nA legendary warrior doesn't just carry a random assortment of weapons. Their ars\nis carefully curated—each item is perfectly crafted, serves a distinct purpose, and i\ninstantly accessible. As the master blacksmith for your agent, you must apply the s\ndiscipline. Here are the three golden rules for forging a world-class action space.\n  Parameters:\n    - sql_query (str): A valid SQL query string to execute.\n[5] run_python_code\n  Description: Write and execute a sandboxed Python script for complex\ncalculations, data manipulation, or interacting with APIs.\n  Parameters:\n    - code (str): A string containing the Python code to run.\nForging the Perfect Arsenal: 3 Golden Rules fo\nYour Weapon Inventory\nGolden Rule #1: Engrave a Crystal-Clear User Manual\n(Clarity is King)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide7/13\n\nThe descriptions for your actions and their parameters are not notes for yourself; t\nare the user manual for the LLM. If the manual is vague, the LLM will misuse the\ntool. Be painfully, relentlessly explicit.\nA Dull Blade (Bad Description):\nThe agent sees this and thinks, \"What stuff? How? What do I provide?\" The result\nwild guess.\nA Sharpened Katana (Good Description):\nNow the agent understands its constraints. It knows the tool is for one topic and th\nquery should be short. It will correctly generate a command like\nsearch_web(query: \"2024 Nobel Prize Physics winner\"), leading to\nmuch better outcome.\nA warrior grabbing a weapon in the heat of battle can't afford to sift through a\nhundred options. They need a small, elite set of choices. Overwhelming the LLM w\ntoo many actions leads to confusion, slower decision-making (more tokens to proc\nand a higher chance of picking the wrong tool.\nsearch: searches for stuff\nsearch_web(query: str):\n  Description: Searches the public internet for up-to-date information\non a single, specific topic. Returns the top 5 text snippets.\n  Parameters:\n    - query (str): A simple and focused search query, typically 3-5 \nwords long.\nGolden Rule #2: Don't Burden Your Warrior with a Junk\nDrawer (Keep it Concise)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide8/13\n\nThe Blacksmith's Guideline: An arsenal of 10 weapons is formidable. An arsen\nof 100 is a junk drawer.\nIf your action space is growing too large, it's a sign that your tools are too granula\nInstead of creating read_json_file, read_csv_file, and read_text_file\nforge a single, more powerful weapon: read_file(filename: str). Your cod\nhandle the internal logic of parsing different file types. Keep the agent's choices cl\nand high-level.\nEvery weapon in the arsenal should have a unique purpose. If the agent has two to\nthat do similar things, it will get confused about which one to use. This is called a \nof \"orthogonality.\"\nThe Confusing Arsenal (Bad Design):\nread_csv_from_disk(file_path: str): Reads customer data from a lo\nCSV file.\nquery_database(sql: str): Queries the live customer database.\nThe agent is asked to \"find the total sales for new customers from this quarter.\" W\ntool should it use? The data might be in the CSV, or it might be in the database. T\nagent doesn't know and might make the wrong choice.\nThe Pro-Gamer Move: Simplify the Battlefield\nA true master blacksmith doesn't just forge weapons; they shape the battlefield to\ntheir advantage. Instead of giving the agent two ambiguous tools, do the work for \nbehind the scenes.\nThe Decisive Arsenal (Good Design):\nBefore the agent even starts, run a script that loads the CSV data into a temporary\ntable in the database.\nNow, the agent's arsenal is clean and unambiguous:\nGolden Rule #3: Make Every Weapon Unique (Slay\nRedundancy)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide9/13\n\nquery_database(sql: str): Queries the customer database, which conta\nall known customer data.\nThe ambiguity is gone. The agent has one, and only one, tool for retrieving custom\ndata. You've eliminated redundancy and made the agent's decision trivial,\nguaranteeing it makes the right choice every time.\nAnd so, the secrets of the forge are yours. You now understand that the true power\nan LLM agent doesn't come from some mysterious, hidden algorithm. It comes fro\nthe thoughtful, disciplined, and creative process of crafting its Action Space.\nYou've learned that agents are just warriors in a loop with branches, making decis\nbased on a prompt that serves as their battle plan. And you've seen how to stock th\narsenal for any challenge:\nWith Simple Daggers for quick, decisive commands.\nWith Sharpshooter's Bows for precise, targeted actions.\nWith reality-bending Spellbooks of Creation for ultimate flexibility.\nMost importantly, you now hold the three golden rules of the master blacksmith:\n1. Engrave a Clear Manual: Your descriptions are the agent's guide to victory.\n2. Avoid the Junk Drawer: A curated, concise arsenal is deadlier than a cluttered\none.\n3. Slay Redundancy: Make every weapon unique to ensure the agent never hesita\nThe next time you see a complex agent framework with thousands of lines of code\nwon't be intimidated. You'll know to look past the noise and ask the fundamental\nquestions: \"What's in the arsenal? How is it described? Is it sharp, concise, and\nunique?\"\nConclusion: An Agent is Only as Sharp as its\nArsenal\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide10/13\n\nArmed with this knowledge, you are no longer just a coder; you are an agent\nblacksmith. You have the power to forge not just tools, but intelligent, reliable, an\neffective digital warriors.\nReady to light the forge? Dive into the code and explore these principles in action by chec\nout PocketFlow on GitHub!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n10 Likes∙2 Restacks\nDiscussion about this post\nPreviousNext\nWrite a comment...\nJul 10\nLiked by Zachary Huang\nJesko Gao\nHi Zachary!\nYour article is truly fantastic. Although I'm Chinese and had to use translation tools to read t\nwhole page, I still found it incredibly engaging—especially the way you present agents like\ncharacters in a video game! Itʼs vivid and memorable.\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide11/13\n\n2 more comments...\n1 reply by Zachary Huang\nI have a small question about Golden Rule #2: Donʼt Burden Your Warrior with a Junk Drawe\nit Concise).\nDoes the recommended number of tools assigned to an agent/model depend on the scale o\nlocal model being used (for example, Qwen-3B vs. Qwen-8B vs. Qwen-32B)?\nIn other words, do larger models handle a bigger arsenal of tools more effectively and accur\nIn my real-world scenario, there are many different APIs and functions that need to be integ\nSo my “weapon arsenal” might easily exceed 10 tools. Would a larger model help manage th\ncomplexity better? Or is it always recommended to keep the toolset as concise as possible,\nregardlessofmodelsize?\nLIKE (1)REPLY\nJul 3\nLiked by Zachary Huang\nEveraldo Gomes\nCongrats, Zachary! Great article, great explanation, as always. Let me share some of my exp\nI never used Cursor for AI Coding, I used to go with CLINE/RooCode. But 2 weeks ago I have\nchanged to Claude Code, since their plan is the most affordable and their agent is incredible\nthe Agent researched an issue for 5 minutes in the Web and got a correct response). Also, C\ncosts only $17 and is kind of unlimited (limited unlimited - after around 2 full context window\nhave to await a couple hours to use it again). Also, I will try the new Coding Agent: \"Open Co\nEveryone says it is great and also works with Claude PRO. And I'm willing to try a new tool fr\ndagger.io team/community called \"container use\". https://github.com/dagger/container-use\nI hope this can be useful.\nBest Regards\nLIKE (1)REPLY\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide12/13\n\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agent's Arsenal: A Beginner's Guide to the Action Space\nhttps://pocketflow.substack.com/p/llm-agents-arsenal-a-beginners-guide13/13"
  },
  {
    "filename": "PocketBlog250704.pdf",
    "title": "LLM Agents & Context: A Warrior's Guide to",
    "date": "2025-07-04",
    "content": "\n\nLLM Agents & Context: A Warrior's Guide to\nNavigating the Dungeon\nJUL 04, 2025\nSh\nYour agent has a legendary sword and a powerful spellbook. But what good are weapon\nyour warrior is lost in a sprawling dungeon, unable to remember which rooms are clear\nand which hold treasure? In this guide, you'll learn the three master navigation techniq\nof agent memory—the Scrying Spell, the Grand Strategy, and the Cautious Explorer's P\nIt's time to teach our warrior not just how to fight, but how to think.\nIn our previous adventures, we learned the secret that all agents are just simple gr\nand forged our warrior in LLM Agents are simply Graph — Tutorial For Dummies\nZACHARY HUANG\n17\n1. Introduction: The Warrior Enters the Dungeo\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors1/12\n\nThen, we equipped it with a deadly arsenal of actions in LLM Agents & Their Arse\nA Beginner's Guide. But now, our warrior faces its greatest challenge yet: the\nenvironment itself.\nThe agent's battle isn't on an open field; it's in a dark, complex dungeon—a large\ncodebase, a multi-step research task, or a complex dataset. Here, the biggest dange\nisn't the monsters (the individual tasks), but getting lost, forgetting where you've b\nand losing sight of the treasure at the end.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nThis brings us to the most critical, and often botched, aspect of agent design: cont\nmanagement. Think of it as the warrior's Cognitive Backpack. In our PocketFlow\nframework, this is the simple shared dictionary that each Node reads from and w\nto. The naive approach is to stuff everything inside. Imagine loading the entire\ndungeon map, every monster's stat block, every rumor of treasure, and the history \nthe last three adventurers who failed into the warrior's backpack right at the start.\nThey'd collapse under the weight before they even took their first step.\nSmart context management isn't about giving the agent more memory; it's about g\nit the right memory at the right time. In this guide, we'll stop treating our agent's\nmemory like a junk drawer and start treating it like a high-tech utility belt. We wil\nlearn three master-level navigation techniques to keep the backpack light, the war\nagile, and the path to victory clear.\nBefore we teach our warrior new navigation tricks, let's refresh our memory of the\nbattle plan. As we learned, every agent, no matter how complex, follows a simple,\nrelentless loop: Assess -> Strike -> Repeat.\nIn the PocketFlow framework, this elegant loop is visualized as a graph:\n2. The Warrior's Battle Plan: A Quick Recap\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors2/12\n\nThe DecideNode is the warrior's brain—the battle tactician. It assesses the situat\nand chooses the next move. The ActionNodes are the specialist soldiers who car\nout a specific command. And the loop back is the report, bringing new informatio\nfrom the battlefield back to the tactician.\nBut how does the DecideNode actually think? How does it \"assess\" the situation?\nThis isn't magic; it's a carefully crafted prompt. The node's entire worldview come\nfrom the shared dictionary, which is formatted and injected directly into its brain\nThe prompt inside our DecideNode looks something like this:\n### CURRENT SITUATION\nYou are a research assistant. Here is what you know right now:\n{context_from_shared_store}\n### AVAILABLE ACTIONS\n[1] search_web(query: str)\n  Description: Search for new information online.\n[2] write_file(filename: str, content: str)\n  Description: Save information to a file.\n[3] finish_task(reason: str)\n  Description: Complete the mission because the goal is met.\n## YOUR NEXT MOVE\nBased **only** on the CURRENT SITUATION, choose the single best action\nto take next and provide the required parameters.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors3/12\n\nThe content of our shared dictionary—our cognitive backpack—is dropped direc\ninto the {context_from_shared_store} placeholder. This is the only thing t\nLLM sees. Its entire universe of knowledge for making a decision is contained wit\nthat block.\nThis reveals a critical truth: the quality of the agent's decisions is 100% dependen\nthe quality of the information in the shared store. This simple dictionary is the \nimportant part of the agent's \"brain.\" So, the central question becomes: what is th\nright way to manage it?\nImagine our warrior at the dungeon entrance. We, as the benevolent master, decid\n\"help\" by giving them everything. We cram the entire 500-page dungeon history, ev\nblueprint, every monster's family tree, and a transcript of every conversation ever \nabout the dungeon into their backpack. \"Good luck!\" we say, as the warrior stumb\nforward, unable to even lift their sword under the crushing weight.\nThey enter the first room, which has a simple pressure plate on the floor. To solve \nthey need to find the small, one-ounce stone they picked up just a moment ago. Bu\nfind it, they have to rummage through the 200-pound bag of useless junk we gave\nthem. They get distracted by a map of a different dungeon wing, start reading abou\nthe goblin king's third cousin, and forget about the pressure plate entirely. They ar\nparalyzed by information overload.\nThis is exactly what happens when you dump your entire shared history into an\nLLM's prompt on every turn. A cluttered backpack doesn't create a genius warrior\ncreates an ineffective one. Here’s why:\nDiluted Attention: LLMs have a finite attention span. When you give them a\nmassive context, the critical piece of information—the \"signal\"—gets lost in a\nof irrelevant data—the \"noise.\" The model might struggle to find the single m\nimportant fact (\"the user just asked to search for this\") when it's buried in ten\n3. The Overwhelmed Warrior: Why Dumping A\nContext Fails\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors4/12\n\npages of previous search results. This is often called the \"lost in the middle\"\nproblem, where information in the center of a large prompt is frequently igno\nSky-High Costs & Latency: Every token in your prompt costs money and\nprocessing time. A cluttered backpack slows your warrior to a crawl and empt\nyour coin purse. An agent that sends a 100,000-token context on every loop is \nonly breathtakingly expensive but also painfully slow, making any real-time\ninteraction impossible.\nIncreased Hallucinations: When an LLM is given too much loosely related\ninformation, it starts to \"cross the wires.\" It might grab a detail from an early,\nnow-irrelevant step and incorrectly apply it to the current situation. It's the\nequivalent of our warrior trying to use a recipe for a health potion to disarm a\nmagical trap—a confident but catastrophically wrong decision.\nThe takeaway is simple: a bigger context does not equal a smarter agent. Our goa\nnot to build the biggest backpack, but the most efficient one. We need to stop bein\nhoarders and start being strategists, ensuring our warrior carries only what they n\nfor the immediate fight.\nIf stuffing everything into the backpack is the path to failure, what is the path to\nvictory? The answer lies in transforming the backpack from a static, heavy burden\na dynamic, intelligent system. A master warrior doesn't carry every tool for every\npossible situation. They carry a few versatile tools that allow them to adapt to any\nsituation.\nHere are the three master techniques for forging your agent's cognitive backpack.\nThe Metaphor: Our warrior enters the dungeon with a nearly empty backpack. Ins\nof a map, they carry a magical \"scrying orb.\" When they reach a fork in the path, th\n4. Forging the Cognitive Backpack: Three\nMaster Navigation Techniques\n4.1. Technique #1: The Scrying Spell (Context On-\nDemand)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors5/12\n\ndon't guess. They hold up the orb and ask, \"What lies down the left corridor?\" The\nshows them a brief vision of the next room. They now have a small, relevant piece \ninformation. They add this \"vision\" to their mental map and then use the orb again\nscout the right corridor. They build their map piece by piece, only gathering the\ninformation they need, precisely when they need it.\nThe Pattern: This is an exploratory, on-demand context strategy. Instead of feedin\nthe agent a massive, pre-filled context, you give it the tools to build its own contex\nThe agent's primary actions are not to solve the final problem, but to ask question\nabout the environment. The shared store starts small and grows incrementally,\npopulated only by the answers to the agent's own, self-directed inquiries. It's a pul\nmodel of information gathering, not a push model.\nImagine an agent tasked with: \"Find the total revenue from our top 5 customers la\nquarter.\"\nA naive approach would be to dump the entire database schema into the initial\nprompt. The Scrying Spell approach is far more elegant:\nLoop 1: Assess the Landscape\nshared store: {\"goal\": \"Find revenue of top 5 customers l\nquarter\"}\nDecideNode thinks: \"I have no idea what tables are in the database. I nee\nlook.\"\nAction: It calls list_tables().\nUpdate shared: The list of tables (['customers', 'orders',\n'products']) is added to the shared store.\nLoop 2: Zoom in on a Clue\nshared store: Now contains the goal and the list of tables.\nDecideNode thinks: \"Okay, 'orders' and 'customers' seem relevant. I need\nknow what columns are in the 'orders' table to find revenue and dates.\"\nConcrete Example: The AI Data Analyst\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors6/12\n\nAction: It calls get_table_schema(table_name='orders').\nUpdate shared: The schema for the orders table ({'order_id': 'IN\n'customer_id': 'INT', 'order_date': 'DATE',\n'total_amount': 'DECIMAL'}) is added.\nLoop 3: Formulate the Attack\nshared store: Contains the goal, table names, and the orders schema.\nDecideNode thinks: \"Perfect. Now I have everything I need to write a pr\nSQL query to get the answer.\"\nAction: It calls execute_sql(query=\"SELECT ...\").\nNotice the difference. The context was never overwhelming. It was built intelligen\nstep-by-step, by the agent itself. We didn't give it a map; we gave it a scrying orb a\ntrusted it to find its own way.\nThe Metaphor: The warrior now faces not a dungeon, but an entire fortress. Tryin\nmap it room by room would take forever. Instead, they first send a hawk into the s\nThe hawk returns with a high-level sketch of the fortress: the barracks, the keep, a\nthe treasury (Map phase). The warrior decides to tackle the keep first. They leave th\nmain map behind and take only the detailed blueprint of the keep with them (Subtas\nExecution). After conquering the keep and taking its treasure, they return to the\nstarting point, drop off the loot, and then take only the blueprint for the treasury for t\nnext mission. Once all wings are cleared, they have all the treasure in one place\n(Reduce phase).\nThe Pattern: This is the classic divide-and-conquer strategy, perfectly suited for t\nthat are too large for a single context window. The process is:\n1. Map: A high-level planning step where the agent breaks a large problem down\ninto smaller, independent subtasks or \"chapters.\"\n4.2. Technique #2: The Grand Strategy (Map-Reduce)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors7/12\n\n2. Subtask Execution (in parallel or sequence): For each subtask, the agent is ru\nwith a hermetically sealed context. It is only given the information relevant to\nthat one subtask, completely ignorant of the others. This keeps the context sm\nand focused.\n3. Reduce: A final step where the results from all the independent subtasks are\ngathered and synthesized into a final, coherent output.\nThis is the exact strategy used in our Codebase Knowledge Builder project, which\nturns an entire GitHub repository into a friendly tutorial. Stuffing a whole codeba\ninto a prompt is impossible. Here's how the Grand Strategy makes it work:\nMap Phase: The Hawk's View\nThe IdentifyAbstractions and OrderChapters nodes act as the ha\nThey scan the file structure and code at a high level (without reading every\nline) to create a plan.\nshared store output: A list of core concepts and a recommended chapter\norder, like: [\"1. BaseNode\", \"2. Flow\", \"3. SharedMemory\"].\nSubtask Execution Phase: Conquering the Keep\nThe WriteChapters BatchNode in PocketFlow executes this phase\nperfectly. It iterates through the plan.\nFor Chapter 1 (\"BaseNode\"): Its prep method intelligently scans the\nshared['codebase'] and gathers only the code files relevant to BaseNod\nthen calls the LLM with a tiny, focused prompt: \"Write a chapter on BaseN\nusing only this specific code.\" The LLM is completely unaware of the code f\nFlow or SharedMemory, preventing confusion.\nFor Chapter 2 (\"Flow\"): The process repeats, but this time with a complete\ndifferent, isolated context containing only the code relevant to Flow.\nReduce Phase: Gathering the Loot\nConcrete Example: The AI Codebase Knowledge Builder\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors8/12\n\nThe CombineTutorial node acts as the final organizer. It takes all the\nindividually written chapter outputs from the shared store (which now\ncontains the completed text for each chapter) and assembles them into a\nsingle, polished tutorial document with a table of contents and navigation\nWithout this strategy, the task would be impossible. With it, we can conquer a fort\nof any size, one well-planned, focused assault at a time.\nThe Metaphor: Our warrior enters a room with a suspicious-looking lever. A reck\nwarrior pulls it and hopes for the best. A cautious warrior pulls it (Apply Change\nbut keeps one foot in the doorway, ready to jump back. They listen intently. Do the\nhear the satisfying click of a hidden door opening, or the terrifying rumble of a ceili\ncollapse? (Verify). If it's the rumble, they immediately let go of the lever, which\nsprings back into place (Revert Change), and they proceed to look for a differen\nsolution. They are allowed to make mistakes, as long as they can observe the\nconsequences and undo them.\nThe Pattern: This is a trial-and-error with a safety net strategy, essential for agen\nthat modify their environment, like coding agents. The flow is cyclical:\n1. Apply Change: The agent performs an action that alters the state (e.g., writes \nfile).\n2. Verify: A special node captures the consequence of that action. This isn't just t\naction's output; it's an observation of the new world state (e.g., a git diff, li\noutput, or a failing test result).\n3. Decide & Revert: This verification result is fed back to the DecideNode. The\nLLM is then prompted: \"You tried X, and the result was Y. Was this successfu\nnot, should we revert and try something else?\" If it decides to revert, a special\naction restores the previous state.\n4.3. Technique #3: The Cautious Explorer (Backtrackin\nwith Verification)\nConcrete Example: The AI Coding Agent\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors9/12\n\nImagine an agent tasked with fixing a bug in a Python file.\nLoop 1: The Attempt\nDecideNode thinks: \"Based on the bug report, I think the error is on line\nI will change x > 5 to x >= 5.\"\nAction: The write_file node modifies the Python file.\nLoop 2: The Verification\nThe post hook of the write_file node is a special verify_code func\nIt doesn't just return \"success.\" It runs the project's linter and unit tests.\nVerification Result: The linter passes, but a unit test now fails with a new\nAssertionError. This full error message is the output.\nUpdate shared: The shared store is updated with: {\"last_attempt\"\n\"Changed line 52 to x >= 5\", \"verification_log\": \"Lint\nOK. Tests: FAILED - AssertionError: Test case for x=5\nfailed.\"}\nLoop 3: The Reassessment\nThe DecideNode sees the previous attempt and the failed test.\nDecideNode thinks: \"My last change was wrong. It broke a different test\ncase. I must revert the change and try a different approach. The logic mus\nmore complex than a simple comparison.\"\nAction: It calls revert_last_change(), followed by a new write_fil\nwith a completely different solution.\nThis loop of Apply -> Verify -> Revert allows the agent to safely explore t\nsolution space without permanently breaking things. It can make hypotheses, test\nthem, and backtrack if they prove false—a much more robust and realistic way to \ncomplex problems.\n5. Conclusion: A Smart Warrior Navigates, a Fo\nMemorizes\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors10/12\n\nAnd so, the secrets of the dungeon are yours. We've moved beyond simply forging \npowerful warrior; we've now taught it how to navigate the most treacherous and\ncomplex environments. You now understand that an agent's true intelligence isn't\nmeasured by the size of its brain (the LLM) or the sharpness of its weapons (the ac\nspace), but by the wisdom of its context management.\nA cluttered, unmanaged shared store—our warrior's cognitive backpack—is a re\nfor a slow, confused, and expensive agent. But a well-managed one is the key to a\nfocused, efficient, and surprisingly clever digital warrior.\nYou've learned the three master navigation techniques, transforming you from a m\nagent blacksmith into a grand strategist:\nThe Scrying Spell (Context On-Demand): The ultimate tool for exploration,\nallowing your agent to build its own map of the unknown, piece by piece, with\never getting overwhelmed.\nThe Grand Strategy (Map-Reduce): Your weapon against overwhelming\ncomplexity, enabling your agent to conquer massive challenges like entire\ncodebases by breaking them down into small, focused, and manageable battle\nThe Cautious Explorer (Backtracking with Verification): The safety net that\nempowers your agent to make bold moves and try new things, secure in the\nknowledge that it can observe the consequences and gracefully retreat from an\ndead ends.\nThe next time you build an agent, don't just ask, \"What can it do?\" Instead, ask, \"H\nwill it think? How will it manage its focus?\" By thoughtfully designing your agent\ncognitive backpack, you are no longer just coding a workflow; you are imparting\nwisdom. You are creating a smart warrior that doesn't just memorize the map, but\nnavigates the dungeon with purpose, clarity, and skill.\nReady to forge your own intelligent navigators? Dive into the code, experiment with the\ncontext strategies, and see how a well-managed backpack can transform your agents. Ch\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors11/12\n\nout PocketFlow on GitHub and start building smarter today!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n17 Likes\nDiscussion about this post\nPreviousNext\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:49 PMLLM Agents & Context: A Warrior's Guide to Navigating the Dungeon\nhttps://pocketflow.substack.com/p/llm-agents-and-context-a-warriors12/12"
  },
  {
    "filename": "PocketBlog250729.pdf",
    "title": "LLM Agents & Prompt Engineering: A Warrior's",
    "date": "2025-07-29",
    "content": "\n\nLLM Agents & Prompt Engineering: A Warrior's\nGuide to Clear Commands\nJUL 29, 2025\n1Sh\nYou've forged a legendary warrior with the perfect arsenal and taught them to navigate\ndungeon. But what happens when your commands are as clear as mud? \"Attack the thi\nyou shout. Which thing? With what weapon? Your warrior stands confused. In this gui\nyou'll master the final art—giving crystal-clear battle commands that turn hesitation in\ndecisive action.\nPicture this: You've spent weeks creating the ultimate digital warrior. In previous\nposts, you've given them a razor-sharp sword (perfect actions). You've taught them\nZACHARY HUANG\n12\n1. Introduction: The Confused Warrior\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering1/12\n\ncarry a lightweight but complete backpack (smart context management), and they'\nstanding right in front of the treasure chest. Victory is one command away.\n\"Get the treasure!\" you command confidently.\nYour warrior looks at you. Looks at the chest. Looks back at you. Then proceeds to\nattack the chest with their sword, smashing it to pieces and destroying the treasur\ninside.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n\"What are you DOING?!\" you scream.\nThe warrior shrugs. \"You said 'get' the treasure. I thought you meant destroy the c\nto get to it. Maybe you should have said 'carefully open the chest and retrieve the\ntreasure inside.'\"\nThis is the final challenge in building effective LLM agents. You can have the mos\nsophisticated graph structure, the deadliest arsenal of tools, and the smartest cont\nmanagement—but if your commands are vague, your agent becomes a confused m\nThe good news? Prompt engineering isn't magic. It's not about finding secret\nincantations that \"unlock\" your LLM's hidden powers. It's simply the art of giving\nclear, unambiguous instructions. Think of it as the final sharpening of your blade—\nthe forging itself, but the careful honing that turns a good sword into a legendary \nIn this guide, we'll strip away the mystique and show you three simple laws that will transf\nyour prompts from confusing mumbles into crystal-clear battle commands. By the end, y\nwarrior won't just be powerful—they'll actually understand what you want them to do\n2. How Agents Work: The Battle Plan Recap\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering2/12\n\nBefore we sharpen our commands, let's quickly remind ourselves how our warrior\nactually operates. As we discovered in our previous adventures, every LLM agent—\nmatter how complex it appears—follows a devastatingly simple loop:\nAssess → Strike → Repeat\nIn the PocketFlow framework, this loop manifests as a graph:\nThe DecideNode is our warrior's brain—the battle tactician that looks at the\nsituation and chooses the next move. But here's the crucial part: how does it think\nThe answer is simpler than you might expect. The entire \"thinking\" process is just\nprompt. Here's the general structure inside any DecideNode:\nprompt = f\"\"\"\n### YOUR TASK\n{task_instruction}\n### CURRENT STATE\n{context}\n### AVAILABLE ACTIONS\n{action_space}\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering3/12\n\nThis is the prompt we're going to improve.\nNotice how this universal template has three main components:\n1. Task Instruction: What the agent is trying to accomplish\n2. Context: The current state (from the shared store we discussed)\n3. Action Space: The available tools (the arsenal we forged)\nWe've already mastered forging the perfect action space (giving our warrior the rig\nweapons) and managing context (keeping the backpack light and relevant). Now it\ntime to focus on that final piece: the task instruction—the actual commands we g\nour warrior.\nLook at it carefully. Everything the agent knows comes from these three sections. \nsince we've already perfected the action space and context management in our\nprevious guides, the quality of your agent now hinges on that task instruction—th\nspecific commands and guidelines you provide.\nFirst, let's clear the air. The term \"prompt engineering\" sounds intimidating, and t\ninternet is full of hype about finding secret phrases that \"unlock\" an LLM's true\npotential. People share \"magic prompts\" like ancient spells, promising that adding\n\"let's think step by step\" or \"you are an expert\" will transform your results.\n### YOUR NEXT MOVE\nBased on your task and current state, choose the best action.\nFormat your response as:\n```yaml\nthinking: |\n    <your reasoning>\naction: <chosen action>\nparameters: <any required parameters>\n```\"\"\"\n3. The Myth of \"Prompt Engineering\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering4/12\n\nThe reality is much simpler and, frankly, more empowering. Effective prompt\nengineering is not about tricking the LLM or finding secret incantations. It's abou\nclarity and structure.\nYour goal is simple: write an instruction manual so clear, so unambiguous, that th\nLLM can't possibly misinterpret it. It's not magic—it's just good communication.\nHere's the most important principle for any agent builder:\nThe 90/10 Rule: Spend 90% of your time designing actions and context.\nPrompting is the final 10%.\nThink of it this way:\nActions (The Arsenal): If your warrior doesn't have the right weapons, no amo\nof yelling will help\nContext (The Backpack): If your warrior is carrying 500 pounds of junk, they c\nmove effectively\nPrompts (The Commands): Only after the first two are solid should you polish\nyour instructions\nIf your agent is failing, resist the urge to immediately tweak prompts. Instead, ask\n1. Does it have the right tools for this job?\n2. Is its context clear and focused?\n3. Only then: Are my instructions clear?\nThis is why prompt engineering is the \"sharpening, not the forging.\" You can't\nsharpen a blade that doesn't exist. You can't polish a sword made of rubber. But on\nyou have a well-forged weapon and a clear battlefield, a sharp command makes all\ndifference.\nLet's learn how to sharpen that blade.\n4. The 3 Sacred Laws of Command\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering5/12\n\nNow that we understand prompt engineering is about clarity, not magic, let's dive \nthe three fundamental techniques that will transform your vague mumbles into\ncrystal-clear battle commands.\nImagine two different commanders:\nCommander A: \"Attack the fortress!\"\nCommander B: \"First, tell me your plan for attacking the fortress. Then execute it\nWhich warrior is more likely to succeed? The one who charges blindly, or the one \nthinks through their approach first?\nThis is the power of Chain of Thought (CoT). By explicitly asking your agent to ex\nits reasoning BEFORE taking action, you dramatically improve its decision quality\nlike the difference between a warrior who swings wildly and one who calculates ea\nstrike.\nBefore (No Chain of Thought):\nAfter (With Chain of Thought):\n4.1. Law #1: Demand the Battle Plan (Chain of Thought\nprompt = f\"\"\"### YOUR TASK\n{task_instruction}\n### YOUR NEXT MOVE\nChoose an action and provide parameters.\"\"\"\nprompt = f\"\"\"### YOUR TASK\n{task_instruction}\n### YOUR NEXT MOVE\nFirst, explain your step-by-step plan for completing this task.\nThen choose an action and provide parameters.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering6/12\n\nThe difference is profound. With the second prompt, your agent might think:\nWithout CoT, it might have jumped straight to searching transactions without\nproperly defining the date range. Chain of Thought forces your warrior to strateg\nbefore striking.\nPro Tip: If you're using a thinking model (like o1 or Claude with thinking mode\nyou get this for free! These models automatically think through problems step-b\nstep without explicit prompting. It's like having a warrior who's already trained\nstrategize before every move.\nYour warrior stands before two doors. You could say:\nFormat your response as:\n```yaml\nthinking: |\n    <your step-by-step reasoning process>\naction: <chosen action>\nparameters: <required parameters>\n```\"\"\"\nresponse = \"\"\"thinking: |\n    1. I need to find grocery spending for last month\n    2. First, I should identify what \"last month\" means (get current \ndate)\n    3. Then search for transactions in that date range\n    4. Filter for grocery-related merchants\n    5. Sum up the amounts\n    Starting with getting the current date...\naction: get_current_date\n...\"\"\"\n4.2. Law #2: Speak Like a General, Not a Poet (Be\nSpecific)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering7/12\n\nPoetic: \"Choose wisely, for one path leads to glory.\"\nGeneral: \"Take the left door. It leads to the armory. Avoid the right door—it's trap\nwith poison darts.\"\nWhich instruction leads to success? The specific one, every time.\nThe biggest prompt engineering mistake is using vague, open-ended language wh\nyou actually have specific requirements. Let's look at common examples:\nVague → Specific Transformations:\n❌ \"Search for relevant information\"\n✅ \"Search for peer-reviewed studies published after 2020 about renewable en\ncosts\"\n❌ \"Summarize this appropriately\"\n✅ \"Create a 3-paragraph summary with: (1) main finding, (2) methodology, (3)\nimplications\"\n❌ \"Handle errors gracefully\"\n✅ \"If a search returns no results, try broadening the query by removing\nadjectives. If it still fails, return 'No information found' and explain what was\nsearched\"\nThe Power of Constraints:\nConstraints aren't limitations—they're guideposts that lead to better results. Cons\nthese improvements:\n# Vague prompt\nprompt_vague = f\"\"\"### TASK (Vague)\nResearch the topic and provide information\"\"\"\n# Specific prompt\nprompt_specific = f\"\"\"### TASK (Specific)\nResearch electric vehicles with these constraints:\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering8/12\n\nThe specific version removes all ambiguity. Your warrior knows exactly what victo\nlooks like.\nSometimes, even the clearest words aren't enough. This is when you need to\ndemonstrate, not just describe. Think of it as the difference between explaining sw\ntechniques with words versus actually showing the movements.\nFew-shot examples are perfect when you need:\nA specific writing style\nA particular output format\nComplex patterns that are hard to describe\nWithout Examples (Frustrating):\nYour agent thinks: \"What does 'friendly' mean? How solution-focused? What tone\nWith Examples (Crystal Clear):\n- Focus on: battery technology and charging infrastructure  \n- Time period: 2022-2024 developments only\n- Sources: Prioritize industry reports and government data\n- Length: Provide 3-5 key findings, each in 1-2 sentences\n- Format: Bullet points with source citations\"\"\"\n4.3. Law #3: Show, Don't Just Tell (Few-Shot Examples\nprompt = f\"\"\"### TASK\nWrite a customer support response in our company's friendly, solution-\nfocused style\n<context and customer message here>\n...\"\"\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering9/12\n\nNotice how the examples teach the style without explicit rules:\nStart with empathy/acknowledgment\nTake immediate action (no \"we'll look into it\")\nProvide specific next steps and timelines\nOffer something extra for the inconvenience\nEnd with an open offer to help more\nWhen to Use Examples:\nWriting style: \"Match our blog voice\" → Show 2-3 actual blog excerpts\nResponse formats: \"Format like our reports\" → Show a complete sample\nTone matching: \"Professional but warm\" → Demonstrate with real examples\nEdge cases: Show how to handle tricky situations\nprompt = f\"\"\"### TASK\nWrite a customer support response following our style:\nExample 1:\nCustomer: \"My order hasn't arrived and it's been a week!\"\nResponse: \"I completely understand your frustration - a week is \ndefinitely too long to wait! Let me track that down for you right away\nI can see your order #12345 left our warehouse on Monday. I'll contact\nthe carrier now and have an update for you within 2 hours. In the \nmeantime, I've credited your account with 20% off your next order for \nthe inconvenience.\"\nExample 2:\nCustomer: \"This product broke after one day\"\nResponse: \"Oh no! That's definitely not the experience we want you to \nhave. I'm starting a replacement order for you right now - it'll ship \ntoday with express delivery at no charge. No need to return the broken\nitem. Your new one should arrive by Thursday. Is there anything else I\ncan help make right?\"\nNow respond to this customer following the same style:\nCustomer: {customer_message}\"\"\"\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering10/12\n\nExamples are particularly powerful because they bypass the ambiguity of language\nInstead of trying to define \"friendly but professional,\" you simply show what it loo\nlike in action.\nAnd so, our journey is complete. We've transformed a simple graph into a legenda\nwarrior:\n1. The Graph: Every agent is just Assess → Strike → Repeat\n2. The Arsenal: Sharp, purposeful tools for every task\n3. The Context: A light backpack with only what's needed\n4. The Commands: Crystal-clear orders that eliminate confusion\nRemember the 90/10 rule: If your agent fails, check the arsenal and context first.\nPrompt engineering is just the final polish. But when you need that polish, your th\nlaws are:\nDemand the battle plan (Chain of Thought)\nSpeak like a general (Be Specific)\nShow, don't tell (Few-Shot Examples)\nYour warrior no longer smashes treasure chests when you meant \"open them\ncarefully.\" They understand. They execute. They win.\nThe next time someone shares \"secret prompt tricks,\" smile knowingly. You\nunderstand it's not about magic—it's about clarity.\nReady to build agents that actually understand? Check out PocketFlow on GitHub and s\ncommanding your digital warriors!\n6. Conclusion: From Confused Grunt to Elite\nSoldier\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering11/12\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n12 Likes∙1 Restack\nDiscussion about this post\nPrevious\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:50 PMLLM Agents & Prompt Engineering: A Warrior's Guide to Clear Commands\nhttps://pocketflow.substack.com/p/llm-agents-and-prompt-engineering12/12"
  },
  {
    "filename": "pocketBlog250507.pdf",
    "title": "Parallel LLM Calls from Scratch — Tutorial For",
    "date": "2025-05-07",
    "content": "\n\nParallel LLM Calls from Scratch — Tutorial For\nDummies (Using PocketFlow!)\nMAY 07, 2025\n1Sh\nEver felt like your program was stuck waiting... and waiting... for one API call to finish\nbefore starting the next? Especially with Large Language Models (LLMs), making mult\nrequests one by one can feel like watching paint dry. This guide breaks down how to\ndrastically speed things up using parallel processing with the PocketFlow Parallel Batch\nExample!\nZACHARY HUANG\n13\nTurbocharge Your LLM Tasks: From Serial\nSlowness to Parallel Power!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial1/22\n\nImagine you need an LLM to translate something into eight languages. The usual\nway?\n1. Ask for Chinese. Wait. \n2. Get Chinese back. Ask for Spanish. Wait. \n3. Get Spanish back. Ask for Japanese. Wait...  ...\nYou see the pattern? Each \"wait\" adds up. This is called sequential processing. It'\nsimple, but when you're talking to slow things like LLMs over the internet, it's\npainfully slow.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nWhat if you could shout out all eight translation requests at once and just grab the\nanswers as they pop back? That's the magic of doing things in parallel (or technic\nconcurrently for waiting tasks). Your program doesn't just sit there; it juggles multi\nrequests at once, cutting down the total time drastically.\nSound complicated? It doesn't have to be! In this guide, you'll learn:\nWhy waiting for API calls kills your speed.\nThe basics of async programming in Python (it's like being a smart chef!).\nHow to use PocketFlow's AsyncParallelBatchNode to easily run lots of L\ncalls at the same time.\nWe'll look at a PocketFlow parallel processing example that turns a slow translation job i\nspeedy one. Let's ditch the waiting game and make your LLM stuff fly!\nThe Problem: One-by-One is SLOOOW\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial2/22\n\nWhy is asking one-after-the-other so bad for speed? Let's stick with our 8-languag\ntranslation example.\nWhen you do it sequentially, here's the boring play-by-play for each language:\n1. Prep: Your code figures out the prompt (e.g., \"Translate to Chinese\").\n2. Send: It shoots the request over the internet to the LLM's brain.\n3. Wait (Internet Travel): Your request zooms across the network. Takes time. ⏳\n4. Wait (LLM Thinking): The big AI server gets your request, thinks hard, and\nmakes the translation. Takes time. 易\n5. Wait (Internet Travel Again): The answer zooms back to you. More waiting. ⏳\n6. Receive: Your program gets the Chinese translation. Yay!\n7. Repeat: Only now does it start all over for Spanish. Prep -> Send -> Wait -> Wa\nWait -> Receive. Then Japanese...\nThe real villain here is the WAITING. Your program spends most of its time twid\nits thumbs, waiting for the internet and the LLM. It can't even think about the Spa\nrequest until the Chinese one is totally done.\nThink of ordering coffee for 8 friends. You order one, wait for it to be made, wait f\nto be delivered... then order the next one. Madness!\nThis is what happens in this standard batch processing example. It uses a BatchN\nthat processes items one by one. Neat, but slow.\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial3/22\n\nThe result? Translating into 8 languages this way can take ages (like ~1136 second\nalmost 19 minutes!). Most of that isn't useful work, just waiting. There's gotta be a\nbetter way!\nRemember the slow way? Call -> Wait -> Call -> Wait... The problem is all that was\n\"wait\" time. What if, while waiting for one thing, we could start the next?\nThink of a chef making breakfast:\nThe Slow Chef: Makes Person 1's eggs. Waits. Serves. Then starts Person 2's to\nWaits. Serves. Then Person 3's coffee... Takes forever! \nThe Smart Chef (Concurrent): Puts eggs on the stove. While they cook, puts br\nin the toaster. While both cook, starts coffee. Toast pops? Serve it. Eggs done? S\nthem. ☕✨\nThe Solution: Stop Waiting, Start Doing (While\nYou Wait)!\nThe Smart Chef Analogy\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial4/22\n\nThe smart chef uses the waiting time for one task to make progress on others. That's\nwhat we want our code to do!\nPython has special keywords to help us be the smart chef:\nasync def: Marks a function as \"might involve waiting.\"\nawait: Inside an async function, this says, \"Okay, pause this specific task here\n(like waiting for toast or an API call). Python, feel free to work on other ready\ntasks while I wait!\"\nLet's see a tiny Python Async Coffee and Toast example using the asyncio library,\nwhich manages these waiting tasks:\nPython's Magic Words: async and await\nimport asyncio\nimport time\n# Mark these functions as async - they might wait\nasync def make_coffee():\n    print(\"Start coffee...\")\n    # Simulate waiting 3 seconds\n    await asyncio.sleep(3)\n    print(\"Coffee ready!\")\n    return \"Coffee\"\nasync def make_toast():\n    print(\"Start toast...\")\n    # Simulate waiting 2 seconds\n    await asyncio.sleep(2)\n    print(\"Toast ready!\")\n    return \"Toast\"\nasync def main():\n    start_time = time.time()\n    print(\"Breakfast time!\")\n    # Tell asyncio to run both tasks concurrently\n    # and wait here until BOTH are finished\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial5/22\n\nWhat's happening?\n1. We have two async functions, make_coffee and make_toast. They print, \nawait asyncio.sleep(SECONDS). This await is key - it pauses only that \nletting Python switch to other tasks.\n2. In main, asyncio.gather(coffee_task, toast_task) tells Python: \"\noff both coffee and toast. Run them concurrently. I'll wait here until they're bo\ndone.\"\n3. asyncio starts coffee, hits await asyncio.sleep(3), pauses coffee.\n4. asyncio starts toast, hits await asyncio.sleep(2), pauses toast.\n5. After 2 seconds, toast finishes sleeping. asyncio wakes it up, it prints \"Toast\nready!\" and finishes.\n6. After 3 seconds (total), coffee finishes sleeping. asyncio wakes it up, it prints\n\"Coffee ready!\" and finishes.\n7. Since both tasks given to gather are done, main wakes up, gets the results\n(['Coffee', 'Toast']), and prints the final messages.\nExpected Output:\n    coffee_task = make_coffee()\n    toast_task = make_toast()\n    results = await asyncio.gather(coffee_task, toast_task)\n    end_time = time.time()\n    print(f\"\\nBreakfast served: {results}\")\n    print(f\"Took {end_time - start_time:.2f} seconds\")\n# Run the main async function\nasyncio.run(main())\nBreakfast time!\nStart coffee...\nStart toast...\nToast ready!      # Toast finishes first (2s)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial6/22\n\nLook at the time! Only 3 seconds total, even though the tasks took 3s and 2s. The \nseconds of waiting for toast happened during the 3 seconds of waiting for coffee. N\ntime wasted!\nWe want:\nStart Call 1 -> Start Call 2 -> Start Call 3 -> (Wait for al\n-> Get Results = Total ~18s (just the longest call!) \nCoffee ready!     # Coffee finishes next (3s total)\nBreakfast served: ['Coffee', 'Toast']\nTook 3.00 seconds # Total time = longest task!\nBack to LLMs\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial7/22\n\nUsing async/await, we fire off multiple LLM requests and let Python handle the\nwaiting efficiently. Now, let's see how PocketFlow helps structure this.\nWe get the idea of asyncio for running things concurrently. But how do we organ\nthis in a real app? PocketFlow gives us simple building blocks called Nodes.\nThink of a PocketFlow Node as one workstation doing a specific job. It usually fol\nthree steps:\n1. prep: Get Ready. Grabs the ingredients (data) it needs from a shared storage a\n(shared dictionary).\n2. exec: Do the Work. Performs its main task using the ingredients.\n3. post: Clean Up. Takes the result, maybe tidies it up, and puts it back in the\nshared storage for the next station or the final output.\nPocketFlow's Toolkit: Building Blocks for Spee\nPocketFlow Nodes: Like Stations on an Assembly Line\nclass Node:\n    # Basic setup\n    def __init__(self):\n        pass\n    # 1. Get data needed from the shared dictionary\n    def prep(self, shared):\n        # ... implementation specific to the node ...\n        pass\n    # 2. Perform the main task (this runs ONE time per node run)\n    def exec(self, prep_res):\n        # ... node's core logic ...\n        pass\n    # 3. Put results back into the shared dictionary\n    def post(self, shared, prep_res, exec_res):\n        # ... store results ...\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial8/22\n\nThis simple prep -> exec -> post cycle keeps things organized.\nImagine a Node that translates text to one language using a regular, slow LLM call:\n        pass\n    # PocketFlow internally calls prep -> exec -> post\n    def run(self, shared):\n        prep_result = self.prep(shared)\n        exec_result = self.exec(prep_result) # The actual work happens\nhere\n        self.post(shared, prep_result, exec_result)\nExample: A Simple Translation Node\nclass TranslateOneLanguageNode(Node):\n    def prep(self, shared):\n        text_to_translate = shared.get(\"text\", \"\")\n        target_language = shared.get(\"language\", \"Spanish\") # Default \nSpanish\n        return text_to_translate, target_language\n    def exec(self, prep_res):\n        # Does the actual translation work\n        text, language = prep_res\n        print(f\"Translating to {language}...\")\n        # This call BLOCKS - the whole program waits here\n        translation = call_llm(f\"Translate '{text}' to {language}\")\n        print(f\"Finished {language} translation.\")\n        return translation\n    def post(self, shared, prep_res, exec_res):\n        # Stores the result back into the shared store\n        text, language = prep_res # Get language again if needed for \nstoring\n        shared[f\"translation_{language}\"] = exec_res\n        print(f\"Stored {language} translation.\")\n# How you might run it (hypothetically):\n# shared_data = {\"text\": \"Hello world\", \"language\": \"French\"}\n# translate_node = TranslateOneLanguageNode()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial9/22\n\nIf you wanted 8 languages, you'd run this Node (or something similar) 8 times one \nthe other. Slow!\nTo use async/await, PocketFlow has AsyncNode. Same idea, but uses async\nmethods, letting us await inside:\nprep_async(shared)\nexec_async(prep_res) <-- This is where we await slow things like LLM\ncalls!\npost_async(shared, prep_res, exec_res)\nAn AsyncNode lets you await inside its exec_async method, preventing it from\nblocking everything else.\n# translate_node.run(shared_data)\n# print(shared_data) # Would now contain {'text': 'Hello world', \n'language': 'French', 'translation_French': 'Bonjour le monde'}\nGoing Async: The AsyncNode\nclass AsyncNode(Node): # Same structure, but uses async\n    async def prep_async(self, shared): pass\n    async def exec_async(self, prep_res): pass # This is where we 'awa\ncall_llm()'!\n    async def post_async(self, shared, prep_res, exec_res): pass\n    async def run_async(self, shared): # Entry point for running an \nAsyncNode\n        # Runs the async prep -> exec -> post cycle\n        p = await self.prep_async(shared)\n        e = await self.exec_async(p)\n        await self.post_async(shared, p, e)\n        return None # Simplified\nHandling Many Items: The BatchNode\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial10/22\n\nOkay, we need to translate into multiple languages. The BatchNode helps organiz\nthis. It changes prep and exec slightly:\nprep(shared): Returns a list of work items (e.g., a list of languages).\nexec(item): Is called once for each item in the list, one after the other\n(sequentially).\nThis BatchNode is good for organization, but still slow because it processes item\none by one.\nThis is the one we want! AsyncParallelBatchNode combines everything:\nIt's Async: Uses prep_async, exec_async, post_async.\nclass BatchNode(Node): # Inherits from Node\n    def prep(self, shared):\n        # Should return a list of items, e.g. [\"Chinese\", \"Spanish\", \n\"Japanese\"]\n        pass # Returns list_of_items\n    # This 'exec' gets called FOR EACH item from prep, one by one\n    def exec(self, one_item):\n        # Process one_item (e.g., translate to this language)\n        pass # Returns result for this item\n    # PocketFlow internally loops through the items from prep\n    # and calls exec(item) for each one sequentially.\n    def batch_exec(self, list_of_items):\n        results = []\n        for one_item in (list_of_items or []):\n             # Calls the standard synchronous exec for one_item\n             result = self.exec(one_item)\n             results.append(result)\n        return results # Returns a list of results\nThe Star Player: AsyncParallelBatchNode - Doing it A\nat Once!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial11/22\n\nIt's Batch: prep_async returns a list of work items.\nIt's Parallel (Concurrent): It runs the exec_async(item) function for all ite\nat the same time using asyncio.gather behind the scenes.\nThe key is asyncio.gather (used internally). It takes all the individual\nexec_async tasks (one for each language) and juggles them concurrently, giving \nthat massive speed-up!\nYou run an AsyncParallelBatchNode inside an AsyncFlow (PocketFlow's wa\nrunning async nodes).\nclass AsyncParallelBatchNode(AsyncNode):\n    async def prep_async(self, shared):\n        # Returns a list of work items, e.g.,\n        # [(text, \"Chinese\"), (text, \"Spanish\"), ...]\n        pass # Returns list_of_items\n    # This 'exec_async' is called FOR EACH item, but runs CONCURRENTLY\n    async def exec_async(self, one_item):\n        # Process one_item (e.g., await call_llm(item))\n        # This is where the magic happens - multiple calls run at once\n        pass # Returns result for this item\n    async def parallel_exec(self, list_of_items): # The key override!\n        if not list_of_items: return [] # Handle empty list\n        # 1. Create a list of 'awaitable' tasks.\n        #    Each task is a call to the standard async 'exec'\n        #    (which calls the user's 'exec_async') for ONE item.\n        tasks_to_run_concurrently = [\n            self.exec_async(one_item) for one_item in list_of_items\n        ]\n        # 2. Pass ALL these tasks to asyncio.gather.\n        #    asyncio.gather starts them all, manages concurrency,\n        #    and returns the list of results once ALL are complete.\n        results = await asyncio.gather(*tasks_to_run_concurrently)\n        return results\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial12/22\n\nWith this tool, let's build our speedy parallel translator!\nTime to put it all together using the pocketflow-parallel-batch example. W\nwant to translate a README.md file into 8 languages, fast.\nFirst, we need a Python function that can call our LLM without blocking. The key is\nusing async def and await when making the actual API call.\nThis call_llm function is our async worker. It waits for the LLM without stoppi\nother workers.\nLet's Build the Speedy Translator!\nStep 1: The Async LLM Helper Function\n# From: cookbook/pocketflow-parallel-batch/utils.py\nimport os\nimport asyncio\nfrom anthropic import AsyncAnthropic # Using Anthropic's async client\n# Async version of the simple wrapper\nasync def call_llm(prompt):\n    \"\"\"Async wrapper for Anthropic API call.\"\"\"\n    client = AsyncAnthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"\n    # The 'await' here pauses THIS call, allowing others to run\n    response = await client.messages.create(\n        model=\"claude-3-7-sonnet-20250219\",\n        max_tokens=4000, # Adjust as needed\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n    )\n    # Assuming the response format gives text in the first content blo\n    return response.content[0].text\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial13/22\n\nNow we create our main Node using AsyncParallelBatchNode. This node wil\nmanage the whole parallel job.\nThis sets up the class.\nInside the Node: prep_async\nThis function gathers the data needed. It needs to return a list, where each item in\nlist represents one translation job.\nSo if you have 8 languages, this returns a list of 8 tuples.\nInside the Node: exec_async\nStep 2: The AsyncParallelBatchNode for Translation\n# From: cookbook/pocketflow-parallel-batch/main.py\nimport os\nimport aiofiles\nimport asyncio\nfrom pocketflow import AsyncFlow, AsyncParallelBatchNode\n# Assume 'call_llm' from utils.py is available\nclass TranslateTextNodeParallel(AsyncParallelBatchNode):\n    \"\"\"Translates text into multiple languages in parallel.\"\"\"\n    # --- Inside TranslateTextNodeParallel --- \n    async def prep_async(self, shared):\n        text = shared.get(\"text\", \"(No text)\")\n        languages = shared.get(\"languages\", [])\n        # Create the list of work items for the batch\n        # Each item is a tuple: (the_full_text, one_language)\n        return [(text, lang) for lang in languages]\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial14/22\n\nThis is the core function that does the actual work for one item from the batch.\nPocketFlow will run this function concurrently for all items returned by prep_as\nCrucially, the await call_llm(prompt) line allows the concurrency. While\nwaiting for the French translation, Python can work on the German one, and so on\nInside the Node: post_async\nThis function runs only after all the concurrent exec_async calls are finished. It\nreceives a list containing all the results.\n    # --- Inside TranslateTextNodeParallel --- \n    async def exec_async(self, one_job_tuple):\n        \"\"\"Translates text for ONE language. Runs concurrently for all\nlanguages.\"\"\"\n        text_to_translate, language = one_job_tuple\n        print(f\"  Starting translation task for: {language}\")\n        prompt = f\"Translate the following markdown into {language}: \n{text_to_translate}\"\n        # HERE is where we call our async helper!\n        # 'await' lets other translations run while this one waits for\nthe LLM.\n        translation_result = await call_llm(prompt)\n        # Return the result paired with its language\n        return {\"language\": language, \"translation\": translation_resul\n    # --- Inside TranslateTextNodeParallel --- \n    async def post_async(self, shared, prep_res, list_of_all_results):\n        \"\"\"Gathers all results and saves them to files.\"\"\"\n        print(\"All translations done! Saving files...\")\n        output_dir = shared.get(\"output_dir\", \"translations_output\")\n        os.makedirs(output_dir, exist_ok=True)\n        save_tasks = []\n        for result_dict in list_of_all_results:\n            language = result_dict.get(\"language\", \"unknown\")\n            translation = result_dict.get(\"translation\", \"\")\n            filename = os.path.join(output_dir, \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial15/22\n\nThis gathers everything up and saves the translated files. The optional async file\nwriting (aiofiles) is neat but not essential to the core parallel LLM call concept\nSince our Node is async, we need AsyncFlow to run it.\nf\"README_{language.upper()}.md\")\n            # Use async file writing for a tiny bit more speed\n            async def write_translation_to_file(fname, content):\n                async with aiofiles.open(fname, \"w\", encoding=\"utf-8\")\nas f:\n                    await f.write(content)\n                print(f\"    Saved: {fname}\")\n            save_tasks.append(write_translation_to_file(filename, \ntranslation))\n        # Wait for all file saving tasks to complete\n        await asyncio.gather(*save_tasks)\n        print(\"All files saved.\")\nStep 3: Running the Node with AsyncFlow\n# From: cookbook/pocketflow-parallel-batch/main.py\nimport asyncio\nimport time\n# Assume TranslateTextNodeParallel is defined\nasync def main():\n    # 1. Prepare the initial data\n    shared_data = {\n        \"text\": source_text_to_translate,\n        \"languages\": [\"Chinese\", \"Spanish\", \"Japanese\", \"German\",\n                      \"Russian\", \"Portuguese\", \"French\", \"Korean\"],\n        \"output_dir\": \"translations\"\n    }\n    # 2. Create an instance of our Node\n    translator_node = TranslateTextNodeParallel()\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial16/22\n\nKey steps: prepare data, create node, create flow, await flow.run_async(). T\nstarts the prep_async, runs all exec_async concurrently, then runs post_asy\nRemember the slow way took ~1136 seconds (almost 19 minutes)?\nRunning this parallel version gives output like this (notice how finishes are out of\norder - that's concurrency!):\n    # 3. Create an AsyncFlow, telling it to start with our node\n    translation_flow = AsyncFlow(start=translator_node)\n    print(f\"Starting parallel translation into \n{len(shared['languages'])} languages...\")\n    start_time = time.perf_counter()\n    # 4. Run the flow! This kicks off the whole process.\n    await translation_flow.run_async(shared_data)\n    end_time = time.perf_counter()\n    duration = end_time - start_time\n    print(f\"\\nTotal parallel translation time: {duration:.2f} seconds\"\n    print(\"\\n=== Translation Complete ===\")\n    print(f\"Translations saved to: {shared['output_dir']}\")\n    print(\"============================\")\nif __name__ == \"__main__\":\n    # Run the main async function\n    asyncio.run(main())\nStep 4: The Payoff - Speed!\nStarting parallel translation into 8 languages...\nPreparing translation batches...\n  Starting translation task for: Chinese\n  Starting translation task for: Spanish\n  Starting translation task for: Japanese\n  Starting translation task for: German\n  Starting translation task for: Russian\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial17/22\n\n~209 seconds! Under 3.5 minutes instead of 19! That's over 5x faster, just by lettin\nthe LLM calls run at the same time using AsyncParallelBatchNode. The total\ntime is now roughly the time of the slowest single translation, not the sum of all of th\nThis shows the huge win from switching to concurrency for slow, waiting tasks.\nDoing things in parallel is awesome, but like driving fast, there are a few things to\nwatch out for:\n1. API Speed Limits! (The #1 Gotcha)\nProblem: Imagine yelling 8 coffee orders at the barista all at once instead \none by one. They might get overwhelmed! Similarly, hitting an API with m\nrequests at the exact same time can trigger rate limits. The API server say\n  Starting translation task for: Portuguese\n  Starting translation task for: French\n  Starting translation task for: Korean\n  Finished translation task for: French  # French might finish first!\n  Finished translation task for: German\n  ... (other finish messages)\n  Finished translation task for: Chinese # Chinese might finish last\nGathering results and saving files...\n    Successfully saved: translations/README_FRENCH.md\n    Successfully saved: translations/README_GERMAN.md\n    ... (other save messages) ...\n    Successfully saved: translations/README_CHINESE.md\nAll translations saved.\nTotal parallel translation time: 209.31 seconds  # <--- WOW!\nTranslations saved to: translation\nHeads Up! Things to Keep in Mind\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial18/22\n\n\"Whoa, too many requests!\" and might reject some of them (often with a 4\nToo Many Requests error).\nWhat to Do:\nCheck the Rules: Look up the API's rate limits in its documentation.\nDon't Overdo It: Maybe don't run 500 tasks at once if the limit is 60 pe\nminute. You might need to run smaller batches in parallel.\nRetry Smartly: If you hit a limit, don't just retry immediately. Wait a b\nmaybe longer each time (this is called \"exponential backoff\"). PocketFl\nhas basic retries, but you can add smarter logic.\nLook for Native Batch Support: Some providers, like OpenAI (see the\nBatch API docs), offer specific batch endpoints. Sending one request w\nmany tasks can be even cheaper and handle scaling better on their side,\nthough it might be more complex to set up than just running parallel c\nyourself.\nAsk Nicely: Some APIs offer higher limits if you pay.\n2. Tasks Should Be Independent\nRequirement: This parallel trick works best when each task doesn't depen\nthe others. Translating to Spanish shouldn't need the French result first.\nIf They Depend: If Task B needs Task A's output, you can't run them in\nparallel like this. You'll need to run them one after the other (PocketFlow \nhandle this too, just differently!).\n3. Using Resources (Memory/Network)\nHeads Up: Juggling many tasks at once can use a bit more computer mem\nand network bandwidth than doing them one by one. Usually not a big dea\nAPI calls, but good to know if you're running thousands of tasks on a sma\nmachine.\n4. Handling Errors in a Crowd\nChallenge: If one translation fails in your batch of 8, what happens? By\ndefault, asyncio.gather (the tool PocketFlow uses internally for\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial19/22\n\nAsyncParallelBatchNode) might stop everything when the first error\noccurs. Alternatively, if configured to continue\n(return_exceptions=True), you'd have to manually check the results l\nfor errors later.\nPocketFlow's Help: PocketFlow Nodes have built-in retry logic for the ex\nstep! You can configure this when creating the node. For example:\n5. Check for Special Batch APIs\nOpportunity: Some services (like OpenAI) have special \"Batch APIs\". You\nsend one big request with all your tasks (e.g., all 8 translation prompts), an\nthey handle running them efficiently on their end. This can be simpler and\nbetter for rate limits, but might work differently (e.g., you get notified whe\nthe whole batch is done).\n6. Python's GIL (Quick Note)\nReminder: Regular Python has something called the Global Interpreter Lo\n(GIL). It means only one chunk of Python code runs at a precise instant on \nCPU core. asyncio is fantastic for waiting tasks (like network calls) becau\nlets Python switch to another task while one waits. It doesn't magically m\nCPU-heavy math run faster on multiple cores within the same program. Luc\ncalling LLMs is mostly waiting, so asyncio is perfect!\nKeep these tips in mind, and you'll be speeding up your code safely!\nYou've seen the difference: waiting for tasks one by one is slow, especially when\ntalking to things over the internet like LLMs. By using async/await and concurr\n# Retry failed translations up to 3 times, waiting 10 seconds between \nretries\ntranslator_node = TranslateTextNodeParallel(max_retries=3, wait=10)\nConclusion: Stop Waiting, Start Doing\n(Together!)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial20/22\n\nwe turn that boring wait time into productive work time, making things way faster\nTools like PocketFlow, specifically the AsyncParallelBatchNode, give you a n\nway to organize this. It uses asyncio.gather behind the scenes to juggle multip\ntasks (like our translations) concurrently. The jump from ~19 minutes to ~3.5 minu\nin our example shows how powerful this is. It's not just a small tweak; it's a smarte\nway to handle waiting.\nNow you know the secret! Go find those slow spots in your own code where you're\nwaiting for APIs or files, and see if AsyncParallelBatchNode can help you dit\nthe waiting game.\nReady to build this yourself? Dive into the code and experiment: You can grab the comp\ncode for the parallel translation example from the PocketFlow Parallel Batch Cookbook\nGitHub. To learn more about PocketFlow and how it helps build these kinds of workflow\ncheck out the main PocketFlow Repository, explore the PocketFlow Documentation, o\nconnect with the community on the PocketFlow Discord if you have questions or want to \nwhat you're building. Go conquer those waiting times!\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n13 Likes∙1 Restack\nDiscussion about this post\nPreviousNext\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial21/22\n\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:42 PMParallel LLM Calls from Scratch — Tutorial For Dummies (Using PocketFlow!)\nhttps://pocketflow.substack.com/p/parallel-llm-calls-from-scratch-tutorial22/22"
  },
  {
    "filename": "pocketBlog250510-2.pdf",
    "title": "The Ultimate AI Experiment: When LLMs Play t",
    "date": "2025-05-10",
    "content": "\n\nThe Ultimate AI Experiment: When LLMs Play t\nDanganronpa Killing Game (Part 2)\nMAY 10, 2025\nSh\nIn Part 1, we talked about why we threw AIs into the wild world of Danganronpa – we\nwanted AI game characters that are actually interesting! We saw AI agents scheme, acc\nand fight for their virtual lives. Now, in Part 2, we get into the how: all the techy stuff li\narchitecture, data management, and how we got these AIs to play together. Missed Par\nCatch up here!!\nZACHARY HUANG\n5\n1. Quick Recap: Boring NPCs are Out,\nDanganronpa Drama is In!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9251/26\n\nIn Part 1, we whined about a big problem in gaming: even though AI is super smar\nnow, a lot of game characters (NPCs) are still kinda... blah. Predictable. Polite, but \nThey say their lines, give you quests, but rarely do anything surprising or get into t\nmessy social stuff that makes games with real people so fun.\nOur crazy idea? The Agentic Danganronpa Simulator. We took AI agents, gave ea\none the personality of a Danganronpa \"Ultimate\" student, and tossed them into th\nsuper-tense \"Killing Game.\" Why? To see if we could make AIs that don't just follo\nscript, but actually strategize, lie, team up, and react with (fake) emotions, all bas\non their unique characters and the desperate need to survive. We saw how this set\nwith all its secrets and mind games, could lead to some seriously cool and\nunpredictable AI moments.\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\nNow, let's pop the hood and see what makes this despair-filled theater tick. How do yo\nactually build a system that lets a bunch of AI agents play such a tricky social game, keep\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9252/26\n\ntrack of who knows what and a game that's always changing? Time to get into the nitty-g\nTo get our Danganronpa AIs to dance (or rather, debate and deceive) properly, our\nsetup uses three main ingredients: a Streamlit-powered state machine to control th\ngame's flow, smart PocketFlow nodes for AI brainpower, and speedy LLM agents t\nbring the characters to life.\nThink of the Danganronpa game as a play with different acts and scenes: secret Ni\ndiscussions, tense Morning Announcements, chaotic Class Trial debates, crucial\nVoting, and dramatic Executions. To manage all this, we use a state machine built\nright into our Streamlit app.\nWhat's a state machine? It's just a way to define all the possible stages (or \"states\"\nthe game and the rules for moving from one stage to the next. The key player here \nvariable we call st.session_state.current_state.\nEach value this variable can take (like NIGHT_PHASE_BLACKENED_DISCUSSION \nCLASS_TRIAL_VOTE) tells the game exactly what phase it's in. Our main app cod\n(app.py) constantly checks this current_state and does whatever is needed fo\nthat phase. This could mean:\nShowing specific buttons or text boxes on the screen.\nGrabbing info from our game database.\nTelling an AI agent (using a PocketFlow node) it's their turn to think or act.\nUpdating the game's status and then switching\nst.session_state.current_state to the next phase.\nHere's a simplified picture of how the game moves from one state to another:\n2. The Blueprint: State Machines, Smart Nodes\nand Fast AI\n1. Driving the Drama: The Streamlit State Machine\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9253/26\n\nThe Streamlit frontend (what you see in your browser) is super important for this.\nWhen you vote or type in your arguments, Streamlit tells our state machine, often\nchanging the current_state and moving the game forward.\nAll the important game info, like the current_state, who the players are, the\nmessage history, and any temporary data the AIs or UI need, is held in\nst.session_state. Think of it as the game's shared brain for the current sessio\n2. Intelligent Actors: PocketFlow Nodes for AI Decision\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9254/26\n\nSo, Streamlit handles the when (what phase are we in?), but PocketFlow nodes han\nthe what and how of what an AI does during its turn. We don't use PocketFlow's big\nFlow objects to run the whole game. Instead, we use its handy Node idea to packa\nup the smarts for a single AI character's decision.\nOur main tool here is the DecisionNode:\nclass Node:\n    def __init__(self):\n        self.params = {} # Parameters specific to this node's executio\n    # Simplified steps for an AI's turn:\n    def prep(self, shared_store): # shared_store is st.session_state\n        # 1. Gather all info the AI needs from shared_store (game \nhistory, its role, etc.).\n        # THIS IS SUPER IMPORTANT for making sure AIs only know what \nthey should!\n        # self.params would tell it which character it's playing (e.g.\n'Kokichi Oma').\n        pass # Returns all the context it gathered.\n    def prep(self, prep_result_context):\n        # 2. Build a prompt for the LLM using the gathered context.\n        # 3. Call the LLM (Gemini 2.5 Flash) to get the AI's thoughts \nand actions.\n        # 4. Check and clean up the LLM's response.\n        pass # Returns the AI's decision in a structured way.\n    def prep(self, shared_store, prep_res, exec_res):\n        # 5. Save the AI's thinking and actions to the database.\n        # 6. Update shared_store if needed (e.g., with what the AI wil\nsay publicly).\n    def run_async(self, shared_store): # app.py calls this for an AI's\nturn\n        prep_result = self.prep(shared_store)\n        exec_result = self.prep(prep_result)\n        self.prep(shared_store, prep_result, exec_result)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9255/26\n\nWhen app.py decides it's a specific AI's turn (based on the current_state and\nwho's next to speak), it basically tells a DecisionNode, \"Hey, you're up! You're\nplaying as [Character Name].\" It then kicks off the run_async method, giving it\naccess to st.session_state (our shared brain). The node then does its prep -\nexec -> post dance to figure out and record what the AI does.\nThis keeps the AI's decision-making logic neatly bundled in the DecisionNode,\nwhile app.py focuses on the big picture of game flow and what you see on screen\nEach Danganronpa character is brought to life by an AI agent powered by Google'\nGemini 2.5 Flash. We picked Flash because it hits a sweet spot:\nSmart Reasoning: It's clever enough to get the complex rules of the Killing Ga\nunderstand social hints from the game's history, and try to think strategically \nits Danganronpa character should.\nSpeedy Responses: Speed is key for a game! Flash answers quickly, so the gam\ndoesn't feel slow, especially during those fast-paced Class Trial arguments.\nThe DecisionNode is in charge of writing super-detailed prompts for Gemini 2.5\nFlash. These prompts give the LLM the character's personality profile, their secret\nrole, what's happening in the game, a filtered history of events, and specific\ninstructions for what to do now (like \"come up with a statement\" or \"pick someon\nvote for\"). Good prompts are everything for getting the LLMs to act in believable a\ninteresting ways.\nBy mixing Streamlit's state control, PocketFlow's neat AI logic nodes, and Gemini 2.5 Fl\nbrainpower, we get a dynamic and pretty engaging Danganronpa Killing Game simulati\n3. The Minds Behind the Madness: Large Language\nModels\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9256/26\n\nBefore your AIs can start scheming and surviving, they need to become the\nDanganronpa characters. This means giving them personalities, backstories, and e\nsome examples of how they talk. Plus, visuals and sounds make everything more\nimmersive!\nTo really bring characters like Shuichi Saihara or Kokichi Oma to life, you need to\nyour game's AI (the LLM playing the character) some rich details. Where do you g\nthese? Well, you can do the research yourself, or even ask an AI assistant (like\nChatGPT) to help you out!\nFor example, you could ask an LLM to search the web for Danganronpa V3 charac\nand help you build out their profiles. The goal is to create a structured description\neach character that your game can use. Here's a simplified idea of what you might\nfor, using Shuichi as an example:\n3. Gathering Your Cast: Resources for\nDanganronpa AIs\nCrafting Character Profiles with a Little Help from AI\nFriends\n{\n  \"Shuichi\": {\n    \"backstory\": (\n        \"Helped his detective uncle solve an art-theft, hailed as \nprodigy but feels undeserving, earning \"\n        \"the Ultimate Detective title.\"\n    ),\n    \"personality\": (\n        \"Timid, earnest, sharp; forces himself to speak when truth \ndemands it.\"\n    ),\n    \"examples\": {\n        \"normal\":       \"Uh... I'll start gathering statements—please te\nme anything you recall.\",\n        \"sad\":          \"I promised myself I'd protect everyone... and I\nfailed.\",\n        \"worried\":      \"The evidence points at me? No—there has to be\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9257/26\n\nBackstory: A brief history to give the AI context on their past.\nPersonality: Key traits that define how they act and react.\nExamples: Short lines showing their typical speaking style in different emotio\nstates. This is super helpful for the LLM to nail the character's voice.\nHaving this kind of detailed profile for each character is a game-changer for gettin\nbelievable performances from your AIs.\nTo make your Danganronpa simulator even more engaging, you'll want character\nsprites (images) and voice clips.\nFor character sprites (images): A great place to look is The Spriters Resource\nexample, you can find a ton of sprites for Danganronpa V3: Killing\nHarmony characters here: https://www.spriters-\nresource.com/pc_computer/danganronpav3killingharmony/\nFor character voices and sound effects: The Sounds Resource is your go-to. F\ninstance, voices for Danganronpa: Trigger Happy Havoc can be found \nhttps://www.sounds-resource.com/pc_computer/danganronpatriggerhappyhav\nDownloading these assets can help you create a much richer user interface, display\nthe character who's speaking and even playing iconic voice lines or sound effects a\nkey moments.\ncontradiction somewhere!\",\n        \"affirmative\":  \"Here it is—the decisive proof! The mystery... i\nsolved.\",\n        \"blackened\":    \"Truth is dead. I'll bury the last witness wit\nit.\"\n    }\n  }\n}\nFinding Visuals and Sounds\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9258/26\n\nWith these resources, you can build a solid foundation for your AI characters, givi\nthem the depth they need to truly shine (or despair!) in the Killing Game.\nTrying to keep track of everything in a Danganronpa game – tons of characters, se\nroles, hidden actions, public statements, and a history that grows every \"day\" – wo\nbe a nightmare with just simple Python code. To keep things clear, easy to search, \nall in one place (even for a single game session), we decided to use an in-memory\nSQLite database. You can think of it as a super-organized digital notebook for the\ngame, accessible via st.session_state.db_conn.\nThis might sound a bit techy for a web app that forgets everything when you refre\nbut it gives us some big wins:\nNeatly Organized Data: Databases are awesome for storing info that has a cle\nstructure. This is perfect for keeping track of players, their roles, and all the\nactions they take.\nEasy Searching: We can quickly find specific bits of game history. For exampl\n\"What did Kokichi say on Day 2 during the Class Trial?\" or \"Who did the Trut\nSeeker check out last night?\" This is way easier than digging through complic\ncode structures.\nOne Source of Truth: The database is the official record of what happened. Th\nmakes it simpler to manage the game, as different parts of our app (like the AI\nDecisionNode or the code that shows stuff on screen) can just ask the datab\nfor what they need.\nHelps Keep Data Safe (Conceptually): Even though it's a simple in-memory\ndatabase, thinking about saving data in chunks (like after a whole phase is don\nhelps make sure everything stays consistent as the game changes.\nThe heart of our data setup is two main tables:\n4. Managing the Mayhem: Game Logic and\nDatabase Details\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-9259/26\n\nThis table stores the basic, unchangeable facts about who each character is and th\ncurrent status. We usually set this up once when a new game starts.\nWhy we have this: This table lets us quickly check a character's secret role (super\nimportant for the AI's DecisionNode) and if they're still alive (for figuring out w\ncan act, who won, etc.).\nThis is where the action is! This table logs every important event, thought, and\nstatement as the game goes on. It's a permanent record, building a complete histo\nfrom start to finish.\nroles Table: Who's Who in the Zoo\nactions Table: The Big Book of Everything That Happe\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92510/26\n\nWhy we have this: This table is the AI's main history book. The AI's DecisionNod\nheavily relies on this table to build the recent_history for its prompts. The\naction_type, actor_name, and phase columns are especially key for filtering \nhistory to keep secrets safe (as we talked about in the last section). For example, an\nonly gets to see its own thinking actions, or only sees the results of a Truth-Seeke\ninvestigation if it is the Truth-Seeker.\nBy carefully logging every move and having a structured way to look them up, our datab\nhelps us create the personalized, secret-filled histories our AIs need to play Danganronpa\nsmart and believable way. It's the quiet record-keeper of every plot, lie, and desperate cry\nhelp!\n5. Crafting AI Context: The Art of Information\nControl\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92511/26\n\nA huge part of what makes Danganronpa so thrilling is information asymmetry –\nmeaning, not everyone knows the same stuff! Secrets, hidden roles, and private clu\nare the heart of the game. If every AI knew all secrets, the game would be boring. T\nfun is in the AIs (and you!) piecing things together from incomplete and often\nmisleading info.\nOur DecisionNode is the AI's brain for each turn. Its most crucial job is to caref\ngather and filter information to build a personalized context for the LLM. This en\neach AI only acts on what it should legitimately know.\nRemember our AIs have private thinking logs and public talking statements?\nWhen an AI prepares for its turn (in its prep step), it needs to access history. Here\nhow we control that access:\nOwn thinking is Fair Game: An AI can always review its own past thinkin\nlogs from the database. This helps it remember its previous plans, suspicions, \nreasoning.\nSelective Memory: Querying thinking vs. talking\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92512/26\n\nOthers' talking is Public: An AI generally gets to see all the talking (publ\nstatements) made by other characters. This is the information everyone shares\nOthers' thinking is Off-Limits: Critically, an AI never sees the thinking lo\nof other AIs. Those private thoughts remain secret, fueling deception and\ndeduction.\nSome roles get unique information. The prep step also handles this:\nBlackened Team Huddle (Private Channel): If the acting AI is \"Blackened,\" it\nprep step will specifically query the database for past actions that were par\nthe private Blackened discussions (e.g., action_type\nblackened_discussion_statement). This lets them see their teammates\nsecret plans.\nTruth-Seeker's Findings (Top Secret Folder): If the AI is the \"Truth-Seeker,\" \nprep step retrieves the results of its past investigations (e.g., action_type\ntruth_seeker_reveal_private). This vital clue is only for them.\nGuardian's Logbook: The Guardian might get reminders of who they protecte\nrecently to follow game rules.\nThis selective querying ensures that the context built for an AI is tailored to its\nspecific role and knowledge.\nLet's break down how a simplified DecisionNode might work, using Python-like\npseudocode for clarity. Imagine this node is a mini-factory for producing an AI's\naction for a turn.\nprep is all about getting everything the AI needs for its specific character and the\ncurrent game situation, and most importantly, filtering the game history to what t\ncharacter should see.\nRole-Specific Intel: Special Briefings\nInside the DecisionNode: An AI's Turn, Step-by-Step\nStep 1: prep - Gather Your Ingredients & Filter History\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92513/26\n\n# --- Simplified DecisionNode: prep --- \nclass DecisionNode(Node): # Assuming Node is a base class\n    def prep(self, shared_game_state):\n        character_name = self.params[\"character_name\"] # Who is acting\n        db_conn = shared_game_state[\"db_conn\"]\n        current_day = shared_game_state[\"current_day\"]\n        current_phase = shared_game_state[\"current_phase\"]\n        print(f\"PREP: {character_name} is thinking for \n{current_phase}...\")\n        # 1. Get character basics (role, profile)\n        my_role = db_conn.query_my_role(character_name)\n        character_profile = \nshared_game_state[\"character_profiles\"].get(character_name, {})\n        # 2. Fetch and filter game history from database\n        # Query 1: Get MY OWN past 'thinking' logs\n        my_thinking_history = db_conn.query_actions(\n            actor_name=character_name, \n            action_type='thinking'\n        )\n        # Query 2: Get ALL PUBLIC 'talking' statements from everyone\n        public_statement_history = db_conn.query_actions(\n            action_type='statement' # Or whatever you call public talk\n        )\n        # Query 3: Get ROLE-SPECIFIC private info\n        role_specific_private_history = []\n        if my_role == 'Blackened':\n            # Simplified: Get private discussion messages among \nBlackened\n            role_specific_private_history = db_conn.query_actions(\n                action_type='blackened_discussion_statement', \n                # May also need to filter by participants if not all \nBlackened see all\n            )\n        elif my_role == 'Truth-Seeker':\n            # Simplified: Get results of my own past investigations\n            role_specific_private_history = db_conn.query_actions(\n                actor_name=character_name,\n                action_type='truth_seeker_result_private' \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92514/26\n\nWhat prep does: It's like a meticulous assistant preparing a briefing document. It\nfinds out who the AI is (character_name), its secret my_role, and its\ncharacter_profile. Then, it hits the database (represented by\ndb_conn.query_... calls): it grabs the AI's own past secret thoughts\n(my_thinking_history), all the public chatter everyone has heard\n(public_statement_history), and any special secret information only that rol\nshould see (role_specific_private_history). All this is carefully combined\n            )\n        # ... (add similar logic for Guardian, etc.)\n        # Combine and format into a single history string for the LLM\n        # This step needs careful ordering and formatting for the LLM \nunderstand\n        personalized_history_str = format_combined_history_for_llm(\n            my_thinking_history, \n            public_statement_history, \n            role_specific_private_history\n        )\n        # 3. Get other relevant info for the prompt\n        game_rules_summary = shared_game_state[\"game_rules_summary\"]\n        living_players = db_conn.query_living_players_names()\n        hint_text = get_playbook_hint(my_role, current_phase) # From o\nplaybook!\n        # Package it all up for the 'exec' step\n        return {\n            \"character_name\": character_name,\n            \"character_profile\": character_profile,\n            \"my_role\": my_role,\n            \"personalized_history\": personalized_history_str,\n            \"current_day\": current_day,\n            \"current_phase\": current_phase,\n            \"living_players\": living_players,\n            \"game_rules_summary\": game_rules_summary,\n            \"hint_text\": hint_text,\n            # ... any other info the LLM needs for this phase (e.g., \nvalid targets for voting)\n        }\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92515/26\n\na personalized_history_str. Finally, it adds general game info, like rules, w\nalive, and any relevant strategic hints from our playbook. This whole package is th\npassed to the exec step.\nexec takes all the carefully prepared info from prep and uses it to ask the LLM w\nthe character should do.\nStep 2: exec - The LLM Makes a Decision\n# --- Simplified DecisionNode: exec --- \n# (Continuing the DecisionNode class)\n    def exec(self, prep_context):\n        character_name = prep_context[\"character_name\"]\n        print(f\"EXEC: {character_name} is making a decision...\")\n        # Build the big prompt for the LLM\n        # This combines all the gathered context into a natural langua\nrequest\n        prompt_components = [\n            f\"You are {character_name}. Your role is \n{prep_context['my_role']}.\",\n            f\"Your personality: \n{prep_context['character_profile'].get('personality', '')}\",\n            f\"Game Day: {prep_context['current_day']}, Phase: \n{prep_context['current_phase']}\",\n            f\"Living Players: {', \n'.join(prep_context['living_players'])}\",\n            f\"Game Rules Summary: {prep_context['game_rules_summary']}\n            f\"Strategic Hint for this situation: \n{prep_context['hint_text']}\",\n            f\"Personalized Game History (what you \nknow):\\n{prep_context['personalized_history']}\",\n            \"Based on all the above, and your character, what is your \ninternal thinking,\",\n            \"and what is your public action (e.g., statement or vote \ntarget)?\",\n            \"Respond in YAML format:\",\n            \"thinking: |\",\n            \"  (Your detailed thoughts and reasoning here...)\",\n            \"action_type: <statement|vote|other_action>\",\n            \"action_content: |\",\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92516/26\n\nWhat exec does: This step is where the AI \"thinks.\" It takes the personalized\ninformation bundle from prep and crafts a detailed prompt for the Large Langua\nModel. This prompt tells the LLM who it is, its role, personality, what it knows ab\nthe game so far (the crucial personalized_history), the current situation, any\nstrategic hints, and then asks it to decide on its internal thinking and its actio\n(like what to say or who to vote for), usually in a structured format like YAML. The\ncall_llm then gets the response, which is parsed into a usable format. Basic\nvalidation checks if the core pieces are there.\n            \"  (Your public statement, or the name of the player you \nvote for, etc.)\",\n            \"optional_emotion: <happy|sad|angry|neutral> # If making a\nstatement\"\n        ]\n        prompt = \"\\n\".join(prompt_components)\n        # Call the LLM (this is a stand-in for the actual API call)\n        llm_response_yaml = call_llm(prompt)\n        # Parse the LLM's YAML response\n        # Real parsing would need error handling (try-except blocks)\n        parsed_decision = parse_yaml_from_llm(llm_response_yaml) \n        # Expected: {'thinking': '...', 'action_type': '...', \n'action_content': '...', 'optional_emotion': '...'}\n        # Basic validation (in real code, this would be more robust)\n        if not all(k in parsed_decision for k in ['thinking', \n'action_type', 'action_content']):\n            print(f\"ERROR: LLM response for {character_name} was missi\nrequired fields!\")\n            # Handle error, maybe by returning a default safe action\n            return {\"thinking\": \"Error in LLM response.\", \"action_type\n\"error\", \"action_content\": \"\"}\n        print(f\"EXEC: {character_name} decided: \n{parsed_decision['action_type']}\")\n        return parsed_decision \nStep 3: post - Record the Action & Update the World\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92517/26\n\npost takes the AI's decision from exec and makes it official by saving it to the\ndatabase.\n# --- Simplified DecisionNode: post --- \n# (Continuing the DecisionNode class)\n    def post(self, shared_game_state, prep_context, exec_decision):\n        character_name = prep_context[\"character_name\"]\n        current_day = prep_context[\"current_day\"]\n        # Important: Use the *logging phase* if it was a user input \nphase that maps to a main one\n        logging_phase = \nmap_user_input_phase_to_logging_phase(prep_context[\"current_phase\"])\n        db_conn = shared_game_state[\"db_conn\"]\n        print(f\"POST: Recording {character_name}'s actions for \n{logging_phase}...\")\n        # 1. Log the AI's (private) thinking process\n        db_conn.log_action(\n            day=current_day, \n            phase=logging_phase, \n            actor_name=character_name, \n            action_type='thinking', # This is always private\n            content=exec_decision['thinking']\n            # No target or emotion for thinking logs typically\n        )\n        # 2. Log the AI's (public or game-changing) action\n        action_to_log = exec_decision['action_type']\n        content_to_log = exec_decision['action_content']\n        emotion_to_log = exec_decision.get('optional_emotion') # Might\nbe None\n        target_for_action = None # Default, may change for votes etc.\n        if action_to_log == 'vote':\n            target_for_action = content_to_log # If content is the \ntarget name\n            content_to_log = None # Votes might not have separate \ncontent beyond target\n        db_conn.log_action(\n            day=current_day, \nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92518/26\n\nWhat post does: This is the cleanup and record-keeping step. It takes the\nexec_decision (which includes the AI's secret thinking and its chosen actio\nIt then writes these to the database using db_conn.log_action(...): the\nthinking is logged privately for that AI, and the action (like a public statement\nvote) is logged according to its type. This makes the AI's move official and updates\ngame's history for the next player's turn. Sometimes, it might also update the\nshared_game_state directly if an action has an immediate effect on the game t\nthe main loop needs to know about right away.\nBy breaking down an AI's turn into these prep -> exec -> post stages, we can ma\nthe complex flow of information and ensure that each AI acts on a world view that's\nappropriate for its character, role, and the secrets it legitimately holds.\n            phase=logging_phase, \n            actor_name=character_name, \n            action_type=action_to_log, \n            content=content_to_log,\n            target_name=target_for_action, \n            emotion=emotion_to_log \n        )\n        # Potentially update shared_game_state if the action has \nimmediate global effects\n        # For example, if a vote triggers the end of a phase, or a \nstatement needs to be displayed.\n        # This part depends heavily on how the main game loop in app.p\nworks.\n        # Example: shared_game_state[\"ui_update_needed\"] = True\n        print(f\"POST: Actions for {character_name} recorded.\")\n6. Making the Chaos Work: Speed-Ups &\nGameplay Adjustments\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92519/26\n\nRunning a game with a dozen AIs, where each one needs to call an LLM to think a\nact, can get tricky. We need to make sure it runs smoothly and is fun to play. Here \nfew tricks we used to keep the despair flowing without the game feeling clunky.\nBeyond their character profile, secret role, and the filtered game history, we also g\nour AIs a little nudge in the right direction through in-context strategic hints – th\nof it as a mini \"playbook\" embedded directly into their prompt. This helps them m\nmore role-appropriate and strategically sound decisions without needing to deduc\nevery optimal strategy from scratch each time.\nThese aren't rigid rules, but rather condensed pieces of advice that the LLM can\nconsider. Here are a few highly simplified examples of the kind of hints an AI migh\nreceive:\nFor Blackened During Night Discussion:\nHint Example: \"Consider eliminating players who are strong investigators \na potential Truth-Seeker). Keeping loud or misleading players alive can cre\nconfusion that benefits you. Don't target Shuichi unless he's a clear, confir\nthreat (helps player experience).\"\nFor the Truth-Seeker During Class Trial:\nHint Example: \"If you've found Blackened and think you might be killed\ntonight, it's vital to reveal everything: who you confirmed as Blackened, AN\nwho you cleared as Hope. If you haven't found Blackened, it's often best to\nstay quiet and avoid drawing attention.\"\nFor Any Player Late in a Class Trial Discussion:\nHint Example: \"As a late speaker, be decisive! Clearly name ONE specific\nperson you believe should be voted for, or firmly call for everyone to absta\nAvoid rambling.\"\nFor Hope Team Members if the Truth-Seeker Died:\nGuiding the AIs: The In-Context Playbook\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92520/26\n\nHint Example: \"With the Truth-Seeker gone, uncertainty is high, but abstai\nnow helps the Blackened. Vote aggressively! Consider targeting the quiete\nplayers or those who were suspicious in the past.\"\nThese in-context hints act as a guiding hand, helping the AI align its powerful\nlanguage and reasoning abilities with the specific strategic nuances of Danganron\nleading to more engaging and coherent gameplay.\nNot all parts of the game should have AIs acting in the same way:\nOne at a Time for Sensible Chats (Discussions):\nWhen AIs are discussing things, like during a CLASS_TRIAL_DISCUSSION o\nwhen the Blackened AIs are secretly planning at night\n(NIGHT_PHASE_BLACKENED_DISCUSSION), they have to go one by one.\nCharacter A says their piece, we log it to the database, and then Character B g\nto \"hear\" (get in their history) what Character A said before they figure out th\nown response. This turn-by-turn flow is key for making conversations and pla\nmake sense.\nIn our app.py code, we do this by going through a list of who needs to act in \ncurrent phase. For each AI, we kick off its DecisionNode. The node logs the\naction, and then we move to the next AI, who now knows what the previous o\ndid.\nAll Together for Speed (Thinking & Voting):\nOther times, AIs are doing things that are effectively independent, like formin\ntheir internal thoughts or deciding on a vote before revealing it. Since these\nactions don't strictly depend on seeing each other's choices in that exact micro-\n(they're based on prior shared history), we can speed things up by processing t\nin parallel.\nFor these bits, we use something in PocketFlow called\nAsyncParallelBatchFlow. This allows multiple AI DecisionNode instan\nto run their thinking and decision-making processes concurrently. Doing thin\nparallel like this really speeds up these phases, making the game feel snappier\nOne by One vs. All at Once: How AIs Take Turns\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92521/26\n\na deep dive into how parallel LLM calls can be implemented with PocketFlow\ncheck out this tutorial: Parallel LLM Calls from Scratch — Tutorial For Dumm\n(Using PocketFlow!).\nEarly on, we noticed something funny: if you, the human player, chose to play as\nShuichi Saihara (Ultimate Detective), the AI Blackened would often, very smartly\ndecide to kill him off super early. Strategically, it makes sense for the AIs – get rid \nthe best detective! But for you, the player, it's a bummer to get knocked out on Day\nor 2 and just watch.\nSo, we gave Shuichi a bit of \"plot armor\" to make the game more fun for you:\nThe Tweak: The prompt we give to Blackened AIs when they're choosing who\nkill at night (NIGHT_PHASE_BLACKENED_VOTE) has a little hint: \"DON'T targ\nShuichi to give him a better user experience. Only target Shuichi if he is likely to be T\nSeeker or Guardian.\"\nWhy We Did It: This isn't to make Shuichi invincible. It just gently nudges th\nAIs to think about other targets unless Shuichi seems like a really immediate,\nconfirmed threat (like if they think he's a key role).\nThe Result: This small change makes it much more likely that you (as Shuichi\nsurvive the first few rounds, so you can actually play the game and do some\ndetective work!\nWe know this is a deliberate choice that makes the game a bit less of a \"pure\" AI\nbattle. But for a game designed for a human to play and enjoy, we think this tweak\nmakes it way more fun. It's about balancing super-smart AI with a great player\nexperience.\nA Little Help for the Hero: Plot Armor\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92522/26\n\nThese kinds of decisions – using parallelism to speed things up and making small changes \nbehavior for the sake of fun – are key to making the Danganronpa Simulator not just a c\ntech demo, but also an enjoyable game you can play again and again.\nSo, after all that building, coding, and watching AIs betray each other, what did we\nactually learn from our Ultimate AI Experiment? This whole adventure with the\nAgentic Danganronpa Simulator has been a blast, pushing LLMs to be more than \nchatbots – we made them into schemers, liars, and desperate survivors!\nHere are our main \"Aha!\" moments:\n7. The Big Takeaways & The Never-Ending Killi\nGame!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92523/26\n\nAmazing Personalities = Amazing AI: Forget generic NPCs! Giving LLMs wi\ndistinct Danganronpa-style personalities is the secret sauce for truly fun and\nunpredictable AI interactions. Their built-in drama does half the work!\nSecrets Make the World Go Round (Especially in Danganronpa): The whole t\nis hidden info. Carefully controlling what each AI knows (and doesn't know) i\nabsolutely essential. No secrets, no strategy, no fun!\nYou Don't Need Super Complex Tools for Complex AI Shows: Simple\nframeworks like PocketFlow show that you can manage a whole crew of smart\nwithout a massive, clunky system. Keep the controller simple, let the AIs (and\nLLMs powering them) be the complicated ones!\nSeeing AIs \"Think\" vs. \"Talk\" is Awesome: Letting AIs have secret inner\nthoughts that are different from what they say out loud? Genius! It gives us a p\ninto their \"minds\" and lets them be way more sneaky and interesting. Plus, th\nsecret thought logs are gold.\nDatabases: Your Friend for Complicated Game States: When you've got tons \nhistory and characters doing things, a good old database (even a simple one) m\nkeeping track of it all way easier than trying to juggle a million Python\ndictionaries.\nSpeed is Key for a Good Time: Nobody likes a laggy game. Using tricks like\nrunning AI actions in parallel (like voting) makes everything feel snappier and\nmore responsive.\nSometimes, You Gotta Bend the AI Rules for Player Fun: If pure AI strategy\nmakes the game a drag for humans (like always killing the main character first\nit's okay to give the AI a little nudge with its instructions (hello, Shuichi's plot\narmor!). A fun game is the goal!\nOf course, it's not all perfect, and there's always more cool stuff we could do (more\ndespair to code!):\nWhere We Tripped & Future Despair (The Fun Kind!)\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92524/26\n\nLLMs Can Be Quirky: Gemini 2.5 Flash is smart, but like all LLMs, it can\nsometimes say something a bit weird, misunderstand a tricky situation, or get\nstuck on repeat. Writing good prompts is a never-ending adventure!\nMaking It Look Good (UI/UX): We're more about the AI brains than the prett\nfaces. Our Streamlit app works great to show off the game, but a real UI/UX g\ncould make it look even more awesome.\nMore Players (Human vs. AI Mayhem?): Imagine scaling this up! More AI pla\nor even mixing human players (PvP) in with the AI agents (PvE), could lead to \nwilder social dynamics and emergent strategies.\nSmarter AI Learning: Right now, we give AIs hints. What if they could truly le\nthe best strategies over multiple games? Enabling genuine AI learning instead\njust in-context hints would be the next level of AI evolution (or despair!).\nMore Danganronpa Madness?: The Danganronpa series has even crazier role\nand game mechanics in later versions. Adding those would be epic, but also a\nbigger challenge for our AIs!\nThe Agentic Danganronpa Simulator is our proof that you can make AI game\ncharacters that are genuinely exciting, surprising, and create their own amazing\nstories. We're moving way beyond those boring, predictable NPCs!\nThe days of staring at lifeless NPC chat are numbered. You've now seen how to giv\nyour AIs real personalities, deep secrets, and the freedom to truly play.\nReady to dive deeper or even build your own?\nExperience the Despair: Play the Danganronpa AI Simulator yourself!\nExplore the Code: Check out the Agentic Danganronpa Simulator on GitHub\nLearn More About the Tech: Dive into the PocketFlow Framework GitHub R\nChat with the Masterminds: Join the PocketFlow Discord Community.\nThe Killing Game Must Go On!\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92525/26\n\nThanks for reading Pocket Flow! Subscribe for\nfree to receive new posts and support my work.\n5 Likes\nDiscussion about this post\nPreviousNext\nWrite a comment...\n© 2025Zachary Huang ∙ Privacy ∙ Terms ∙ Collection notice\nSubstackis the home for great culture\nCommentsRestacks\nLooks like an article worth saving!\nHover over the brain icon or use hotkeys to save with Memex.\nOptionQ\nRemind me laterHide Forever\n8/24/25, 3:43 PMThe Ultimate AI Experiment: When LLMs Play the Danganronpa Killing Game (Part 2)\nhttps://pocketflow.substack.com/p/the-ultimate-ai-experiment-when-llms-92526/26"
  }
]